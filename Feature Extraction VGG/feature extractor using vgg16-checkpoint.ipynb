{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "from PIL import ImageFile   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the train,test and model directories\n",
    "\n",
    "* We will create the directories for train,test and model training paths if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/state-farm-distracted-driver-detection/imgs\"\n",
    "TEST_DIR = os.path.join(DATA_DIR,\"test\")\n",
    "TRAIN_DIR = os.path.join(DATA_DIR,\"train\")\n",
    "\n",
    "CSV_DIR = os.path.join(os.getcwd(),\"csv_files\")\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(),\"model\",\"vgg16\")\n",
    "PICKLE_PATH = os.path.join(os.getcwd(),\"pickle\")\n",
    "TEST_CSV = os.path.join(os.getcwd(),\"csv_files\",\"test.csv\")\n",
    "TRAIN_CSV = os.path.join(os.getcwd(),\"csv_files\",\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path does not exists\n",
      "Model path created\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(TEST_DIR):\n",
    "    print(\"Testing data does not exists\")\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(\"Training data does not exists\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"Model path does not exists\")\n",
    "    os.makedirs(MODEL_PATH)\n",
    "    print(\"Model path created\")\n",
    "else:\n",
    "    shutil.rmtree(MODEL_PATH)\n",
    "    os.makedirs(MODEL_PATH)\n",
    "if not os.path.exists(PICKLE_PATH):\n",
    "    os.makedirs(PICKLE_PATH)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.makedirs(CSV_DIR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(DATA_DIR,filename):\n",
    "    class_names = os.listdir(DATA_DIR)\n",
    "    data = list()\n",
    "    if(os.path.isdir(os.path.join(DATA_DIR,class_names[0]))):\n",
    "        for class_name in class_names:\n",
    "            file_names = os.listdir(os.path.join(DATA_DIR,class_name))\n",
    "            for file in file_names:\n",
    "                data.append({\n",
    "                    \"Filename\":os.path.join(DATA_DIR,class_name,file),\n",
    "                    \"ClassName\":class_name\n",
    "                })\n",
    "    else:\n",
    "        class_name = \"test\"\n",
    "        file_names = os.listdir(DATA_DIR)\n",
    "        for file in file_names:\n",
    "            data.append(({\n",
    "                \"FileName\":os.path.join(DATA_DIR,file),\n",
    "                \"ClassName\":class_name\n",
    "            }))\n",
    "    data = pd.DataFrame(data)\n",
    "    data.to_csv(os.path.join(os.getcwd(),\"csv_files\",filename),index=False)\n",
    "\n",
    "create_csv(TRAIN_DIR,\"train.csv\")\n",
    "create_csv(TEST_DIR,\"test.csv\")\n",
    "data_train = pd.read_csv(os.path.join(os.getcwd(),\"csv_files\",\"train.csv\"))\n",
    "data_test = pd.read_csv(os.path.join(os.getcwd(),\"csv_files\",\"test.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(TRAIN_CSV)\n",
    "data_test = pd.read_csv(TEST_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c0': 0, 'c2': 1, 'c4': 2, 'c5': 3, 'c3': 4, 'c6': 5, 'c9': 6, 'c8': 7, 'c1': 8, 'c7': 9}\n",
      "(22424, 10)\n"
     ]
    }
   ],
   "source": [
    "labels_list = list(set(data_train['ClassName'].values.tolist()))\n",
    "labels_id = {label_name:id for id,label_name in enumerate(labels_list)}\n",
    "print(labels_id)\n",
    "data_train['ClassName'].replace(labels_id,inplace=True)\n",
    "\n",
    "labels = to_categorical(data_train['ClassName'])\n",
    "print(labels.shape)\n",
    "\n",
    "with open(os.path.join(PICKLE_PATH,\"labels_list_vgg16.pkl\"),\"wb\") as handle:\n",
    "    pickle.dump(labels_id,handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "1. Converting the all the train and test images into image size of 64,64,3 \n",
    "2. Standardizing the flattened image vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(data_train.iloc[:,0],labels,test_size = 0.2,random_state=42)\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(64, 64))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (64, 64, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 64, 64, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17939/17939 [03:00<00:00, 99.30it/s] \n",
      "100%|██████████| 4485/4485 [00:44<00:00, 101.79it/s]\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(xtrain).astype('float32')/255 - 0.5\n",
    "valid_tensors = paths_to_tensor(xtest).astype('float32')/255 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561/561 [==============================] - 8s 9ms/step\n",
      "141/141 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "train_vgg16 = model.predict(train_tensors,verbose=1)\n",
    "valid_vgg16 = model.predict(valid_tensors,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (17939, 2, 2, 512)\n",
      "Validation shape (4485, 2, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape\",train_vgg16.shape)\n",
    "print(\"Validation shape\",valid_vgg16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_vgg16[0]\n",
    "valid_features = valid_vgg16[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape (2, 2, 512)\n",
      "Validation features shape (2, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features shape\",train_features.shape)\n",
    "print(\"Validation features shape\",valid_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 5,130\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_features.shape))\n",
    "VGG16_model.add(Dense(10, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(VGG16_model,to_file=os.path.join(os.getcwd(),\"model\",\"vgg16\",\"model_distracted_driver_vgg16.png\"),show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(MODEL_PATH,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0135 - accuracy: 0.3272 - val_loss: 1.4477 - val_accuracy: 0.5871\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.44771, saving model to vgg_model.h5\n",
      "Epoch 2/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.3455 - accuracy: 0.6310 - val_loss: 1.1311 - val_accuracy: 0.6896\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.44771 to 1.13113, saving model to vgg_model.h5\n",
      "Epoch 3/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 1.0725 - accuracy: 0.7120 - val_loss: 0.9714 - val_accuracy: 0.7373\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.13113 to 0.97144, saving model to vgg_model.h5\n",
      "Epoch 4/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.9317 - accuracy: 0.7483 - val_loss: 0.8624 - val_accuracy: 0.7641\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.97144 to 0.86237, saving model to vgg_model.h5\n",
      "Epoch 5/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.8130 - accuracy: 0.7835 - val_loss: 0.7765 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.86237 to 0.77649, saving model to vgg_model.h5\n",
      "Epoch 6/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.7532 - accuracy: 0.8009 - val_loss: 0.7253 - val_accuracy: 0.7844\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.77649 to 0.72534, saving model to vgg_model.h5\n",
      "Epoch 7/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6896 - accuracy: 0.8151 - val_loss: 0.6679 - val_accuracy: 0.8230\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72534 to 0.66788, saving model to vgg_model.h5\n",
      "Epoch 8/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6467 - accuracy: 0.8321 - val_loss: 0.6318 - val_accuracy: 0.8256\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.66788 to 0.63178, saving model to vgg_model.h5\n",
      "Epoch 9/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.6036 - accuracy: 0.8432 - val_loss: 0.5998 - val_accuracy: 0.8328\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.63178 to 0.59980, saving model to vgg_model.h5\n",
      "Epoch 10/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.5818 - accuracy: 0.8458 - val_loss: 0.5749 - val_accuracy: 0.8397\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.59980 to 0.57488, saving model to vgg_model.h5\n",
      "Epoch 11/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.5501 - accuracy: 0.8585 - val_loss: 0.5599 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.57488 to 0.55995, saving model to vgg_model.h5\n",
      "Epoch 12/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.5247 - accuracy: 0.8602 - val_loss: 0.5485 - val_accuracy: 0.8388\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.55995 to 0.54855, saving model to vgg_model.h5\n",
      "Epoch 13/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.5000 - accuracy: 0.8699 - val_loss: 0.5148 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.54855 to 0.51481, saving model to vgg_model.h5\n",
      "Epoch 14/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4807 - accuracy: 0.8788 - val_loss: 0.4975 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.51481 to 0.49755, saving model to vgg_model.h5\n",
      "Epoch 15/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.4725 - accuracy: 0.8756 - val_loss: 0.4829 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.49755 to 0.48292, saving model to vgg_model.h5\n",
      "Epoch 16/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.4582 - accuracy: 0.8806 - val_loss: 0.4679 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48292 to 0.46794, saving model to vgg_model.h5\n",
      "Epoch 17/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.4391 - accuracy: 0.8823 - val_loss: 0.4566 - val_accuracy: 0.8698\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.46794 to 0.45661, saving model to vgg_model.h5\n",
      "Epoch 18/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4206 - accuracy: 0.8901 - val_loss: 0.4490 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.45661 to 0.44902, saving model to vgg_model.h5\n",
      "Epoch 19/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.4126 - accuracy: 0.8896 - val_loss: 0.4374 - val_accuracy: 0.8796\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.44902 to 0.43738, saving model to vgg_model.h5\n",
      "Epoch 20/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.4112 - accuracy: 0.8873 - val_loss: 0.4385 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.43738\n",
      "Epoch 21/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.4010 - accuracy: 0.8936 - val_loss: 0.4405 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.43738\n",
      "Epoch 22/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3879 - accuracy: 0.8971 - val_loss: 0.4196 - val_accuracy: 0.8798\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.43738 to 0.41955, saving model to vgg_model.h5\n",
      "Epoch 23/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3832 - accuracy: 0.8953 - val_loss: 0.4114 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.41955 to 0.41144, saving model to vgg_model.h5\n",
      "Epoch 24/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3714 - accuracy: 0.9028 - val_loss: 0.4078 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.41144 to 0.40784, saving model to vgg_model.h5\n",
      "Epoch 25/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3660 - accuracy: 0.9018 - val_loss: 0.3969 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.40784 to 0.39687, saving model to vgg_model.h5\n",
      "Epoch 26/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3620 - accuracy: 0.9010 - val_loss: 0.3981 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.39687\n",
      "Epoch 27/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3639 - accuracy: 0.8996 - val_loss: 0.3924 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.39687 to 0.39244, saving model to vgg_model.h5\n",
      "Epoch 28/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3504 - accuracy: 0.9056 - val_loss: 0.3969 - val_accuracy: 0.8829\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.39244\n",
      "Epoch 29/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3410 - accuracy: 0.9094 - val_loss: 0.3829 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.39244 to 0.38293, saving model to vgg_model.h5\n",
      "Epoch 30/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3364 - accuracy: 0.9086 - val_loss: 0.3835 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.38293\n",
      "Epoch 31/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3323 - accuracy: 0.9093 - val_loss: 0.3721 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.38293 to 0.37209, saving model to vgg_model.h5\n",
      "Epoch 32/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3352 - accuracy: 0.9088 - val_loss: 0.3721 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.37209\n",
      "Epoch 33/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3283 - accuracy: 0.9106 - val_loss: 0.3707 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.37209 to 0.37075, saving model to vgg_model.h5\n",
      "Epoch 34/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3172 - accuracy: 0.9145 - val_loss: 0.3655 - val_accuracy: 0.8957\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.37075 to 0.36549, saving model to vgg_model.h5\n",
      "Epoch 35/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3151 - accuracy: 0.9147 - val_loss: 0.3617 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.36549 to 0.36171, saving model to vgg_model.h5\n",
      "Epoch 36/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3216 - accuracy: 0.9100 - val_loss: 0.3535 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.36171 to 0.35348, saving model to vgg_model.h5\n",
      "Epoch 37/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.9163 - val_loss: 0.3527 - val_accuracy: 0.8988\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.35348 to 0.35269, saving model to vgg_model.h5\n",
      "Epoch 38/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3093 - accuracy: 0.9162 - val_loss: 0.3494 - val_accuracy: 0.8943\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.35269 to 0.34937, saving model to vgg_model.h5\n",
      "Epoch 39/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.3024 - accuracy: 0.9163 - val_loss: 0.3503 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.34937\n",
      "Epoch 40/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2873 - accuracy: 0.9220 - val_loss: 0.3464 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34937 to 0.34636, saving model to vgg_model.h5\n",
      "Epoch 41/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2951 - accuracy: 0.9179 - val_loss: 0.3417 - val_accuracy: 0.9023\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.34636 to 0.34169, saving model to vgg_model.h5\n",
      "Epoch 42/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2876 - accuracy: 0.9243 - val_loss: 0.3441 - val_accuracy: 0.9006\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34169\n",
      "Epoch 43/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2932 - accuracy: 0.9202 - val_loss: 0.3388 - val_accuracy: 0.9001\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.34169 to 0.33880, saving model to vgg_model.h5\n",
      "Epoch 44/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2895 - accuracy: 0.9219 - val_loss: 0.3438 - val_accuracy: 0.8992\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.33880\n",
      "Epoch 45/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2802 - accuracy: 0.9268 - val_loss: 0.3343 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33880 to 0.33428, saving model to vgg_model.h5\n",
      "Epoch 46/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2756 - accuracy: 0.9257 - val_loss: 0.3307 - val_accuracy: 0.9030\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.33428 to 0.33067, saving model to vgg_model.h5\n",
      "Epoch 47/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2810 - accuracy: 0.9203 - val_loss: 0.3314 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.33067\n",
      "Epoch 48/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2761 - accuracy: 0.9252 - val_loss: 0.3325 - val_accuracy: 0.8979\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.33067\n",
      "Epoch 49/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2641 - accuracy: 0.9265 - val_loss: 0.3336 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33067\n",
      "Epoch 50/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2763 - accuracy: 0.9215 - val_loss: 0.3278 - val_accuracy: 0.9032\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33067 to 0.32779, saving model to vgg_model.h5\n",
      "Epoch 51/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2699 - accuracy: 0.9238 - val_loss: 0.3369 - val_accuracy: 0.9003\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.32779\n",
      "Epoch 52/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2691 - accuracy: 0.9247 - val_loss: 0.3239 - val_accuracy: 0.9035\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.32779 to 0.32394, saving model to vgg_model.h5\n",
      "Epoch 53/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2680 - accuracy: 0.9230 - val_loss: 0.3244 - val_accuracy: 0.9037\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32394\n",
      "Epoch 54/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2619 - accuracy: 0.9267 - val_loss: 0.3210 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.32394 to 0.32103, saving model to vgg_model.h5\n",
      "Epoch 55/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2607 - accuracy: 0.9261 - val_loss: 0.3230 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.32103\n",
      "Epoch 56/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2608 - accuracy: 0.9270 - val_loss: 0.3201 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.32103 to 0.32012, saving model to vgg_model.h5\n",
      "Epoch 57/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2576 - accuracy: 0.9296 - val_loss: 0.3218 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32012\n",
      "Epoch 58/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2514 - accuracy: 0.9322 - val_loss: 0.3162 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.32012 to 0.31624, saving model to vgg_model.h5\n",
      "Epoch 59/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2533 - accuracy: 0.9316 - val_loss: 0.3128 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.31624 to 0.31284, saving model to vgg_model.h5\n",
      "Epoch 60/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2518 - accuracy: 0.9285 - val_loss: 0.3180 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.31284\n",
      "Epoch 61/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2518 - accuracy: 0.9296 - val_loss: 0.3100 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.31284 to 0.30998, saving model to vgg_model.h5\n",
      "Epoch 62/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2645 - accuracy: 0.9262 - val_loss: 0.3119 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.30998\n",
      "Epoch 63/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2478 - accuracy: 0.9312 - val_loss: 0.3088 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.30998 to 0.30881, saving model to vgg_model.h5\n",
      "Epoch 64/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2445 - accuracy: 0.9318 - val_loss: 0.3118 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.30881\n",
      "Epoch 65/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2430 - accuracy: 0.9344 - val_loss: 0.3100 - val_accuracy: 0.9050\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.30881\n",
      "Epoch 66/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2399 - accuracy: 0.9347 - val_loss: 0.3102 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.30881\n",
      "Epoch 67/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2342 - accuracy: 0.9335 - val_loss: 0.3132 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.30881\n",
      "Epoch 68/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2434 - accuracy: 0.9303 - val_loss: 0.3146 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.30881\n",
      "Epoch 69/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2378 - accuracy: 0.9315 - val_loss: 0.3050 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.30881 to 0.30495, saving model to vgg_model.h5\n",
      "Epoch 70/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2389 - accuracy: 0.9318 - val_loss: 0.3185 - val_accuracy: 0.9023\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.30495\n",
      "Epoch 71/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2430 - accuracy: 0.9300 - val_loss: 0.3083 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.30495\n",
      "Epoch 72/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2416 - accuracy: 0.9328 - val_loss: 0.3041 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.30495 to 0.30408, saving model to vgg_model.h5\n",
      "Epoch 73/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2441 - accuracy: 0.9324 - val_loss: 0.3122 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.30408\n",
      "Epoch 74/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2305 - accuracy: 0.9371 - val_loss: 0.3009 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.30408 to 0.30092, saving model to vgg_model.h5\n",
      "Epoch 75/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2366 - accuracy: 0.9344 - val_loss: 0.3057 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.30092\n",
      "Epoch 76/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2416 - accuracy: 0.9358 - val_loss: 0.3067 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.30092\n",
      "Epoch 77/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2346 - accuracy: 0.9353 - val_loss: 0.3019 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.30092\n",
      "Epoch 78/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2385 - accuracy: 0.9338 - val_loss: 0.2992 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.30092 to 0.29925, saving model to vgg_model.h5\n",
      "Epoch 79/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2204 - accuracy: 0.9409 - val_loss: 0.2996 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.29925\n",
      "Epoch 80/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2335 - accuracy: 0.9356 - val_loss: 0.2999 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.29925\n",
      "Epoch 81/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2246 - accuracy: 0.9367 - val_loss: 0.2971 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.29925 to 0.29705, saving model to vgg_model.h5\n",
      "Epoch 82/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2308 - accuracy: 0.9363 - val_loss: 0.2967 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.29705 to 0.29667, saving model to vgg_model.h5\n",
      "Epoch 83/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2203 - accuracy: 0.9385 - val_loss: 0.2997 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.29667\n",
      "Epoch 84/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2247 - accuracy: 0.9373 - val_loss: 0.2959 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.29667 to 0.29589, saving model to vgg_model.h5\n",
      "Epoch 85/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2273 - accuracy: 0.9355 - val_loss: 0.2979 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.29589\n",
      "Epoch 86/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2222 - accuracy: 0.9413 - val_loss: 0.2970 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.29589\n",
      "Epoch 87/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2256 - accuracy: 0.9357 - val_loss: 0.2981 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.29589\n",
      "Epoch 88/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2172 - accuracy: 0.9406 - val_loss: 0.2989 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.29589\n",
      "Epoch 89/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2192 - accuracy: 0.9392 - val_loss: 0.2928 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.29589 to 0.29275, saving model to vgg_model.h5\n",
      "Epoch 90/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2207 - accuracy: 0.9373 - val_loss: 0.2968 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.29275\n",
      "Epoch 91/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2230 - accuracy: 0.9384 - val_loss: 0.2944 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.29275\n",
      "Epoch 92/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2240 - accuracy: 0.9384 - val_loss: 0.2999 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.29275\n",
      "Epoch 93/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2232 - accuracy: 0.9379 - val_loss: 0.2965 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.29275\n",
      "Epoch 94/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2148 - accuracy: 0.9404 - val_loss: 0.2946 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.29275\n",
      "Epoch 95/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2208 - accuracy: 0.9392 - val_loss: 0.2962 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.29275\n",
      "Epoch 96/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2176 - accuracy: 0.9401 - val_loss: 0.2930 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.29275\n",
      "Epoch 97/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2166 - accuracy: 0.9394 - val_loss: 0.2937 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.29275\n",
      "Epoch 98/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2191 - accuracy: 0.9381 - val_loss: 0.2934 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.29275\n",
      "Epoch 99/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2162 - accuracy: 0.9416 - val_loss: 0.2912 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.29275 to 0.29124, saving model to vgg_model.h5\n",
      "Epoch 100/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2228 - accuracy: 0.9376 - val_loss: 0.2939 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.29124\n",
      "Epoch 101/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2146 - accuracy: 0.9392 - val_loss: 0.2938 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.29124\n",
      "Epoch 102/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2098 - accuracy: 0.9403 - val_loss: 0.2980 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.29124\n",
      "Epoch 103/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2197 - accuracy: 0.9387 - val_loss: 0.2958 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.29124\n",
      "Epoch 104/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2062 - accuracy: 0.9442 - val_loss: 0.2907 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.29124 to 0.29067, saving model to vgg_model.h5\n",
      "Epoch 105/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2065 - accuracy: 0.9435 - val_loss: 0.2898 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.29067 to 0.28975, saving model to vgg_model.h5\n",
      "Epoch 106/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2081 - accuracy: 0.9418 - val_loss: 0.2921 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.28975\n",
      "Epoch 107/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2050 - accuracy: 0.9441 - val_loss: 0.2910 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.28975\n",
      "Epoch 108/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2125 - accuracy: 0.9432 - val_loss: 0.2916 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.28975\n",
      "Epoch 109/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2069 - accuracy: 0.9434 - val_loss: 0.2906 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.28975\n",
      "Epoch 110/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2080 - accuracy: 0.9442 - val_loss: 0.2932 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.28975\n",
      "Epoch 111/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2041 - accuracy: 0.9440 - val_loss: 0.2882 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.28975 to 0.28823, saving model to vgg_model.h5\n",
      "Epoch 112/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2089 - accuracy: 0.9428 - val_loss: 0.2864 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.28823 to 0.28638, saving model to vgg_model.h5\n",
      "Epoch 113/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2065 - accuracy: 0.9410 - val_loss: 0.2902 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.28638\n",
      "Epoch 114/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1981 - accuracy: 0.9444 - val_loss: 0.2880 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.28638\n",
      "Epoch 115/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2098 - accuracy: 0.9378 - val_loss: 0.2944 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.28638\n",
      "Epoch 116/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2046 - accuracy: 0.9436 - val_loss: 0.2887 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.28638\n",
      "Epoch 117/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2037 - accuracy: 0.9427 - val_loss: 0.2859 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.28638 to 0.28595, saving model to vgg_model.h5\n",
      "Epoch 118/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2042 - accuracy: 0.9432 - val_loss: 0.2962 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.28595\n",
      "Epoch 119/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2022 - accuracy: 0.9428 - val_loss: 0.2854 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.28595 to 0.28544, saving model to vgg_model.h5\n",
      "Epoch 120/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2019 - accuracy: 0.9455 - val_loss: 0.2922 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.28544\n",
      "Epoch 121/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2067 - accuracy: 0.9431 - val_loss: 0.2946 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.28544\n",
      "Epoch 122/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2025 - accuracy: 0.9442 - val_loss: 0.2899 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.28544\n",
      "Epoch 123/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2040 - accuracy: 0.9441 - val_loss: 0.2910 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.28544\n",
      "Epoch 124/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1946 - accuracy: 0.9470 - val_loss: 0.2876 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.28544\n",
      "Epoch 125/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2018 - accuracy: 0.9446 - val_loss: 0.2874 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.28544\n",
      "Epoch 126/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2030 - accuracy: 0.9442 - val_loss: 0.2987 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.28544\n",
      "Epoch 127/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1929 - accuracy: 0.9482 - val_loss: 0.2949 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.28544\n",
      "Epoch 128/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1992 - accuracy: 0.9456 - val_loss: 0.2879 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.28544\n",
      "Epoch 129/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2021 - accuracy: 0.9426 - val_loss: 0.2877 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.28544\n",
      "Epoch 130/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1929 - accuracy: 0.9458 - val_loss: 0.2862 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.28544\n",
      "Epoch 131/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1970 - accuracy: 0.9444 - val_loss: 0.2856 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.28544\n",
      "Epoch 132/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2009 - accuracy: 0.9445 - val_loss: 0.2866 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.28544\n",
      "Epoch 133/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2005 - accuracy: 0.9443 - val_loss: 0.2865 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.28544\n",
      "Epoch 134/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1988 - accuracy: 0.9458 - val_loss: 0.2944 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.28544\n",
      "Epoch 135/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1922 - accuracy: 0.9463 - val_loss: 0.2958 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.28544\n",
      "Epoch 136/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1978 - accuracy: 0.9443 - val_loss: 0.2883 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.28544\n",
      "Epoch 137/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.2004 - accuracy: 0.9447 - val_loss: 0.2910 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.28544\n",
      "Epoch 138/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1909 - accuracy: 0.9463 - val_loss: 0.2890 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.28544\n",
      "Epoch 139/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1912 - accuracy: 0.9472 - val_loss: 0.2845 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.28544 to 0.28447, saving model to vgg_model.h5\n",
      "Epoch 140/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1922 - accuracy: 0.9446 - val_loss: 0.2867 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.28447\n",
      "Epoch 141/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1934 - accuracy: 0.9483 - val_loss: 0.2873 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.28447\n",
      "Epoch 142/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1986 - accuracy: 0.9451 - val_loss: 0.2891 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.28447\n",
      "Epoch 143/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1955 - accuracy: 0.9464 - val_loss: 0.2876 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.28447\n",
      "Epoch 144/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1823 - accuracy: 0.9500 - val_loss: 0.2886 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.28447\n",
      "Epoch 145/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1857 - accuracy: 0.9468 - val_loss: 0.2999 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.28447\n",
      "Epoch 146/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1980 - accuracy: 0.9454 - val_loss: 0.2876 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.28447\n",
      "Epoch 147/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1893 - accuracy: 0.9468 - val_loss: 0.2863 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.28447\n",
      "Epoch 148/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1889 - accuracy: 0.9470 - val_loss: 0.2880 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.28447\n",
      "Epoch 149/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1952 - accuracy: 0.9444 - val_loss: 0.2855 - val_accuracy: 0.9193\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.28447\n",
      "Epoch 150/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1939 - accuracy: 0.9478 - val_loss: 0.2854 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.28447\n",
      "Epoch 151/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1884 - accuracy: 0.9474 - val_loss: 0.2910 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.28447\n",
      "Epoch 152/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1935 - accuracy: 0.9456 - val_loss: 0.2882 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.28447\n",
      "Epoch 153/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1970 - accuracy: 0.9478 - val_loss: 0.2844 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.28447 to 0.28437, saving model to vgg_model.h5\n",
      "Epoch 154/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1897 - accuracy: 0.9477 - val_loss: 0.2910 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.28437\n",
      "Epoch 155/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1942 - accuracy: 0.9458 - val_loss: 0.2935 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.28437\n",
      "Epoch 156/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1926 - accuracy: 0.9459 - val_loss: 0.2912 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.28437\n",
      "Epoch 157/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1866 - accuracy: 0.9489 - val_loss: 0.2877 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.28437\n",
      "Epoch 158/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1911 - accuracy: 0.9457 - val_loss: 0.2895 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.28437\n",
      "Epoch 159/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1830 - accuracy: 0.9473 - val_loss: 0.2877 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.28437\n",
      "Epoch 160/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1853 - accuracy: 0.9475 - val_loss: 0.2947 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.28437\n",
      "Epoch 161/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1789 - accuracy: 0.9491 - val_loss: 0.2929 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.28437\n",
      "Epoch 162/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1871 - accuracy: 0.9482 - val_loss: 0.2866 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.28437\n",
      "Epoch 163/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1879 - accuracy: 0.9485 - val_loss: 0.2872 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.28437\n",
      "Epoch 164/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1853 - accuracy: 0.9483 - val_loss: 0.2938 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.28437\n",
      "Epoch 165/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1908 - accuracy: 0.9490 - val_loss: 0.2848 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.28437\n",
      "Epoch 166/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1926 - accuracy: 0.9463 - val_loss: 0.2923 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.28437\n",
      "Epoch 167/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1873 - accuracy: 0.9466 - val_loss: 0.2910 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.28437\n",
      "Epoch 168/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1893 - accuracy: 0.9484 - val_loss: 0.2902 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.28437\n",
      "Epoch 169/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1774 - accuracy: 0.9511 - val_loss: 0.2871 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.28437\n",
      "Epoch 170/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1828 - accuracy: 0.9472 - val_loss: 0.2889 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.28437\n",
      "Epoch 171/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1918 - accuracy: 0.9457 - val_loss: 0.2877 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.28437\n",
      "Epoch 172/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1920 - accuracy: 0.9465 - val_loss: 0.2880 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.28437\n",
      "Epoch 173/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1809 - accuracy: 0.9495 - val_loss: 0.2907 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.28437\n",
      "Epoch 174/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1909 - accuracy: 0.9479 - val_loss: 0.2909 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.28437\n",
      "Epoch 175/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1933 - accuracy: 0.9470 - val_loss: 0.2860 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.28437\n",
      "Epoch 176/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1913 - accuracy: 0.9479 - val_loss: 0.2871 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.28437\n",
      "Epoch 177/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1783 - accuracy: 0.9508 - val_loss: 0.2851 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.28437\n",
      "Epoch 178/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1835 - accuracy: 0.9484 - val_loss: 0.2899 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.28437\n",
      "Epoch 179/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1838 - accuracy: 0.9512 - val_loss: 0.2890 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.28437\n",
      "Epoch 180/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1742 - accuracy: 0.9497 - val_loss: 0.2894 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.28437\n",
      "Epoch 181/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1792 - accuracy: 0.9497 - val_loss: 0.2923 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.28437\n",
      "Epoch 182/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1783 - accuracy: 0.9522 - val_loss: 0.2899 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.28437\n",
      "Epoch 183/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1849 - accuracy: 0.9465 - val_loss: 0.2874 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.28437\n",
      "Epoch 184/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1859 - accuracy: 0.9505 - val_loss: 0.2926 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.28437\n",
      "Epoch 185/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1736 - accuracy: 0.9520 - val_loss: 0.2931 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.28437\n",
      "Epoch 186/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1737 - accuracy: 0.9528 - val_loss: 0.2900 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.28437\n",
      "Epoch 187/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1778 - accuracy: 0.9511 - val_loss: 0.2869 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.28437\n",
      "Epoch 188/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1866 - accuracy: 0.9509 - val_loss: 0.2887 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.28437\n",
      "Epoch 189/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1749 - accuracy: 0.9507 - val_loss: 0.2916 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.28437\n",
      "Epoch 190/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1854 - accuracy: 0.9479 - val_loss: 0.2924 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.28437\n",
      "Epoch 191/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1812 - accuracy: 0.9506 - val_loss: 0.2904 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.28437\n",
      "Epoch 192/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1885 - accuracy: 0.9474 - val_loss: 0.2890 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.28437\n",
      "Epoch 193/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1795 - accuracy: 0.9490 - val_loss: 0.2856 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.28437\n",
      "Epoch 194/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1764 - accuracy: 0.9496 - val_loss: 0.2962 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.28437\n",
      "Epoch 195/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1778 - accuracy: 0.9500 - val_loss: 0.2890 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.28437\n",
      "Epoch 196/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1818 - accuracy: 0.9485 - val_loss: 0.2861 - val_accuracy: 0.9188\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.28437\n",
      "Epoch 197/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1809 - accuracy: 0.9496 - val_loss: 0.2887 - val_accuracy: 0.9186\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.28437\n",
      "Epoch 198/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1877 - accuracy: 0.9503 - val_loss: 0.2875 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.28437\n",
      "Epoch 199/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1778 - accuracy: 0.9525 - val_loss: 0.2935 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.28437\n",
      "Epoch 200/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1823 - accuracy: 0.9500 - val_loss: 0.2908 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.28437\n",
      "Epoch 201/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1713 - accuracy: 0.9514 - val_loss: 0.2960 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.28437\n",
      "Epoch 202/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1838 - accuracy: 0.9492 - val_loss: 0.2983 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.28437\n",
      "Epoch 203/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1893 - accuracy: 0.9510 - val_loss: 0.2931 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.28437\n",
      "Epoch 204/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1758 - accuracy: 0.9512 - val_loss: 0.2890 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.28437\n",
      "Epoch 205/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1817 - accuracy: 0.9491 - val_loss: 0.2964 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.28437\n",
      "Epoch 206/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1788 - accuracy: 0.9496 - val_loss: 0.2962 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.28437\n",
      "Epoch 207/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1823 - accuracy: 0.9499 - val_loss: 0.2900 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.28437\n",
      "Epoch 208/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1805 - accuracy: 0.9514 - val_loss: 0.2970 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.28437\n",
      "Epoch 209/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1780 - accuracy: 0.9495 - val_loss: 0.2919 - val_accuracy: 0.9175\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.28437\n",
      "Epoch 210/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1775 - accuracy: 0.9487 - val_loss: 0.2971 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.28437\n",
      "Epoch 211/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1716 - accuracy: 0.9523 - val_loss: 0.2932 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.28437\n",
      "Epoch 212/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1714 - accuracy: 0.9533 - val_loss: 0.2966 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.28437\n",
      "Epoch 213/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1657 - accuracy: 0.9513 - val_loss: 0.2899 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.28437\n",
      "Epoch 214/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1778 - accuracy: 0.9519 - val_loss: 0.2932 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.28437\n",
      "Epoch 215/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1726 - accuracy: 0.9509 - val_loss: 0.2948 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.28437\n",
      "Epoch 216/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1709 - accuracy: 0.9525 - val_loss: 0.2908 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.28437\n",
      "Epoch 217/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1789 - accuracy: 0.9506 - val_loss: 0.2963 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.28437\n",
      "Epoch 218/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1768 - accuracy: 0.9502 - val_loss: 0.2973 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.28437\n",
      "Epoch 219/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1737 - accuracy: 0.9518 - val_loss: 0.2951 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.28437\n",
      "Epoch 220/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1707 - accuracy: 0.9509 - val_loss: 0.2985 - val_accuracy: 0.9166\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.28437\n",
      "Epoch 221/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1834 - accuracy: 0.9502 - val_loss: 0.2935 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.28437\n",
      "Epoch 222/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1790 - accuracy: 0.9515 - val_loss: 0.2972 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.28437\n",
      "Epoch 223/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1753 - accuracy: 0.9511 - val_loss: 0.2928 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.28437\n",
      "Epoch 224/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1800 - accuracy: 0.9481 - val_loss: 0.2959 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.28437\n",
      "Epoch 225/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1753 - accuracy: 0.9513 - val_loss: 0.2963 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.28437\n",
      "Epoch 226/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1674 - accuracy: 0.9545 - val_loss: 0.2938 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.28437\n",
      "Epoch 227/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1825 - accuracy: 0.9505 - val_loss: 0.2983 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.28437\n",
      "Epoch 228/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1744 - accuracy: 0.9539 - val_loss: 0.2974 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.28437\n",
      "Epoch 229/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1696 - accuracy: 0.9503 - val_loss: 0.2942 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.28437\n",
      "Epoch 230/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1718 - accuracy: 0.9534 - val_loss: 0.2980 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.28437\n",
      "Epoch 231/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1664 - accuracy: 0.9552 - val_loss: 0.2988 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.28437\n",
      "Epoch 232/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1614 - accuracy: 0.9565 - val_loss: 0.2966 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.28437\n",
      "Epoch 233/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1808 - accuracy: 0.9502 - val_loss: 0.2946 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.28437\n",
      "Epoch 234/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1737 - accuracy: 0.9518 - val_loss: 0.2973 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.28437\n",
      "Epoch 235/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1758 - accuracy: 0.9510 - val_loss: 0.2989 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.28437\n",
      "Epoch 236/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1767 - accuracy: 0.9495 - val_loss: 0.2984 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.28437\n",
      "Epoch 237/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1698 - accuracy: 0.9546 - val_loss: 0.3003 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.28437\n",
      "Epoch 238/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1735 - accuracy: 0.9514 - val_loss: 0.2990 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.28437\n",
      "Epoch 239/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1705 - accuracy: 0.9513 - val_loss: 0.2956 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.28437\n",
      "Epoch 240/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1633 - accuracy: 0.9544 - val_loss: 0.2991 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.28437\n",
      "Epoch 241/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1705 - accuracy: 0.9522 - val_loss: 0.2975 - val_accuracy: 0.9162\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.28437\n",
      "Epoch 242/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1737 - accuracy: 0.9535 - val_loss: 0.2983 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.28437\n",
      "Epoch 243/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1772 - accuracy: 0.9513 - val_loss: 0.2996 - val_accuracy: 0.9177\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.28437\n",
      "Epoch 244/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1727 - accuracy: 0.9509 - val_loss: 0.2971 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.28437\n",
      "Epoch 245/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1721 - accuracy: 0.9542 - val_loss: 0.3042 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.28437\n",
      "Epoch 246/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1715 - accuracy: 0.9511 - val_loss: 0.3002 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.28437\n",
      "Epoch 247/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1803 - accuracy: 0.9527 - val_loss: 0.3029 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.28437\n",
      "Epoch 248/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1726 - accuracy: 0.9559 - val_loss: 0.3042 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.28437\n",
      "Epoch 249/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1674 - accuracy: 0.9543 - val_loss: 0.2968 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.28437\n",
      "Epoch 250/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1697 - accuracy: 0.9514 - val_loss: 0.2990 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.28437\n",
      "Epoch 251/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1661 - accuracy: 0.9539 - val_loss: 0.3057 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.28437\n",
      "Epoch 252/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1658 - accuracy: 0.9541 - val_loss: 0.2994 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.28437\n",
      "Epoch 253/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1745 - accuracy: 0.9500 - val_loss: 0.2985 - val_accuracy: 0.9179\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.28437\n",
      "Epoch 254/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1692 - accuracy: 0.9525 - val_loss: 0.3017 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.28437\n",
      "Epoch 255/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1685 - accuracy: 0.9512 - val_loss: 0.3009 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.28437\n",
      "Epoch 256/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1702 - accuracy: 0.9533 - val_loss: 0.3004 - val_accuracy: 0.9173\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.28437\n",
      "Epoch 257/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1711 - accuracy: 0.9527 - val_loss: 0.3085 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.28437\n",
      "Epoch 258/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1685 - accuracy: 0.9540 - val_loss: 0.3020 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.28437\n",
      "Epoch 259/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1698 - accuracy: 0.9537 - val_loss: 0.3086 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.28437\n",
      "Epoch 260/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1881 - accuracy: 0.9495 - val_loss: 0.3051 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.28437\n",
      "Epoch 261/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9495 - val_loss: 0.3030 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.28437\n",
      "Epoch 262/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1684 - accuracy: 0.9524 - val_loss: 0.3020 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.28437\n",
      "Epoch 263/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1778 - accuracy: 0.9502 - val_loss: 0.3117 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.28437\n",
      "Epoch 264/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1666 - accuracy: 0.9523 - val_loss: 0.3027 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.28437\n",
      "Epoch 265/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1755 - accuracy: 0.9509 - val_loss: 0.3093 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.28437\n",
      "Epoch 266/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1728 - accuracy: 0.9507 - val_loss: 0.3058 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.28437\n",
      "Epoch 267/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1735 - accuracy: 0.9540 - val_loss: 0.3006 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.28437\n",
      "Epoch 268/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1746 - accuracy: 0.9532 - val_loss: 0.3089 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.28437\n",
      "Epoch 269/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1627 - accuracy: 0.9550 - val_loss: 0.3069 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.28437\n",
      "Epoch 270/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9557 - val_loss: 0.3074 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.28437\n",
      "Epoch 271/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1709 - accuracy: 0.9555 - val_loss: 0.3045 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.28437\n",
      "Epoch 272/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1660 - accuracy: 0.9516 - val_loss: 0.3004 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.28437\n",
      "Epoch 273/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1652 - accuracy: 0.9554 - val_loss: 0.3018 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.28437\n",
      "Epoch 274/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1737 - accuracy: 0.9521 - val_loss: 0.2991 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.28437\n",
      "Epoch 275/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1619 - accuracy: 0.9547 - val_loss: 0.3028 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.28437\n",
      "Epoch 276/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1741 - accuracy: 0.9511 - val_loss: 0.3014 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.28437\n",
      "Epoch 277/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1667 - accuracy: 0.9542 - val_loss: 0.3092 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.28437\n",
      "Epoch 278/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1717 - accuracy: 0.9514 - val_loss: 0.3060 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.28437\n",
      "Epoch 279/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1708 - accuracy: 0.9535 - val_loss: 0.3057 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.28437\n",
      "Epoch 280/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1672 - accuracy: 0.9545 - val_loss: 0.3047 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.28437\n",
      "Epoch 281/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9547 - val_loss: 0.3028 - val_accuracy: 0.9157\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.28437\n",
      "Epoch 282/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1786 - accuracy: 0.9508 - val_loss: 0.3045 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.28437\n",
      "Epoch 283/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1746 - accuracy: 0.9523 - val_loss: 0.3057 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.28437\n",
      "Epoch 284/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1687 - accuracy: 0.9517 - val_loss: 0.3070 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.28437\n",
      "Epoch 285/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1725 - accuracy: 0.9534 - val_loss: 0.3148 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.28437\n",
      "Epoch 286/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1722 - accuracy: 0.9519 - val_loss: 0.3063 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.28437\n",
      "Epoch 287/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1672 - accuracy: 0.9521 - val_loss: 0.3030 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.28437\n",
      "Epoch 288/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1642 - accuracy: 0.9541 - val_loss: 0.3089 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.28437\n",
      "Epoch 289/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9567 - val_loss: 0.3084 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.28437\n",
      "Epoch 290/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1742 - accuracy: 0.9521 - val_loss: 0.3052 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.28437\n",
      "Epoch 291/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1759 - accuracy: 0.9528 - val_loss: 0.3046 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.28437\n",
      "Epoch 292/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9517 - val_loss: 0.3094 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.28437\n",
      "Epoch 293/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1759 - accuracy: 0.9548 - val_loss: 0.3109 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.28437\n",
      "Epoch 294/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1737 - accuracy: 0.9543 - val_loss: 0.3106 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.28437\n",
      "Epoch 295/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1685 - accuracy: 0.9518 - val_loss: 0.3097 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.28437\n",
      "Epoch 296/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1737 - accuracy: 0.9532 - val_loss: 0.3058 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.28437\n",
      "Epoch 297/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1655 - accuracy: 0.9536 - val_loss: 0.3076 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.28437\n",
      "Epoch 298/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1628 - accuracy: 0.9535 - val_loss: 0.3103 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.28437\n",
      "Epoch 299/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1694 - accuracy: 0.9533 - val_loss: 0.3092 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.28437\n",
      "Epoch 300/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1648 - accuracy: 0.9542 - val_loss: 0.3086 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.28437\n",
      "Epoch 301/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1745 - accuracy: 0.9545 - val_loss: 0.3080 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.28437\n",
      "Epoch 302/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1593 - accuracy: 0.9534 - val_loss: 0.3130 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.28437\n",
      "Epoch 303/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1623 - accuracy: 0.9555 - val_loss: 0.3135 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.28437\n",
      "Epoch 304/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1712 - accuracy: 0.9512 - val_loss: 0.3111 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.28437\n",
      "Epoch 305/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1680 - accuracy: 0.9536 - val_loss: 0.3092 - val_accuracy: 0.9159\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.28437\n",
      "Epoch 306/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1573 - accuracy: 0.9562 - val_loss: 0.3089 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.28437\n",
      "Epoch 307/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1615 - accuracy: 0.9535 - val_loss: 0.3212 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.28437\n",
      "Epoch 308/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1645 - accuracy: 0.9547 - val_loss: 0.3100 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.28437\n",
      "Epoch 309/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1653 - accuracy: 0.9539 - val_loss: 0.3128 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.28437\n",
      "Epoch 310/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1757 - accuracy: 0.9532 - val_loss: 0.3189 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.28437\n",
      "Epoch 311/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1722 - accuracy: 0.9525 - val_loss: 0.3136 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.28437\n",
      "Epoch 312/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1757 - accuracy: 0.9532 - val_loss: 0.3076 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.28437\n",
      "Epoch 313/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1589 - accuracy: 0.9549 - val_loss: 0.3164 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.28437\n",
      "Epoch 314/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1674 - accuracy: 0.9538 - val_loss: 0.3190 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.28437\n",
      "Epoch 315/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1691 - accuracy: 0.9546 - val_loss: 0.3106 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.28437\n",
      "Epoch 316/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9560 - val_loss: 0.3113 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.28437\n",
      "Epoch 317/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1645 - accuracy: 0.9546 - val_loss: 0.3129 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.28437\n",
      "Epoch 318/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1640 - accuracy: 0.9556 - val_loss: 0.3079 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.28437\n",
      "Epoch 319/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1798 - accuracy: 0.9497 - val_loss: 0.3097 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.28437\n",
      "Epoch 320/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1565 - accuracy: 0.9546 - val_loss: 0.3104 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.28437\n",
      "Epoch 321/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9556 - val_loss: 0.3152 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.28437\n",
      "Epoch 322/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1711 - accuracy: 0.9527 - val_loss: 0.3130 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.28437\n",
      "Epoch 323/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1642 - accuracy: 0.9562 - val_loss: 0.3179 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.28437\n",
      "Epoch 324/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1775 - accuracy: 0.9529 - val_loss: 0.3135 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.28437\n",
      "Epoch 325/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1663 - accuracy: 0.9560 - val_loss: 0.3132 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.28437\n",
      "Epoch 326/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1635 - accuracy: 0.9561 - val_loss: 0.3185 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.28437\n",
      "Epoch 327/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1652 - accuracy: 0.9566 - val_loss: 0.3237 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.28437\n",
      "Epoch 328/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1622 - accuracy: 0.9552 - val_loss: 0.3130 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.28437\n",
      "Epoch 329/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1820 - accuracy: 0.9488 - val_loss: 0.3138 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.28437\n",
      "Epoch 330/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1643 - accuracy: 0.9543 - val_loss: 0.3229 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.28437\n",
      "Epoch 331/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1603 - accuracy: 0.9555 - val_loss: 0.3151 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.28437\n",
      "Epoch 332/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1746 - accuracy: 0.9547 - val_loss: 0.3151 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.28437\n",
      "Epoch 333/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1697 - accuracy: 0.9552 - val_loss: 0.3148 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.28437\n",
      "Epoch 334/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1745 - accuracy: 0.9531 - val_loss: 0.3192 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.28437\n",
      "Epoch 335/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1736 - accuracy: 0.9511 - val_loss: 0.3155 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.28437\n",
      "Epoch 336/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1727 - accuracy: 0.9511 - val_loss: 0.3143 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.28437\n",
      "Epoch 337/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1739 - accuracy: 0.9545 - val_loss: 0.3178 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.28437\n",
      "Epoch 338/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1668 - accuracy: 0.9544 - val_loss: 0.3170 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.28437\n",
      "Epoch 339/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1622 - accuracy: 0.9566 - val_loss: 0.3201 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.28437\n",
      "Epoch 340/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1644 - accuracy: 0.9567 - val_loss: 0.3173 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.28437\n",
      "Epoch 341/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1601 - accuracy: 0.9566 - val_loss: 0.3166 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.28437\n",
      "Epoch 342/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1696 - accuracy: 0.9535 - val_loss: 0.3193 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.28437\n",
      "Epoch 343/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1755 - accuracy: 0.9528 - val_loss: 0.3198 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.28437\n",
      "Epoch 344/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1637 - accuracy: 0.9560 - val_loss: 0.3189 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.28437\n",
      "Epoch 345/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1818 - accuracy: 0.9514 - val_loss: 0.3202 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.28437\n",
      "Epoch 346/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1693 - accuracy: 0.9521 - val_loss: 0.3176 - val_accuracy: 0.9164\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.28437\n",
      "Epoch 347/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1635 - accuracy: 0.9555 - val_loss: 0.3186 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.28437\n",
      "Epoch 348/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1757 - accuracy: 0.9528 - val_loss: 0.3214 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.28437\n",
      "Epoch 349/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1660 - accuracy: 0.9530 - val_loss: 0.3265 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.28437\n",
      "Epoch 350/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1637 - accuracy: 0.9547 - val_loss: 0.3185 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.28437\n",
      "Epoch 351/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1649 - accuracy: 0.9552 - val_loss: 0.3213 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.28437\n",
      "Epoch 352/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1664 - accuracy: 0.9563 - val_loss: 0.3212 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.28437\n",
      "Epoch 353/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1633 - accuracy: 0.9547 - val_loss: 0.3245 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.28437\n",
      "Epoch 354/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1641 - accuracy: 0.9568 - val_loss: 0.3218 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.28437\n",
      "Epoch 355/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1702 - accuracy: 0.9533 - val_loss: 0.3182 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.28437\n",
      "Epoch 356/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1647 - accuracy: 0.9563 - val_loss: 0.3217 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.28437\n",
      "Epoch 357/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1799 - accuracy: 0.9521 - val_loss: 0.3223 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.28437\n",
      "Epoch 358/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1650 - accuracy: 0.9562 - val_loss: 0.3307 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.28437\n",
      "Epoch 359/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1675 - accuracy: 0.9556 - val_loss: 0.3208 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.28437\n",
      "Epoch 360/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1660 - accuracy: 0.9561 - val_loss: 0.3225 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.28437\n",
      "Epoch 361/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1614 - accuracy: 0.9547 - val_loss: 0.3273 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.28437\n",
      "Epoch 362/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9549 - val_loss: 0.3250 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.28437\n",
      "Epoch 363/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1638 - accuracy: 0.9568 - val_loss: 0.3248 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.28437\n",
      "Epoch 364/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1663 - accuracy: 0.9575 - val_loss: 0.3318 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.28437\n",
      "Epoch 365/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1731 - accuracy: 0.9558 - val_loss: 0.3238 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.28437\n",
      "Epoch 366/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1646 - accuracy: 0.9548 - val_loss: 0.3372 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.28437\n",
      "Epoch 367/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1664 - accuracy: 0.9528 - val_loss: 0.3239 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.28437\n",
      "Epoch 368/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1689 - accuracy: 0.9513 - val_loss: 0.3237 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.28437\n",
      "Epoch 369/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1692 - accuracy: 0.9532 - val_loss: 0.3223 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.28437\n",
      "Epoch 370/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1671 - accuracy: 0.9561 - val_loss: 0.3269 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.28437\n",
      "Epoch 371/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1724 - accuracy: 0.9531 - val_loss: 0.3224 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.28437\n",
      "Epoch 372/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1582 - accuracy: 0.9560 - val_loss: 0.3233 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.28437\n",
      "Epoch 373/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1718 - accuracy: 0.9535 - val_loss: 0.3264 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.28437\n",
      "Epoch 374/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1570 - accuracy: 0.9590 - val_loss: 0.3258 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.28437\n",
      "Epoch 375/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1713 - accuracy: 0.9536 - val_loss: 0.3218 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.28437\n",
      "Epoch 376/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1859 - accuracy: 0.9517 - val_loss: 0.3313 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.28437\n",
      "Epoch 377/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1565 - accuracy: 0.9583 - val_loss: 0.3271 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.28437\n",
      "Epoch 378/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1581 - accuracy: 0.9574 - val_loss: 0.3241 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.28437\n",
      "Epoch 379/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1598 - accuracy: 0.9549 - val_loss: 0.3296 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.28437\n",
      "Epoch 380/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1729 - accuracy: 0.9562 - val_loss: 0.3248 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.28437\n",
      "Epoch 381/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1703 - accuracy: 0.9567 - val_loss: 0.3263 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.28437\n",
      "Epoch 382/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1576 - accuracy: 0.9570 - val_loss: 0.3269 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.28437\n",
      "Epoch 383/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1660 - accuracy: 0.9567 - val_loss: 0.3283 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.28437\n",
      "Epoch 384/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1749 - accuracy: 0.9536 - val_loss: 0.3307 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.28437\n",
      "Epoch 385/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1565 - accuracy: 0.9573 - val_loss: 0.3267 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.28437\n",
      "Epoch 386/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9546 - val_loss: 0.3292 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.28437\n",
      "Epoch 387/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1637 - accuracy: 0.9585 - val_loss: 0.3312 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.28437\n",
      "Epoch 388/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1593 - accuracy: 0.9561 - val_loss: 0.3271 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.28437\n",
      "Epoch 389/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1624 - accuracy: 0.9568 - val_loss: 0.3288 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.28437\n",
      "Epoch 390/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1545 - accuracy: 0.9548 - val_loss: 0.3277 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.28437\n",
      "Epoch 391/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1652 - accuracy: 0.9559 - val_loss: 0.3339 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.28437\n",
      "Epoch 392/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1743 - accuracy: 0.9569 - val_loss: 0.3286 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.28437\n",
      "Epoch 393/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1738 - accuracy: 0.9541 - val_loss: 0.3333 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.28437\n",
      "Epoch 394/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1678 - accuracy: 0.9559 - val_loss: 0.3282 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.28437\n",
      "Epoch 395/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1661 - accuracy: 0.9563 - val_loss: 0.3323 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.28437\n",
      "Epoch 396/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1706 - accuracy: 0.9535 - val_loss: 0.3287 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.28437\n",
      "Epoch 397/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1643 - accuracy: 0.9559 - val_loss: 0.3309 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.28437\n",
      "Epoch 398/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1654 - accuracy: 0.9533 - val_loss: 0.3343 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.28437\n",
      "Epoch 399/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1646 - accuracy: 0.9560 - val_loss: 0.3325 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.28437\n",
      "Epoch 400/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1657 - accuracy: 0.9534 - val_loss: 0.3383 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.28437\n",
      "Epoch 401/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1667 - accuracy: 0.9546 - val_loss: 0.3359 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.28437\n",
      "Epoch 402/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1690 - accuracy: 0.9548 - val_loss: 0.3322 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.28437\n",
      "Epoch 403/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1639 - accuracy: 0.9542 - val_loss: 0.3286 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.28437\n",
      "Epoch 404/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1665 - accuracy: 0.9553 - val_loss: 0.3297 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.28437\n",
      "Epoch 405/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1621 - accuracy: 0.9575 - val_loss: 0.3331 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.28437\n",
      "Epoch 406/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1719 - accuracy: 0.9546 - val_loss: 0.3332 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.28437\n",
      "Epoch 407/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1727 - accuracy: 0.9549 - val_loss: 0.3345 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.28437\n",
      "Epoch 408/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1675 - accuracy: 0.9529 - val_loss: 0.3327 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.28437\n",
      "Epoch 409/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1622 - accuracy: 0.9568 - val_loss: 0.3312 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.28437\n",
      "Epoch 410/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1706 - accuracy: 0.9566 - val_loss: 0.3340 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.28437\n",
      "Epoch 411/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1727 - accuracy: 0.9535 - val_loss: 0.3394 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.28437\n",
      "Epoch 412/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1647 - accuracy: 0.9563 - val_loss: 0.3343 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.28437\n",
      "Epoch 413/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1709 - accuracy: 0.9541 - val_loss: 0.3338 - val_accuracy: 0.9135\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.28437\n",
      "Epoch 414/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1604 - accuracy: 0.9555 - val_loss: 0.3361 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.28437\n",
      "Epoch 415/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1639 - accuracy: 0.9553 - val_loss: 0.3365 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.28437\n",
      "Epoch 416/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1718 - accuracy: 0.9538 - val_loss: 0.3341 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.28437\n",
      "Epoch 417/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1747 - accuracy: 0.9551 - val_loss: 0.3349 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.28437\n",
      "Epoch 418/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1727 - accuracy: 0.9539 - val_loss: 0.3361 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.28437\n",
      "Epoch 419/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1662 - accuracy: 0.9541 - val_loss: 0.3382 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.28437\n",
      "Epoch 420/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1612 - accuracy: 0.9562 - val_loss: 0.3359 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.28437\n",
      "Epoch 421/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1625 - accuracy: 0.9561 - val_loss: 0.3384 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.28437\n",
      "Epoch 422/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1648 - accuracy: 0.9540 - val_loss: 0.3349 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.28437\n",
      "Epoch 423/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1695 - accuracy: 0.9560 - val_loss: 0.3407 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.28437\n",
      "Epoch 424/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9580 - val_loss: 0.3433 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.28437\n",
      "Epoch 425/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1651 - accuracy: 0.9541 - val_loss: 0.3430 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.28437\n",
      "Epoch 426/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1611 - accuracy: 0.9560 - val_loss: 0.3420 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.28437\n",
      "Epoch 427/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1644 - accuracy: 0.9574 - val_loss: 0.3457 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.28437\n",
      "Epoch 428/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1652 - accuracy: 0.9565 - val_loss: 0.3402 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.28437\n",
      "Epoch 429/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1551 - accuracy: 0.9559 - val_loss: 0.3419 - val_accuracy: 0.9133\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.28437\n",
      "Epoch 430/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1710 - accuracy: 0.9558 - val_loss: 0.3440 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.28437\n",
      "Epoch 431/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1677 - accuracy: 0.9545 - val_loss: 0.3382 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.28437\n",
      "Epoch 432/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1608 - accuracy: 0.9592 - val_loss: 0.3393 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.28437\n",
      "Epoch 433/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1658 - accuracy: 0.9560 - val_loss: 0.3403 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.28437\n",
      "Epoch 434/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1706 - accuracy: 0.9519 - val_loss: 0.3369 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.28437\n",
      "Epoch 435/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1644 - accuracy: 0.9574 - val_loss: 0.3422 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.28437\n",
      "Epoch 436/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1660 - accuracy: 0.9550 - val_loss: 0.3457 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.28437\n",
      "Epoch 437/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1628 - accuracy: 0.9555 - val_loss: 0.3444 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.28437\n",
      "Epoch 438/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1733 - accuracy: 0.9533 - val_loss: 0.3485 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.28437\n",
      "Epoch 439/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1577 - accuracy: 0.9575 - val_loss: 0.3401 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.28437\n",
      "Epoch 440/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1665 - accuracy: 0.9562 - val_loss: 0.3419 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.28437\n",
      "Epoch 441/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9580 - val_loss: 0.3485 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.28437\n",
      "Epoch 442/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1618 - accuracy: 0.9577 - val_loss: 0.3598 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.28437\n",
      "Epoch 443/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9579 - val_loss: 0.3403 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.28437\n",
      "Epoch 444/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1572 - accuracy: 0.9560 - val_loss: 0.3434 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.28437\n",
      "Epoch 445/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1612 - accuracy: 0.9576 - val_loss: 0.3468 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.28437\n",
      "Epoch 446/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1626 - accuracy: 0.9560 - val_loss: 0.3464 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.28437\n",
      "Epoch 447/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1694 - accuracy: 0.9556 - val_loss: 0.3423 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.28437\n",
      "Epoch 448/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1699 - accuracy: 0.9544 - val_loss: 0.3414 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.28437\n",
      "Epoch 449/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1544 - accuracy: 0.9558 - val_loss: 0.3422 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.28437\n",
      "Epoch 450/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1732 - accuracy: 0.9558 - val_loss: 0.3457 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.28437\n",
      "Epoch 451/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1612 - accuracy: 0.9568 - val_loss: 0.3434 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.28437\n",
      "Epoch 452/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1695 - accuracy: 0.9546 - val_loss: 0.3436 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.28437\n",
      "Epoch 453/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1719 - accuracy: 0.9551 - val_loss: 0.3480 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.28437\n",
      "Epoch 454/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9549 - val_loss: 0.3473 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.28437\n",
      "Epoch 455/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1671 - accuracy: 0.9524 - val_loss: 0.3478 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.28437\n",
      "Epoch 456/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1661 - accuracy: 0.9570 - val_loss: 0.3501 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.28437\n",
      "Epoch 457/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1683 - accuracy: 0.9543 - val_loss: 0.3461 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.28437\n",
      "Epoch 458/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1637 - accuracy: 0.9555 - val_loss: 0.3440 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.28437\n",
      "Epoch 459/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1635 - accuracy: 0.9560 - val_loss: 0.3451 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.28437\n",
      "Epoch 460/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1539 - accuracy: 0.9583 - val_loss: 0.3486 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.28437\n",
      "Epoch 461/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1657 - accuracy: 0.9558 - val_loss: 0.3473 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.28437\n",
      "Epoch 462/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1681 - accuracy: 0.9558 - val_loss: 0.3542 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.28437\n",
      "Epoch 463/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1628 - accuracy: 0.9545 - val_loss: 0.3454 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.28437\n",
      "Epoch 464/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1710 - accuracy: 0.9543 - val_loss: 0.3508 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.28437\n",
      "Epoch 465/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1730 - accuracy: 0.9551 - val_loss: 0.3469 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.28437\n",
      "Epoch 466/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1620 - accuracy: 0.9561 - val_loss: 0.3526 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.28437\n",
      "Epoch 467/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1744 - accuracy: 0.9547 - val_loss: 0.3481 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.28437\n",
      "Epoch 468/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1682 - accuracy: 0.9562 - val_loss: 0.3494 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.28437\n",
      "Epoch 469/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1623 - accuracy: 0.9574 - val_loss: 0.3541 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.28437\n",
      "Epoch 470/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1613 - accuracy: 0.9582 - val_loss: 0.3486 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.28437\n",
      "Epoch 471/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1671 - accuracy: 0.9558 - val_loss: 0.3495 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.28437\n",
      "Epoch 472/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1648 - accuracy: 0.9556 - val_loss: 0.3502 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.28437\n",
      "Epoch 473/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1726 - accuracy: 0.9565 - val_loss: 0.3496 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.28437\n",
      "Epoch 474/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1601 - accuracy: 0.9586 - val_loss: 0.3525 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.28437\n",
      "Epoch 475/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1594 - accuracy: 0.9574 - val_loss: 0.3531 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.28437\n",
      "Epoch 476/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1686 - accuracy: 0.9542 - val_loss: 0.3518 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.28437\n",
      "Epoch 477/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1747 - accuracy: 0.9555 - val_loss: 0.3534 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.28437\n",
      "Epoch 478/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1596 - accuracy: 0.9578 - val_loss: 0.3511 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.28437\n",
      "Epoch 479/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1622 - accuracy: 0.9563 - val_loss: 0.3524 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.28437\n",
      "Epoch 480/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1738 - accuracy: 0.9557 - val_loss: 0.3504 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.28437\n",
      "Epoch 481/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1577 - accuracy: 0.9578 - val_loss: 0.3541 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.28437\n",
      "Epoch 482/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1649 - accuracy: 0.9559 - val_loss: 0.3533 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.28437\n",
      "Epoch 483/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1625 - accuracy: 0.9573 - val_loss: 0.3507 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.28437\n",
      "Epoch 484/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1662 - accuracy: 0.9569 - val_loss: 0.3487 - val_accuracy: 0.9128\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.28437\n",
      "Epoch 485/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1619 - accuracy: 0.9558 - val_loss: 0.3509 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.28437\n",
      "Epoch 486/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1603 - accuracy: 0.9573 - val_loss: 0.3546 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.28437\n",
      "Epoch 487/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1649 - accuracy: 0.9562 - val_loss: 0.3518 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.28437\n",
      "Epoch 488/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1602 - accuracy: 0.9542 - val_loss: 0.3558 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.28437\n",
      "Epoch 489/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1715 - accuracy: 0.9553 - val_loss: 0.3653 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.28437\n",
      "Epoch 490/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1523 - accuracy: 0.9571 - val_loss: 0.3530 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.28437\n",
      "Epoch 491/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1693 - accuracy: 0.9565 - val_loss: 0.3556 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.28437\n",
      "Epoch 492/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9572 - val_loss: 0.3647 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.28437\n",
      "Epoch 493/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1616 - accuracy: 0.9544 - val_loss: 0.3536 - val_accuracy: 0.9115\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.28437\n",
      "Epoch 494/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1637 - accuracy: 0.9573 - val_loss: 0.3534 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.28437\n",
      "Epoch 495/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1569 - accuracy: 0.9572 - val_loss: 0.3649 - val_accuracy: 0.9072\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.28437\n",
      "Epoch 496/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1734 - accuracy: 0.9579 - val_loss: 0.3579 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.28437\n",
      "Epoch 497/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1646 - accuracy: 0.9572 - val_loss: 0.3611 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.28437\n",
      "Epoch 498/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1721 - accuracy: 0.9561 - val_loss: 0.3562 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.28437\n",
      "Epoch 499/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1660 - accuracy: 0.9555 - val_loss: 0.3552 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.28437\n",
      "Epoch 500/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1721 - accuracy: 0.9578 - val_loss: 0.3588 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.28437\n",
      "Epoch 501/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1616 - accuracy: 0.9576 - val_loss: 0.3598 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.28437\n",
      "Epoch 502/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1755 - accuracy: 0.9549 - val_loss: 0.3589 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.28437\n",
      "Epoch 503/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1716 - accuracy: 0.9570 - val_loss: 0.3583 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.28437\n",
      "Epoch 504/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1690 - accuracy: 0.9538 - val_loss: 0.3569 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.28437\n",
      "Epoch 505/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1618 - accuracy: 0.9562 - val_loss: 0.3573 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.28437\n",
      "Epoch 506/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1724 - accuracy: 0.9539 - val_loss: 0.3562 - val_accuracy: 0.9126\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.28437\n",
      "Epoch 507/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1731 - accuracy: 0.9534 - val_loss: 0.3596 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.28437\n",
      "Epoch 508/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1667 - accuracy: 0.9584 - val_loss: 0.3663 - val_accuracy: 0.9113\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.28437\n",
      "Epoch 509/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1707 - accuracy: 0.9569 - val_loss: 0.3588 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.28437\n",
      "Epoch 510/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1585 - accuracy: 0.9589 - val_loss: 0.3578 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.28437\n",
      "Epoch 511/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1588 - accuracy: 0.9586 - val_loss: 0.3577 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.28437\n",
      "Epoch 512/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1623 - accuracy: 0.9541 - val_loss: 0.3583 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.28437\n",
      "Epoch 513/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1671 - accuracy: 0.9562 - val_loss: 0.3630 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.28437\n",
      "Epoch 514/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1603 - accuracy: 0.9578 - val_loss: 0.3639 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.28437\n",
      "Epoch 515/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1671 - accuracy: 0.9556 - val_loss: 0.3604 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.28437\n",
      "Epoch 516/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1575 - accuracy: 0.9555 - val_loss: 0.3598 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.28437\n",
      "Epoch 517/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1718 - accuracy: 0.9546 - val_loss: 0.3639 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.28437\n",
      "Epoch 518/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1726 - accuracy: 0.9564 - val_loss: 0.3653 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.28437\n",
      "Epoch 519/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1525 - accuracy: 0.9591 - val_loss: 0.3685 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.28437\n",
      "Epoch 520/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1705 - accuracy: 0.9556 - val_loss: 0.3650 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.28437\n",
      "Epoch 521/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1640 - accuracy: 0.9557 - val_loss: 0.3614 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.28437\n",
      "Epoch 522/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1548 - accuracy: 0.9565 - val_loss: 0.3632 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.28437\n",
      "Epoch 523/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1614 - accuracy: 0.9577 - val_loss: 0.3671 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.28437\n",
      "Epoch 524/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1598 - accuracy: 0.9567 - val_loss: 0.3653 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.28437\n",
      "Epoch 525/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1742 - accuracy: 0.9562 - val_loss: 0.3651 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.28437\n",
      "Epoch 526/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1690 - accuracy: 0.9564 - val_loss: 0.3708 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.28437\n",
      "Epoch 527/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1756 - accuracy: 0.9554 - val_loss: 0.3664 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.28437\n",
      "Epoch 528/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1756 - accuracy: 0.9540 - val_loss: 0.3711 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.28437\n",
      "Epoch 529/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1645 - accuracy: 0.9587 - val_loss: 0.3687 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.28437\n",
      "Epoch 530/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1547 - accuracy: 0.9579 - val_loss: 0.3675 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.28437\n",
      "Epoch 531/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1620 - accuracy: 0.9577 - val_loss: 0.3689 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.28437\n",
      "Epoch 532/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1588 - accuracy: 0.9580 - val_loss: 0.3631 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.28437\n",
      "Epoch 533/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1695 - accuracy: 0.9543 - val_loss: 0.3739 - val_accuracy: 0.9055\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.28437\n",
      "Epoch 534/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1670 - accuracy: 0.9559 - val_loss: 0.3648 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.28437\n",
      "Epoch 535/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1624 - accuracy: 0.9571 - val_loss: 0.3650 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.28437\n",
      "Epoch 536/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1608 - accuracy: 0.9581 - val_loss: 0.3682 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.28437\n",
      "Epoch 537/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1613 - accuracy: 0.9564 - val_loss: 0.3641 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.28437\n",
      "Epoch 538/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1742 - accuracy: 0.9562 - val_loss: 0.3762 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.28437\n",
      "Epoch 539/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1652 - accuracy: 0.9567 - val_loss: 0.3662 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.28437\n",
      "Epoch 540/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1679 - accuracy: 0.9573 - val_loss: 0.3667 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.28437\n",
      "Epoch 541/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1795 - accuracy: 0.9547 - val_loss: 0.3751 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.28437\n",
      "Epoch 542/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1620 - accuracy: 0.9596 - val_loss: 0.3683 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.28437\n",
      "Epoch 543/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1576 - accuracy: 0.9588 - val_loss: 0.3659 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.28437\n",
      "Epoch 544/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1829 - accuracy: 0.9520 - val_loss: 0.3831 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.28437\n",
      "Epoch 545/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1679 - accuracy: 0.9540 - val_loss: 0.3639 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.28437\n",
      "Epoch 546/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1710 - accuracy: 0.9572 - val_loss: 0.3701 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.28437\n",
      "Epoch 547/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1751 - accuracy: 0.9535 - val_loss: 0.3720 - val_accuracy: 0.9064\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.28437\n",
      "Epoch 548/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1594 - accuracy: 0.9596 - val_loss: 0.3659 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.28437\n",
      "Epoch 549/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9566 - val_loss: 0.3733 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.28437\n",
      "Epoch 550/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1557 - accuracy: 0.9585 - val_loss: 0.3697 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.28437\n",
      "Epoch 551/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1675 - accuracy: 0.9556 - val_loss: 0.3674 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.28437\n",
      "Epoch 552/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1687 - accuracy: 0.9573 - val_loss: 0.3706 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.28437\n",
      "Epoch 553/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1576 - accuracy: 0.9595 - val_loss: 0.3715 - val_accuracy: 0.9086\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.28437\n",
      "Epoch 554/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1652 - accuracy: 0.9569 - val_loss: 0.3729 - val_accuracy: 0.9084\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.28437\n",
      "Epoch 555/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1661 - accuracy: 0.9567 - val_loss: 0.3710 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.28437\n",
      "Epoch 556/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9582 - val_loss: 0.3724 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.28437\n",
      "Epoch 557/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9547 - val_loss: 0.3761 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.28437\n",
      "Epoch 558/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1632 - accuracy: 0.9567 - val_loss: 0.3725 - val_accuracy: 0.9099\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.28437\n",
      "Epoch 559/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9549 - val_loss: 0.3717 - val_accuracy: 0.9101\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.28437\n",
      "Epoch 560/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1690 - accuracy: 0.9558 - val_loss: 0.3743 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.28437\n",
      "Epoch 561/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1546 - accuracy: 0.9592 - val_loss: 0.3733 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.28437\n",
      "Epoch 562/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1845 - accuracy: 0.9540 - val_loss: 0.3745 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.28437\n",
      "Epoch 563/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1710 - accuracy: 0.9559 - val_loss: 0.3796 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.28437\n",
      "Epoch 564/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1703 - accuracy: 0.9551 - val_loss: 0.3713 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.28437\n",
      "Epoch 565/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9576 - val_loss: 0.3730 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.28437\n",
      "Epoch 566/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1813 - accuracy: 0.9539 - val_loss: 0.3765 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.28437\n",
      "Epoch 567/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1650 - accuracy: 0.9553 - val_loss: 0.3746 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.28437\n",
      "Epoch 568/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1661 - accuracy: 0.9581 - val_loss: 0.3750 - val_accuracy: 0.9106\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.28437\n",
      "Epoch 569/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1605 - accuracy: 0.9545 - val_loss: 0.3798 - val_accuracy: 0.9072\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.28437\n",
      "Epoch 570/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1648 - accuracy: 0.9584 - val_loss: 0.3758 - val_accuracy: 0.9075\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.28437\n",
      "Epoch 571/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1722 - accuracy: 0.9532 - val_loss: 0.3784 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.28437\n",
      "Epoch 572/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1607 - accuracy: 0.9590 - val_loss: 0.3775 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.28437\n",
      "Epoch 573/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1688 - accuracy: 0.9555 - val_loss: 0.3793 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.28437\n",
      "Epoch 574/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1643 - accuracy: 0.9567 - val_loss: 0.3842 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.28437\n",
      "Epoch 575/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1662 - accuracy: 0.9577 - val_loss: 0.3765 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.28437\n",
      "Epoch 576/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1703 - accuracy: 0.9550 - val_loss: 0.3727 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.28437\n",
      "Epoch 577/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1658 - accuracy: 0.9574 - val_loss: 0.3851 - val_accuracy: 0.9055\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.28437\n",
      "Epoch 578/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1637 - accuracy: 0.9571 - val_loss: 0.3802 - val_accuracy: 0.9072\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.28437\n",
      "Epoch 579/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1590 - accuracy: 0.9563 - val_loss: 0.3792 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.28437\n",
      "Epoch 580/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1715 - accuracy: 0.9554 - val_loss: 0.3812 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.28437\n",
      "Epoch 581/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1601 - accuracy: 0.9602 - val_loss: 0.3824 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.28437\n",
      "Epoch 582/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1592 - accuracy: 0.9570 - val_loss: 0.3775 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.28437\n",
      "Epoch 583/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1667 - accuracy: 0.9558 - val_loss: 0.3851 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.28437\n",
      "Epoch 584/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1629 - accuracy: 0.9567 - val_loss: 0.3802 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.28437\n",
      "Epoch 585/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1676 - accuracy: 0.9570 - val_loss: 0.3822 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.28437\n",
      "Epoch 586/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1678 - accuracy: 0.9560 - val_loss: 0.3821 - val_accuracy: 0.9055\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.28437\n",
      "Epoch 587/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1604 - accuracy: 0.9579 - val_loss: 0.3792 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.28437\n",
      "Epoch 588/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1626 - accuracy: 0.9588 - val_loss: 0.3852 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.28437\n",
      "Epoch 589/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1553 - accuracy: 0.9602 - val_loss: 0.3811 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.28437\n",
      "Epoch 590/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1679 - accuracy: 0.9564 - val_loss: 0.3889 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.28437\n",
      "Epoch 591/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1592 - accuracy: 0.9591 - val_loss: 0.3821 - val_accuracy: 0.9093\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.28437\n",
      "Epoch 592/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1680 - accuracy: 0.9553 - val_loss: 0.3886 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.28437\n",
      "Epoch 593/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1645 - accuracy: 0.9574 - val_loss: 0.3794 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.28437\n",
      "Epoch 594/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1745 - accuracy: 0.9552 - val_loss: 0.3836 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.28437\n",
      "Epoch 595/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1629 - accuracy: 0.9580 - val_loss: 0.3797 - val_accuracy: 0.9081\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.28437\n",
      "Epoch 596/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1646 - accuracy: 0.9580 - val_loss: 0.3803 - val_accuracy: 0.9079\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.28437\n",
      "Epoch 597/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1675 - accuracy: 0.9564 - val_loss: 0.3804 - val_accuracy: 0.9070\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.28437\n",
      "Epoch 598/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1732 - accuracy: 0.9579 - val_loss: 0.3848 - val_accuracy: 0.9057\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.28437\n",
      "Epoch 599/600\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1679 - accuracy: 0.9537 - val_loss: 0.3915 - val_accuracy: 0.9037\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.28437\n",
      "Epoch 600/600\n",
      "1122/1122 [==============================] - 3s 2ms/step - loss: 0.1710 - accuracy: 0.9568 - val_loss: 0.3836 - val_accuracy: 0.9061\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.28437\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('vgg_model.h5', save_best_only=True, verbose=1)\n",
    "\n",
    "model_history = VGG16_model.fit(train_vgg16,\n",
    "                                ytrain,validation_data = (valid_vgg16, ytest),\n",
    "                                epochs=600, \n",
    "                                batch_size=16, \n",
    "                                shuffle=True,\n",
    "                                callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAANYCAYAAADZn0yoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAC5i0lEQVR4nOzdd5wcZeHH8e9zNcml95CQ0BJ6j/QiHaQpCgrYAEVQbHTrT8GCYENEEZEmaigi0kORXhN6AgRDAum93yVXn98f3x1nsrlLriV7l3zer9e+7nZ3duaZ2dnd5zvPM8+EGKMAAAAAAG1XVOgCAAAAAMDGgoAFAAAAAO2EgAUAAAAA7YSABQAAAADthIAFAAAAAO2kpFAL7t+/f9xiiy0KtXgAAAAAaLVXXnllQYxxQP7jBQtYW2yxhcaPH1+oxQMAAABAq4UQPmzscboIAgAAAEA7IWABAAAAQDshYAEAAABAOyFgAQAAAEA7IWABAAAAQDshYAEAAABAOyFgAQAAAEA7IWABAAAAQDshYAEAAABAOyFgAQAAAEA7IWABAAAAQDshYAEAAABAOyFgAQAAAEA7IWABAAAAQDshYOXU1kpLlkh1dYUuCQAAAIDOioCV8+CDUp8+0ptvFrokAAAAADorAlZOcbH/NjQUthwAAAAAOi8CVk5RbkvU1xe2HAAAAAA6LwJWTtKCRcACAAAA0FoErBwCFgAAAIC2ImDlELAAAAAAtBUBK4eABQAAAKCtCFg5BCwAAAAAbUXAyiFgAQAAAGgrAlYOAQsAAABAWxGwcrjQMAAAAIC2ImDlcKFhAAAAAG1FwMqhiyAAAACAtiJg5RCwAAAAALQVASuHgAUAAACgrQhYOQQsAAAAAG1FwMohYAEAAABoKwJWDgELAAAAQFsRsHIIWAAAAADaioCVw4WGAQAAALQVASuHCw0DAAAAaCsCVg5dBAEAAAC0FQErh4AFAAAAoK0IWDkELAAAAABtRcDKIWABAAAAaCsCVg4BCwAAAEBbEbByCFgAAAAA2oqAlUPAAgAAANBWBKycEHzjQsMAAAAAWouAlVFURAsWAAAAgNYjYGUUFxOwAAAAALQeASuDgAUAAACgLQhYGQQsAAAAAG1BwMogYAEAAABoCwJWBgELAAAAQFsQsDIIWAAAAADagoCVQcACAAAA0BYErIziYi40DAAAAKD1CFgZXGgYAAAAQFsQsDLoIggAAACgLQhYGQQsAAAAAG1BwMogYAEAAABoCwJWBgELAAAAQFsQsDIIWAAAAADagoCVQcACAAAA0BYErAwCFgAAAIC2IGBlcKFhAAAAAG1BwMrgQsMAAAAA2oKAlUEXQQAAAABtQcDKIGABAAAAaAsCVgYBCwAAAEBbELAyCFgAAAAA2oKAlUHAAgAAANAWBKwMAhYAAACAtiBgZRCwAAAAALQFASujqIgLDQMAAABoPQJWBi1YAAAAANqCgJVBwAIAAADQFgSsDAIWAAAAgLYgYGUQsAAAAAC0BQErg4AFAAAAoC0IWBkELAAAAABtQcDKIGABAAAAaAsCVgYBCwAAAEBbELAyuNAwAAAAgLYgYGXQggUAAACgLQhYGQQsAAAAAG1BwMogYAEAAABoCwJWBgELAAAAQFsQsBJvvqmTHv+ahtRNL3RJAAAAAHRSBKzEhx9q39f+oP71cwtdEgAAAACdFAErUVoqSSpqqC1wQQAAAAB0VgSsREmJ/6iOa2EBAAAAaBUCViLXglWqWgIWAAAAgFYhYCUyAYuRBAEAAAC0BgErkekiSMACAAAA0BoErAQtWAAAAADaiICVyAUsWrAAAAAAtBYBK5HrIkgLFgAAAIDWImAl6CIIAAAAoI0IWAm6CAIAAABoIwJWgi6CAAAAANqIgJXgQsMAAAAA2oiAlaCLIAAAAIA2ImAl6CIIAAAAoI0IWAlGEQQAAADQRgSsBF0EAQAAALQRAStRVKQYAi1YAAAAAFqNgJXRUFxKwAIAAADQagSsjFhSShdBAAAAAK1GwMqIxSW0YAEAAABoNQJWRsx1EeRCwwAAAABag4CVEUtK6CIIAAAAoNUIWBmRQS4AAAAAtAEBKyOWErAAAAAAtB4BKyMW00UQAAAAQOsRsLJKaMECAAAA0HoErAy6CAIAAABoCwJWFl0EAQAAALQBASuDFiwAAAAAbUHAyirlQsMAAAAAWo+AlcWFhgEAAAC0AQEriy6CAAAAANqAgJVVWkoLFgAAAIBWI2BllZTQggUAAACg1QhYGYEuggAAAADagICVVUYXQQAAAACtR8DKCHQRBAAAANAGBKyMUEYXQQAAAACtR8DKyo0iyIWGAQAAALQGASsjlLmLYF1doUsCAAAAoDMiYGUU5boI1tYWuiQAAAAAOiMCVkZxF3cRrK4udEkAAAAAdEYErIyiXBfBmppClwQAAABAZ0TAyghlpSpRvapXxUIXBQAAAEAnRMDKKi2VJNWtYpQLAAAAAC1HwMoqKZEk1a1klAsAAAAALUfAysq1YNWvImABAAAAaDkCVlauBau+mi6CAAAAAFqOgJX1v3OwaMECAAAA0HIErKxcwIrVBCwAAAAALUfAykoGuWAUQQAAAACtQMDKSlqwamjBAgAAANByBKysXMBqoIsgAAAAgFYgYGUxiiAAAACANiBgZdFFEAAAAEAbELCyCFgAAAAA2oCAlZXrIhhr6SIIAAAAoOUIWFm0YAEAAABoAwJWVjKKYA0tWAAAAABajoCVlesiGOpowQIAAADQcgSsrFwLlmoJWAAAAABajoCVlZyDVVenGAtcFgAAAACdDgErK9dFsFS1NGIBAAAAaDECVlauBatUtaqpKXBZAAAAAHQ6BKysXMAqUZ2qqwtcFgAAAACdDgErK9NFkIAFAAAAoKUIWFl0EQQAAADQBgSsrLIy/1ENLVgAAAAAWoyAldWli/9oFS1YAAAAAFqMgJVVVqYYgrpqJS1YAAAAAFqMgJUVgurLu6mbqghYAAAAAFqMgJWnobyrumolXQQBAAAAtBgBK0/s0pUuggAAAABahYCVJ5Z3VTdV0YIFAAAAoMUIWHlit260YAEAAABoFQJWvq50EQQAAADQOgSsfF0Z5AIAAABA6xCw8oRuXRmmHQAAAECrELDyhIputGABAAAAaBUCVp6iCs7BAgAAANA6BKw8xRWcgwUAAACgdQhYeUJFN87BAgAAANAqBKw8oRtdBAEAAAC0DgErX9euKlG96lbWFrokAAAAADoZAla+rl0lSbGyqsAFAQAAANDZELDydevmvytXFrYcAAAAADodAla+XAsWAQsAAABASxGw8hGwAAAAALQSAStfErCqOAcLAAAAQMsQsPLlzsGKVbRgAQAAAGgZAla+XAtWQyUBCwAAAEDLELDycQ4WAAAAgFYiYOXLBaywknOwAAAAALQMAStf7hysompasAAAAAC0DAErX9KCtYqABQAAAKBlCFj5cgGrpKZKMRa4LAAAAAA6FQJWvlzA6qKVWrWqwGUBAAAA0KkQsPKVlKi+uFRdtZJrDQMAAABoEQJWI+rLuqqrVqqystAlAQAAANCZELAaUV/WVd1URcACAAAA0CIErEY0dOlGCxYAAACAFiNgNSJ2cQsW52ABAAAAaAkCVmMquqtClbRgAQAAAGgRAlYjYo8e6qllBCwAAAAALULAakTo1VM9tJwuggAAAABahIDViOLePWnBAgAAANBiBKxGFPfuoR5aTsACAAAA0CIErEaU9M21YK2IhS4KAAAAgE6EgNWIol49VKJ61S5bWeiiAAAAAOhECFiN6dlTklS/ZHmBCwIAAACgMyFgNaZHD0lSXLqswAUBAAAA0JkQsBqTa8GKy2jBAgAAANB8BKzG5FqwilbQggUAAACg+QhYjcm1YIUVtGABAAAAaL5mBawQwtEhhEkhhMkhhEsbeb5PCOFfIYQ3QwgvhxB2av+ibkC5FqziKlqwAAAAADTfOgNWCKFY0rWSjpG0g6RTQwg75E32XUmvxxh3kfR5SVe3d0E3qFwLVkkVLVgAAAAAmq85LVh7SZocY5wSY6yRNEbSiXnT7CDpcUmKMb4raYsQwqB2LemGlGvBKq+mBQsAAABA8zUnYA2VND1zf0busaw3JJ0kSSGEvSSNkDQsf0YhhLNDCONDCOPnz5/fuhJvCBUValBQaTUtWAAAAACarzkBKzTyWMy7f4WkPiGE1yV9XdJrkurWeFGM18cYR8cYRw8YMKClZd1wQlBNWQ9asAAAAAC0SEkzppkhafPM/WGSZmUniDEuk3SGJIUQgqSpuVunVdO1p7otXa5Vq6QuXQpdGgAAAACdQXNasMZJGhlC2DKEUCbpM5LuzU4QQuide06SviTp6Vzo6rTquvZQTy3TkiWFLgkAAACAzmKdLVgxxroQwnmSxkoqlnRjjHFiCOGc3PPXSdpe0q0hhHpJb0s6az2WeYNoqOipHlqupUulwYMLXRoAAAAAnUFzuggqxvigpAfzHrsu8/8Lkka2b9EKrActWAAAAABaplkXGt4UhV49CVgAAAAAWoSA1YSi3j3UQ8sJWAAAAACajYDVhNK+PdVLS7V0aaFLAgAAAKCzaNY5WJuiskF9VKZlWrqoXh7bAwAAAADWjhasJpQO6itJWjVnSWELAgAAAKDTIGA1IfTtI0mqX7C4wCUBAAAA0FkQsJrSh4AFAAAAoGUIWE3JBSwtWlTYcgAAAADoNAhYTckFrLCUFiwAAAAAzUPAakpfD3JRupyABQAAAKB5CFhNybVglVYSsAAAAAA0DwGrKV26qLa4i7qsJGABAAAAaB4C1lqs6tZHPWoXqba20CUBAAAA0Bk0K2CFEI4OIUwKIUwOIVzayPO9Qgj3hRDeCCFMDCGc0f5F3fBqKvqqjxZr2bJClwQAAABAZ7DOgBVCKJZ0raRjJO0g6dQQwg55k31N0tsxxl0lfVTSr0IIZe1c1g2urmcf9dFiLaaXIAAAAIBmaE4L1l6SJscYp8QYaySNkXRi3jRRUo8QQpDUXdIiSXXtWtICiL0dsLgUFgAAAIDmaE7AGippeub+jNxjWb+XtL2kWZLekvTNGGND/oxCCGeHEMaHEMbPnz+/lUXecIr7O2B1gqICAAAA6ACaE7BCI4/FvPtHSXpd0maSdpP0+xBCzzVeFOP1McbRMcbRAwYMaGFRN7yygX3UV4s0b16hSwIAAACgM2hOwJohafPM/WFyS1XWGZLujjZZ0lRJ27VPEQuny9C+6qEVWjiHYQQBAAAArFtzAtY4SSNDCFvmBq74jKR786aZJukwSQohDJK0raQp7VnQQigb6IsNr5ixpLAFAQAAANAplKxrghhjXQjhPEljJRVLujHGODGEcE7u+eskXS7p5hDCW3KXwktijAvWY7k3iNDXAWvlzEWSOn6XRgAAAACFtc6AJUkxxgclPZj32HWZ/2dJOrJ9i9YBDB7sv7Nny41yAAAAANC0Zl1oeJO1uU89K583fR0TAgAAAAABa+1yAav7YgIWAAAAgHUjYK1Nt26q7NJXfVZMV8wfmB4AAAAA8hCw1mFFn801uH6GKisLXRIAAAAAHR0Bax2qB26uzTVd8+cXuiQAAAAAOjoC1jrEoQQsAAAAAM1DwFqHohHD1E+LtGBaVaGLAgAAAKCDI2CtQ5dtPJJg1XuMJAgAAABg7QhY69BzRwesmskELAAAAABrR8Bah/JcC1b9BwQsAAAAAGtHwFqXoUMlSWH2rAIXBAAAAEBHR8Baly5dtLykj8oXErAAAAAArF2zAlYI4egQwqQQwuQQwqWNPH9RCOH13G1CCKE+hNC3/YtbGMu6b6aKZbMLXQwAAAAAHdw6A1YIoVjStZKOkbSDpFNDCDtkp4kxXhVj3C3GuJuk70h6Ksa4aD2UtyBW9t1Mfatnqa6u0CUBAAAA0JE1pwVrL0mTY4xTYow1ksZIOnEt058q6R/tUbiOon7gZtpMszRnTqFLAgAAAKAja07AGiopO4TejNxjawghdJN0tKR/NvH82SGE8SGE8fPnz29pWQumeNgQDdFszZzeUOiiAAAAAOjAmhOwQiOPxSamPV7Sc011D4wxXh9jHB1jHD1gwIDmlrHgyrfaTKWq0/x3Fxa6KAAAAAA6sOYErBmSNs/cHyapqSH1PqONrHugJPXcdjNJ0vJJjCQIAAAAoGnNCVjjJI0MIWwZQiiTQ9S9+ROFEHpJOljSv9u3iIXXY9QQSdLK9wlYAAAAAJpWsq4JYox1IYTzJI2VVCzpxhjjxBDCObnnr8tN+glJj8QYK9dbaQukaJhbsOpmMFQ7AAAAgKatM2BJUozxQUkP5j12Xd79myXd3F4F61CGuAUrzKIFCwAAAEDTmnWh4U1eebmWl/dT2QICFgAAAICmEbCaqbLPMA2o+kArVxa6JAAAAAA6KgJWM60asZ2207v68MNClwQAAABAR0XAaqainbbXFvpAH7xDExYAAACAxhGwmqnnXturSFFLXppU6KIAAAAA6KAIWM3Ua5/tJUl1b71T4JIAAAAA6KgIWM0URo1UvYpU9j4BCwAAAEDjCFjN1aWL5nbbUr3nvFvokgAAAADooAhYLbBo0PYauuwdNTQUuiQAAAAAOiICVgvUjtxRI+MkzZhSU+iiAAAAAOiACFgtUL73ripTrWY8zkiCAAAAANZEwGqBQYfvIkla9uybBS4JAAAAgI6IgNUCffcZpWqVKbxFwAIAAACwpmYFrBDC0SGESSGEySGES5uY5qMhhNdDCBNDCE+1bzE7hlBWqg8rdlDvaW8UuigAAAAAOqCSdU0QQiiWdK2kIyTNkDQuhHBvjPHtzDS9Jf1B0tExxmkhhIHrqbwFN3+zXbX1+48UuhgAAAAAOqDmtGDtJWlyjHFKjLFG0hhJJ+ZNc5qku2OM0yQpxjivfYvZcdRut4sGN8zWoknzC10UAAAAAB1McwLWUEnTM/dn5B7LGiWpTwjhyRDCKyGEzzc2oxDC2SGE8SGE8fPnd86A0u3APSVJM+9+qcAlAQAAANDRNCdghUYei3n3SyTtKelYSUdJ+kEIYdQaL4rx+hjj6Bjj6AEDBrS4sB3BiE99RLUq0crHnit0UQAAAAB0MOs8B0tusdo8c3+YpFmNTLMgxlgpqTKE8LSkXSW91y6l7EAGbdlNr5TuqZ4TCFgAAAAAVtecFqxxkkaGELYMIZRJ+oyke/Om+bekA0MIJSGEbpL2lvRO+xa14/hw2P7acv7LUnV1oYsCAAAAoANZZ8CKMdZJOk/SWDk03RFjnBhCOCeEcE5umnckPSzpTUkvS7ohxjhh/RW7sFbuvr/KY7WqX3i10EUBAAAA0IE0p4ugYowPSnow77Hr8u5fJemq9itax9XzYweo/u4iLbr1fg356L6FLg4AAACADqJZFxrG6nY8ZKAe0jHqeffNUl1doYsDAAAAoIMgYLXClltKd/U6SxVLZ0ljxxa6OAAAAAA6CAJWK4QgVR1ynBYUD5SuuabQxQEAAADQQRCwWmmfA0t1Vf35bsF64YVCFwcAAABAB0DAaqUDDpCu1de0qucA6fLLC10cAAAAAB0AAauVdt9daujaXS9u/VnpiSek+vpCFwkAAABAgRGwWqm0VNpnH+nJRbtIq1ZJU6YUukgAAAAACoyA1QYHHCA9PH1H35mw0V5XGQAAAEAzEbDaYP/9pbcadvAdAhYAAACwySNgtcG++0qriiq0qM9WBCwAAAAABKy26NlT2mUX6d3inaSJEwtdHAAAAAAFRsBqo4MPlp5dvKPipElSTU2hiwMAAACggJoVsEIIR4cQJoUQJocQLm3k+Y+GEJaGEF7P3X7Y/kXtmI4/Xnqpfk+FujouOAwAAABs4tYZsEIIxZKulXSMpB0knRpC2KGRSZ+JMe6Wu13WzuXssA46SHqp11GqLu4q3XlnoYsDAAAAoICa04K1l6TJMcYpMcYaSWMknbh+i9V5lJZKBx/bXY8Uf0zxrru44DAAAACwCWtOwBoqaXrm/ozcY/n2DSG8EUJ4KISwY2MzCiGcHUIYH0IYP3/+/FYUt2M68UTprzWnKMydKz3zTKGLAwAAAKBAmhOwQiOPxbz7r0oaEWPcVdI1ku5pbEYxxutjjKNjjKMHDBjQooJ2ZEcfLT1ScqxWlfWQbr650MUBAAAAUCDNCVgzJG2euT9M0qzsBDHGZTHGFbn/H5RUGkLo326l7OB69pT2OaxC93Q5VfGOO6SlSwtdJAAAAAAF0JyANU7SyBDCliGEMkmfkXRvdoIQwuAQQsj9v1duvgvbu7Ad2YknSr9a9iWFlSulMWMKXRwAAAAABbDOgBVjrJN0nqSxkt6RdEeMcWII4ZwQwjm5yT4laUII4Q1Jv5P0mRhjfjfCjdqJJ0qvaLTmDNxFuuGGQhcHAAAAQAGEQuWg0aNHx/Hjxxdk2evLUUdJ+4y7Rj9e/A3ptdek3XYrdJEAAAAArAchhFdijKPzH2/WhYbRPGeeKV2z+HTVl5ZLf/lLoYsDAAAAYAMjYLWjE0+U1Kevnt/sUx5NcOEmdRoaAAAAsMkjYLWjLl2kL3xB+vrM7yhWVkq//GWhiwQAAABgAyJgtbNzzpHeqNtRE3c5Vfrd76QpUwpdJAAAAAAbCAGrnW27rXTYYdLZ83+mWFYmnXyytGpVoYsFAAAAYAMgYK0H554rvTBrhMZ97Rbp1VfdkgUAAABgo0fAWg9OOEHabDPp/145QTrySOmqq6Rly6QnnpD+/vdCFw8AAADAekLAWg9KS6Wzz5bGjpXe/9z/SQsWSP36SYceKp1+uvTOO4UuIgAAAID1gIC1npx3ntSzp/TNMftJl10mffWr0h//6CfHji1s4QAAAACsFwSs9aRfP+m735UeeEB68sAfSFdf7SEGt91WeuSRQhcPAAAAwHpAwFqPvv51adgw6aKLpIaG3INHHik9+SQjCwIAAAAbIQLWetS1q/STn0jjx0t33JF78MgjpZUrpfvuK2jZAAAAALS/EGMsyIJHjx4dx48fX5Blb0j19dIee0jLl3tsi/JQI33kI9KcOdKbb0qDBhW6iAAAAABaKITwSoxxdP7jzWrBCiEcHUKYFEKYHEK4dC3TfSSEUB9C+FRbCrsxKS6WfvlLaepU6fe/l1RW5qHaly510HrssUIXEQAAAEA7WWfACiEUS7pW0jGSdpB0aghhhyam+4UkhsjLc8QR0jHHSD/6kTRliqQdd/R5WBUV0sknS4sXF7iEAAAAANpDc1qw9pI0OcY4JcZYI2mMpBMbme7rkv4paV47lm+jcd11bs367GfdbVD77CPdfrtbsr77XY8sWFMjxSjV1RW6uAAAAABaoTkBa6ik6Zn7M3KP/U8IYaikT0i6bm0zCiGcHUIYH0IYP3/+/JaWtVMbPtxdBF94QbrxxtyDu+winXqq09dRR0knnujWreOOK2hZAQAAALROcwJWaOSx/JExfivpkhhj/dpmFGO8PsY4OsY4esCAAc0s4sbj9NOlgw5yg9X/egVec430t79JV1whPfyw9N57vhDxG28UtKwAAABAu3vnHWnGDPfYmjCh6elilC64QDr+ePfy6kSaE7BmSNo8c3+YpFl504yWNCaE8IGkT0n6Qwjh4+1RwI1JCNLvfictWSKddZb3G/XtK512mnTJJdJzz3lH69JF+tWvpLffLnSRAQAAsKFUVuYqiB3I++9L//1vev/WW6W33mp82nfekf7858wFYHNmz5Z++lPXdT/yEWmvvaRTTpF23ln65z+lmTN92kwiRunyy6Vf/1q6/37p+99v//Vaj9Y5THsIoUTSe5IOkzRT0jhJp8UYJzYx/c2S7o8x3rW2+W4qw7Q35je/kc4/3xnq/PMbmeDMM6WbbvL/d90lffKTG7R8AAAA2MAWL5a22spB5Ktfbf/5r1jhSwTtt1/jz//nP17+iBFuDejRwxdy/fKXffD/tdekWbOkffeVunWTfvxjqbzc13Z9+23p05+W7rxTmj7d08yd6+sU7bmnh9OeNMnL6dfPLVLLl0t9+khFRQ6WvXpJ3/iGy/n229K//+3uX927S3/6k0PdTju1/3Zpg6aGaW/WdbBCCB+TuwEWS7oxxvjTEMI5khRjvC5v2ptFwFqrGKVPfUq6917pqaca2c/nz3da/8UvpJISfxiKuCY0AABAp1BX5wpfaenqj7/2WtoiE4JbfEpKpJEjpZtvls44QzrgAOmZZ1Z/XYyefm1WrfIJ/0OHSp/5jB975x0Hmrlzpc99znXKO+6QTjjB0374obT//tLTT0t/+INHuB4+3K8rLZVqa6XRox2Ott1W6t1beuUV///ii17GDjtIw4Z5wLayMunrX/fpL6NHS0OGSPfc4wD1u99Jd9/t1oWKCpdljz1cET74YGnePD9WXCx17SpdfLH0ve9J1dW+rNHxx7fDG9O+2hSw1odNOWBJbgXdc0+H9Oef9wGDNYwZ40EwRo/2BMcf7yS/rg8YAAAA1o+5c13hP+UU9zgaMMB1tJISd40LQTr6aGnBAo9uVlbm18Xo8PT8867jHXCAu8jF6LBy/vnSgw/6oPqkSdK//uUwc9llDl4xOhTtuKOvqfraa55/VZW0996+BNDUqV7W9tu7PNmufD16OAjNmuX/Z8xwC1R1tZ8/91w/NneuA9jChS7jccdJDz3kOunKldIPf+hrD82a5VC39dYu29/+5gCWP1hbVZW0bJk0eHDj23PRIr9Ocite376dpq5LwOqA3nnH+23fvu6SOnBg3gT19dKXvuQPy/vve6c/7zz3MSwpKUiZAQAA2kV9vVtQkqPMdXW+deni+0nFu7W9eB57zN3OPvKR5k0/e7Z0223S9ddLH/uYzwHq2VOaPNl1r+22k7bZxt3YJk+WBg1yGJFczoEDpWnT3E3pttv8+IUX+oj6VVd5Pe+6y60zffu6pemtt9wFrqTEPZgOPFB64gkHoOXL3YoUgrvU9e3rbdKnj4NI9+7S7rs7JL3yiluDLrzQXfT++U8fxf/0p72de/WSDj/cAemEE7wu55zjlqNJk1z2zTZb+/aZPFm65RYvo1ev1r0nGxkCVgf1wgvSYYe5dTX5PDWqocEDYfzyl27Ruv32Jpq9AABAp1Zd7Yr1xn56wNe+5kvVvPGGK0KHHOJQMW6cW0+23dZHoq+91qMsH354+traWreMNFXRHztWOvZYnys0frw0apQfj9F1qT//2a0qF10kHXqoW2Xuv9/T7Lmn9OqrbnE54giHotpa3ySHrgsu8DzOP1/acku38Mya5fI/9ZTraHvs4ddKbjmaMcOtXX/7m1t5Kiqkq692i9T557tla9w4t34tWuTydOvmaS+4wNvrhhvc2vWVr7hsnaSlZ2NFwOrAHnjAl8A65BD/n7QkN+rOO6Wzz/aH+cUX1zExAADoVKqr3W3s2GPdarKxeuUVtyzF6HOD9tnHAULyKHVvvukgJDloNjR44IfTT08vbVNb61akHXd0QOvZ09MWFfm1W2/t0FNc7C50FRXuETRunENVUZFbuSS3An3nO+7qt8ce0ssvuzyTJrmS9vOfuzvc7NluxRoypPH1qqlxWDvuOI+U9/jjnvdBB7m7UpcuLktDw5oBurbWwfr5592itddefryujp5LHRQBq4O75Rbpi1/05/qOO9LW8Ubdc4/0iU/4w3rMMe422K3bxn+kCwCAjd0f/uCK/ZAhbvFYH7/tCxZ4EIQvfcnnES1d6nBy3XXSRz/qwHLXXR7u+He/S4NQfb27pt1wg1uU+vVzaJk8WTrqKM9n8GDpgw+kv/7VXc5OPdXLKirySHC//a2Dw2OP+bFjj/XgDjG6S8/Che5mV1kpnXyytMUWvt+zp68dKrlr3Je/7HA1aZI0caJHnVu50s/X17sb3B//6NdedZXLuHKl1L+/u8194xue9uWX/dxHPpK2cmU1Z3AJbLIIWJ1A8p16yCEembLJ7oKSh/D861/9xdKtm494fepTPvmxf/8NVmYAAJBTX+/WkuZOW1fnlpbddnPQWL7cgxMsXuzub+PHuzXl+efd4rHHHg40WUkAWLjQXem6dHErytixPhfnl79ML/fyj3+4RWXCBAeLHj3cHe6FF3z6wXPP+fygffbxeQvFxa5jbL21Q0hlpVtS6uocnhYs8LL69fP/Wfvt58fee8/d+MrLPUrcnns6EG2/vc9T6t3bgefgg90NbsoU6bvf9fb585/dYyfx9ts+Z2m//aTNN199eUl9trrayxk+vLnvGtBqBKxO4rbb3JK1554eSKZfv3W84MUXPYJNUZH0l7/4yNE3vym9/rpPzrznHg/9eeyx67/wAABsKt580932S0rcynLbbQ4u993nlpx77pF23dWtRFnz5vl8mzFjHDwWLXJoeuEFnw/02GNuPTrpJLcuTZ3qMCQ5bPzqV+6i9swzvg5R377u7nb//W6tSWy7rcPS66+7HlBf7/DSvbuD0s9+5nrCqlUepvuZZzwk9ltveeCJj33MZf/mNx3uttnG5V250tfr3H57h5nqas/z1Vfd6pZckPajH3Xoeewxj3hXVSV9/vOeb9LljZYhdHIErE7k3nv9nbrNNv6ezh68WatXX3XXwWnTHLhKS/3F16OHW7qa6i+8fPk6mssAAJuchgZXtJv9I1Qg9fU+Z2fPPaVddmn+655+2iHnJz9xSJF8Dkx9fdpPP0a3Ir3/vltNnnjCy7nlFrcMJecGSe7C1r27z/mR0ue++EW3SP33v+7Wf/fd0syZDhvLlklHHumWm6VL/bobbpDOOssXan3xRbcU/fjHHjnuwgvd/S6x//5exrvvOuT9+c8OU+XlvtXWetvceadD3LHHSl/4gkNS9+4ejEHyKQdz5zY9jDaARhGwOpknnnBWitEt+h/7WDNfuHSpA1ZDg7+8jzrKI9R87GM+glRc7Gb+t97yF2lZmfskXnedfwQAAJu25OT73/zGLSpvvukBBDakhQv9m3XGGe5i1rOnu6klISBGh4YJExxcxozx65KLpybdx156yb95H37o28EHeyS6Bx/0ENXV1W7pOfZY6dFH/dtYXu77y5b5fjIMd76zz/ZgC927uwyDBrll6Prr3ZXvsMN8XaE77nDoGTLEP+79+nnEuezQ4WPH+iKtH/+4h+mW0hHlvvxld9OT3Ar08svSnDk+CrvnnrQCAQVEwOqEPvjAPQQmTnRvgVZfwPqqq3w17F69fE2E+vr0ueQaDqNG+cJcDJQBABu3l192q82f/+zfgIYGB42uXX0dnoMO8iAETz3lUPKVr/gg3LpUVbk1ZscdpV//2q0kf/iDW2OGDvU0s2d79Le77vLBvX33dff2F19068yAAS7LlVc6XIwa5YBUUeGR1x57zOcTTZvm5xM/+IGD0U9/6gOJX/+6fzzvvTedJrmuUGLfff3bmFw3aLfd3MI0b55PhB46VNppJ7cSjRrlLnQHHOCy9+7tVqXmhJvsCHCvv+6WqBEj1v06AB0eAauTWrzYB9tefdWDBf7iF+mBrBZ54gmP0rP55r643PbbexjRBx/08Kh//au7KBxwgIcjnTPHRwk5MgYArfPee754Z+/evl9ZueYABe2hocGDAjz/vK/1kXT5fvlldw//5CfTH44VK3xe0JQpPo/miivcXeK119z68957/sFJjBzpkexuvtktPbfe6m4V117rdbvySgeZHXf0/Rtu8O/G5ps7sCXd07fc0tMl3eCyF2jt3t3d2yZMSJdbXOzgc/XVvibQ1Kk+CHjyyW652mYb6dvf9lHIqVPdkiP5/3POcWtQv34+f+jTn/bgT717u7vfY4/5N/DEEzmoCKBNCFid2MqV/u387W/9W3frrR7gp81qa/3jt+22Dl1Tpvjxfv3cPWPXXf2jPHiwB9Lo1cuvacmJqbW1PoF30KB2KDAAtJNf/MLnqZ5/vu9PmuRWheTcm4YGt6rsscc6rpuRU1fnUJB8N952m7u3HXigR2175hlfFPTKK13pl9yb4MknfW5P167pY1VVPui1zTZ+zYoVPiF39mwHheXL/dgpp/hg2GWXuYuZ5BaYujqP3vbaa36sf3//iDz4oEPYypVuaXrkEQe+ujp3TXvqKS//t7/1OUbTprmb3ujRq/d8GDrU5xBJDi1HHOHQsnix9NnPukvbhRf6vKBf/tJDcyfX9Nl6a7cIjR7tdVqyxCGpa1efm9Svn39runf3b1NlpX+Hamo8/8GD19zW+WL0tH36cJAQwHpFwNoIPPmkT5OaPl265BLpRz9qx+sMr1jhH7IHHvCP8C67uBtEaan73++6q38wv/UtH/X705+antfChe73vs8+/nG9+moPrUqXCABNidHnwBxwQCub6ZtQX++w0bNnGmKmTXNFPwS32Dz7rM9Z3W8/f//NmePvuXff9UVNb7ut8XnPnevphwxxN7qhQ92C89BD/r5Mgsg//uEv7EmT/J36wx86mNx3n0PONtv4mjyPPebHyss9spvkAQ4qK9OWn8b07u3R4ObOdde/ESN80GyvvTyS2w9/6OG3+/Xz+hx+uM9FOv10adgwl3233VafZ7bb4KxZ7jr45ptupTr4YOlvf3MQOuwwB5mZM93l8LzzHOhi9OubE04BoJNqU8AKIRwt6WpJxZJuiDFekff8iZIul9QgqU7St2KMz65tngSs1lm2zL0ibrzRGeiWW9b8XWx3993nyseSJa74VFW5y0VNjY+gPvCAf2B3282jMv31r/5xPuIId8dYvNgXGfz73z0EbM+e0qWXrudCA2iWZEADac1r+LzwgnT77T6Pc/58V9DLy/3csmX+LDfHnDmudCfnoTTmmmscMj73OTfTSw5GFRVpMKqtdXh58UWHo+HDXcHfZht/H91zj9dn223d3P/OO26ZmTXLLSInn+wWljFj3CpfXOyua++9J+28s7uw7bFHGryOPtrh6LTTfFLstGkeQGHoULcOXX65j3hJDkLLlvlgleTrEt54o78Xk94BY8b4vJ133vH98nIPInHHHV5eRYXPV2po8MVZ337b4S8ED5e9004+PygZHe6++7zco45y2Ela3T7yEQe57Hv86KNuNVrntT8AAM3VVMBSjHGtNzlUvS9pK0llkt6QtEPeNN2VhrVdJL27rvnuueeeEa13770xDhoUoxTjQQfFOG7cel7gvHkx/vrXMc6YEeMBB8RYVhbjgAEuQK9eMXbp4v+7dInxW9+K8fzzfV+K8aij/PfUU/23uDjG116L8be/jfErX4nxqafWc+GBjdyqVTHW16f3lyxJ/1+4MMa7746xoWHN182fH+M22/hzeOmlMXbvHuMVV8S4bFmMK1fGuOWW6We3rCzGrbeO8YknYrz9dj++887+PjjrrBjfe6/xsj37bIwlJTHusEOMP/lJjH/5S4wvvhhjXV2MixbF+K9/+fsi+51yww0xfvOb/j+EGD/72RgfeijGgw/2YyUl/h6RYiwtdfmGDk2/c7K3LbaI8Xe/i/HMM71+yeNf+EKMF13k13/lKzEuXx7jPff4vhTjX/8aY02Nv2B79oxxr728vtl5jxjhct10U4yzZ8c4ZUqMf/pTjLfd5vWLMf2ue+4536+v9/adN8/LjNHvzbRpMS5Y0Pp9AACwwUkaHxvJOetswQoh7CvpRzHGo3L3v5MLZj9fy/Q3xhi3X9t8acFqu4UL3SPjmmvcM+Tii90TZL33yKiu9tHToiIPnrH//j5aOn++R4CqqPDze+zhI61PP+2jxv/6l4+sTpjgPvS1tS5sXZ27z5xxho9CV1b6CHRJiasxNTXpUfN1mTXLffQ39ROX587lvLfOLkZ3UYvR3b3y9+m6OreY1NS4O27Pnr4cwz/+4ZaWX/5S+upXPVLbSy+5peTnP3eL1BtvuGvYgw96RLfEyJEebrpbNw868Pbb7h78xhseRS1GDyLQtau7oQ0c6HK8/LJbSS65xOXZd1+38Dz/vFuFSkv9mnffTZfVp49bxWP05/ugg9wk/6lP+XWS+0T36uUR7KqrPd0f/+gWpdJStwz94AduyTnkEK/v0KFuDZo82a3tX/ta+lmorPR31rJlbp3q3duPZa8D+MQTbnm/8MI1z9+prJR+9zsv44AD3IK2tlY5AMBGrdVdBEMIn5J0dIzxS7n7n5O0d4zxvLzpPiHp55IGSjo2xvjC2uZLwGo/S5Z4AMAbb/Tv/SWXeHCognd9TypPffr478MPO2D9/veupPz9766InXGGw1fWVlt5ZKuXX/bJ4V/6kis3yTkBb7/tPv+XXea+kpMmeTCNCy7weQc/+IG7zkyf7kpntrtMorraXXw++MAb7NBDW7eeMaYVsUmTXDlNrsHS1PSnnOLuSb/97dov7NjQ4EBaUeFzRppj7FhXHu+9tw1j+2fKWlfX+PbrSOrqXDE+9NDVu7hlzZ7t7f3CC94Hd9nFQ1A/8IDPofn4xx1OkuBw++0ejezxxz3t9rljRrW13h5vveXRzJYt83593XXpuS3PPOPBE954w5X94cM9sMBll7mr3Gc/625zN93kAxNHHeXzYWbM8Pk+48Y5TCxY4GUOH+5uuTff7LKWlDi4VFf7oEZlpQPW3Lne36uqPGDBqFHeJw8/3F3EysocgIqL00ELfv1rl2XRIq/DuHEuw/jxDm7f+Y4/Jxdd5M/ySSf5c/nqq+6aJ/n1Z5/toBOC9xvJwXDBAnfrGz3a5xXNnOnXjx3rz/khh/gzmxxEqavzsN3Ll/vzHIK30bvvOhQ2dtHb7GcQAIANpC0B62RJR+UFrL1ijF9vYvqDJP0wxnh4I8+dLelsSRo+fPieH374YYtXBE177DHnihdfdB3s8st9ALip+mbBNFZpHz/eR6179PDz11/vymm/fq6w/uMfrpj26+fK5Pbbu2KbnIuR7McHH+wK7ezZ6by32MKVz4YGVzi3394DeCxY4GbA3r0dBn/847RCPW+eK3NLl3pjPvCAK7I/+IFbEurr/ffii329lAcecNm22cZ/n37ao3b9+98+/+yrX3UFcuRI6f77HXxCcAh8+WX/zbd8uY+Sv/mmj+KPG+d1HzWq6UEAYnRF9tVXXWlNtk/W7NneFsl1aZ591oG3pMQXxUwuchmjz7276y7puONc+e7Xz6OgvfqqK/tXX+3WgV13datjfrlqa92S0dDgEJLdGbOV4mee8fqdfLLD6d/+5oDYrZtbEnbc0dO9/74fnz/fFfODD3Zo+OlPpe9/3+/HL36x+rp+6Us+v+a22xwEevRwea691ucETpvmaY84wiGkpMTTLF7sfbS21oHrkksciCZOdCvLgw86NJWWOuj06rX6QAT59yW//w0NXg/J23rYMO8/y5b5se22c1CsrvbQ0127eju//rofD8G3XXdNR167/HKPCrdsmfel5cs9bbKPfuITXv9XX/W1hE45xft/VVXjgWVtGhp8nlH++VcxukVpyBAfTBkwIN2XAADYCLUlYLWoi2BumqmSPhJjXNDUNLRgrR8x+kD+97/vA/VbbOHrLZ51lut7nU5SCV+wwEEo2x1n1Sq3fg0c6Ir5W2+5Mp2MRrZkiZvx/vQnV0SLirxR5s71ifGbb+7XHXaYhxX+61+bLkdJiUPhkUf6qP6vfuXyzJzpCnb//j6Z/aGHPP2AAa7sHnJI2gUrBJ+4/sorrrSPGeNK8IgRnu8ee7ilpKHB3bBuu80n7V91lUcGW7HCr6uocGvCmWdK//mPK+uPPebwU1bmCvehh/q5n/7U08+d62WvWOFwt3Spt91++3k+/fo5NC5e7FHHpk71+r3xhod9/s9/XLbDD3c3M8mh5a230m3Uu7e358SJ3rY9e7qVIgkwxx3nVpqyMgfb88/3wAMhpIG4qMjb9/nn3WqzeLHLfNppbnm5++403DY0+H39+McdWkPwNr/wQj8/YYK7u334oV87ZIjfn759fb2f11936H3kEb8Xf/yjA1t5uVs1f/5z7xMHH+zwvWSJQ+LOOztcbredt3uPHu6Ct99+bnlZuNDv5ZVXOlwfc4zXZ9Ysj7BWXu7WsaTsIXhffvhhb7NDDlkzFNfXuwVnhx1oqQEAoINoyyAXJZKmSNpS6SAXO+ZNs43SsLaHpJnJ/aZuDHKxfjU0+Nzxgw7yudjdu8f49a83fR76JqOmJsY5c9Z8vKEhxocfjvGXv4zx0UdjnDUrxldeiXHy5BgffzzGuXN9onzv3t6gRx4Z4yGHxHjOOTG++WaMO+3kx7/8ZZ/0L8V4xx2e93/+E+Ott/pE/ooKn5w/Zoyfu/9+nyjfrVvjJ+j/5Cee7tFHYzziiBj/+McYP/Wp1acJwSfgjxoV47BhMZ5xRowrVsS4227pNEVF6f/Dh8d47rkeKECKcZ99PH1VVYw/+pEHBfj4x71OZ5/tbfPvf6fTH398jB/7mP//6ldjnDgxxjvv9OMlJZ7fiBExDh4c46GHxviPf8R45ZWrlyEZneWMMzz4wDXXxPjOOzFecokHOjj77Bhra33S/0UXefCUgQM9gMq0aS7rPfd4+eXlnvfrr3vgghB8f4cdvK5PPOEdf+7c9P1euTLGH//Y84jRAxLccUeMixd7fbMDRsToed97bzpQxKRJHqgAAABsstTaQS5y6exjkn4rjyh4Y4zxpyGEc3IB7boQwiWSPi+pVtJKSRdFhmnvMF591T2M/vEPN8Iccoi7Dp50khs30AK1tW4RSa6hk0iGR959d7cOvfuuW4Ia09j5IvX1bg167z0/P3KkW3dGjWr89f/4h0/iP+kkd/Fq7I1MumyVlLi15L773KXtpJPcjez1193l7Xvfcyvgusyf7x1o8GD/P2aMr5+THYAkO+R3vnffdUvNwoU+1ygZqKA5Vq1yy1dj8/7gA7cO7bef70+d6nVe23lwAAAAbcSFhqE5c3xq0y23uN7dvbtPxfje93yuOQAAAIDmaSpgbeJjWW9aBg/2MO6TJ3sMhk9/2g0h223nQed+/WuftlKgzA0AAAB0egSsTVAIHtzrhhs8BsB557nX2wUX+Pz9YcM8VsSLLxa6pAAAAEDnQhdB/M/06R587+GHfVu+3Kf3HHywdOKJHuiuqdHBAQAAgE0J52ChRVas8AjVjz/u25IlHifhqKM82vZRR7mlCwAAANgUEbDQarW1Pmfrnnt8mzHDj++4oy+3NHCgLyW1776FLCUAAACw4RCw0C5i9EAYDz/sa8g+/7xH/pak7bf3SNlHHOHr0fbrV9iyAgAAAOsLAQvrzfLlHvr9oYccuJYs8UAagwf7Mk4HHOBBNfbdV+rZs9ClBQAAANqOgIUNor5eGj/e521NmSK9+aYvdFxf72vEDhwobbONtM8+Dlx77y0NHVroUgMAAAAtQ8BCwaxY4SHfn39emjZNevtt6ZVXpJoaP7/ZZtIuu/hix1tu6b/77y8NGlTYcgMAAABNaSpglRSiMNi0dO/uc7IOPzx9rLpaev116aWXfHv3XYewJUvSaUaNSm8jRzp8DR8ujRjBcPEAAADomAhYKIjycncP3Hvv1R9fvFh67z3pscccwN57z90Nk4E0JHc1HDVK2n13t3YNHy5tvrn/Dh8u9eixQVcFAAAA+B8CFjqUPn3WDF4NDdLMme5eOG2aW7tef91dDm+/3c9n7bCDh5AfODDtfti1q9S3r1vCunffoKsEAACATQgBCx1eUZFbqDbf3OdmZdXVSbNnO3hNny69/7707LPSW29J8+ZJixatPn1xscNX795uBRsyRKqocLDbZhtp220dzEpLN9jqAQAAYCPSrIAVQjha0tWSiiXdEGO8Iu/50yVdkru7QtK5McY32rOgQGNKStLw1Zhly6SJE32x5Pnzpddek954w+d6/etf0sKFjb+ua1dpwABpt93cCtavn9S/vwPZ9tt7CPq+fb18AAAAILHO6mEIoVjStZKOkDRD0rgQwr0xxrczk02VdHCMcXEI4RhJ10vae825ARtWz54eDj7xyU+u/nxDg7RqlYPWe+/5tmCBg9mMGW4Je/FFP19fv+b8t9jCLWIh+P7mm3sQjn79fOvbN/2/Xz+prGy9rSoAAAA6gOYcf99L0uQY4xRJCiGMkXSipP8FrBjj85npX5Q0rD0LCawvRUUekbBbN4ejww5rfLqGBmnp0vQcsPnzHcQmTJAmT/Z8YpSeecbTNaV79zR4bbaZB+UYMsTzr6310PSDB7sr4957p61kJSVpiAMAAEDH1ZyANVTS9Mz9GVp769RZkh5q7IkQwtmSzpak4cOHN7OIQOEVFfk8rT59pF13bXq6GKWqKrd4ZW+LFq352MyZHqhj8WK/NgS/vjFlZV625Fa5vn3Xfuvd26Fss818Kypq180BAACAJjQnYDV23LzRamAI4RA5YB3Q2PMxxuvl7oMaPXp0Ya5wDKxHIXjQjIoKt041R22tW6xCkObMcctYVZX08sv+W1cnLV+eBrFlyxzY5s+XJk3y/9nrhzWmW7e0XBUVXl55uVvtamrcsta/v1vXevf2MmtqpC5d/PjAgW5p22wzP1Zb61a38nLfp4UNAADAmhOwZkjKDiEwTNKs/IlCCLtIukHSMTHGJoYOAJAvO2LhkCG+SWteI2xt6usdshYtSgNXba27NM6dK1VWrn5raPDfd95xSKqqcrDLH3WxuUJwOBs1yuEsCWJ1dR4wpKLCQ+SvWuWw2LOnr1fWs+eat+Txbt0837o6BhMBAACdR3OqLeMkjQwhbClppqTPSDotO0EIYbikuyV9Lsb4XruXEsBaFRenA2m0RdJaVlLibokrV7qlbN48D4c/a5ZUXe1QWFzs/1etcmvXrFkeJr+iwi1rdXWeZtWqtNVN8rzr6tZdlqIiL6e62mXp3Tu99ejhUFlT4yBZXu5wt802bumrrpZ69fK0PXs6qHXr5v/r690Vc/hwd6dsTLdubrlraHA5kta5GNPAR4sdAABozDoDVoyxLoRwnqSx8jDtN8YYJ4YQzsk9f52kH0rqJ+kPwbWOuhjj6PVXbADrQ0lJeq6X5ODSu7dbn9pqwQK3alVUOAAtW+Ywt2xZesu/X1PjMFVZ6Va5JUs8iMiyZS5r164OUpWV0gMPuLWurMzLWbas7WWWvJyKCget5cvT4Jjf4tajh5/r0sXBbcECd60sL3cIrK11QEvOiQvBrykvdygMwa/t0sXrVVbmx/v1k7be2uvdpYu7c1ZUpBfMfv/9NED26JF281ywwOUZNMjT1tSkLYqS75eXt882AgAAqRCbOqt+PRs9enQcP358QZYNYOO0YoWDRlGRW5+WL09HdaysTFvnYpSmTvX9xixf7oBSWuoWuBUrPL8ePRxQkla5bChM5l1Z6da6/v3d+pe0eJWWermzZvlv0hompaNQro+v49JSt+xNmpSeN1dU5NbJYcP8WNeuLm+MHiVz6FAHs4oKr+vkydKWWzqUxejXDRjgwDtvnsNjEgyTW7Kdk+UvWOBtVFzcutvAgS5Tff2at6SlsajI0yb/t+Z+ba0D65Ah6fsipe9PEoxbO3BMQ4PnQQsogM4u+V5s7Ptw5cr0ty9r1Sr/DuV/B1ZX+29ZWePfjx31uzOE8EpjjUoELADYgJJKuuTAsnKlK+zJ+WYrV/oHKOnmOHOmr8nWt68fr6x04KusdLjYaiuHhKoqB72FC9OWr7IyX8tt4kRp9929nIUL07D4wQf+AUzOwaurk7bbzt1BFy3ycoqL3YL24YcOUSG4TPPmuUwDBng5q1a57MktuW7cypUOucXFadfOhoY1A1JnUlzs7Za0ZK5a5XVLgndjAbG01MFz2rS0pTgbqrt3T6/JN2RIOvhMjN5+SUtpjK6clJQ4wA8enLaOlpV5v6iq8oGG3r09j+LiNNwvW+b3cehQt6bGmL5nDQ1eRtIVt7bWByJmzvR+1qOH511Z6emLilyO+npP26eP97uGBu871dVeVnm5/29oSFtfu3RJ96ktt5SmTPH2SS7+PmCA96/aWm+XJESXlnrd3nnH22jgQC8zWU5ZWTqSa+/e3k9jTLsr9+nj/buuLj3Pc/Fizzc7EFBFhZ+fM8frl7RKNzSk79mKFd42vXq5HGVlabfp5G/Pnn6Pst2MZ8zwNtx6a5ejb9/0Uh3J9qut9XP19Z7XokVeRnIAp7TU67v11n4+f6CjrbbyIEbz5vmgSV2dy5AMcFRWln5uly1LK71lZV7noiLPY8AAf09kv5/Ky31LumlXV/tv/v9FRWm37eTAy9y53gYDB6YV80GD0u/C5Bajt0uM0n//689A//6+zuTMmV52t24ub4zeZskt2xugujrdF5ODKJWV3n49enhZM2b4Peza1euYbPfaWu+jtbXSttumB+SS0JBcQiXp9p5936ur3Q195Up/Byf7TAjedj17+u+cOV6vHj38vlZW+nWLFqXfKz16pOuzZEn6GUkkn8OGBn8ndO/u7Vta6vkk3/HLlrkcffp4mrlzvYwkAK1c6eli9Gu6dfN3UdKbItluySkCyWjIdXXSTjv5fZw712Vctsyfl+T7smtXl7+hwWWqqPB86+r8/9KlXn6yPt27+/1fvtzTFRd7W82e7e3VkRCwAAAbXIz+0e/du+kLbScVpMZap+rr/SM8a5Z/0LOhJQk5ySUOkrCW3Fpzv7TUf+fMScNwUjlOlrNwYVoRW7bMlYckuPTs2fi61NS48rL55r6/dOnq816+3Mvu18+VlPJyPxaCt92KFWm316QSO2BA2i22qMiPd+/uilFVlStFK1ak23fIEFdaKiu9PWfNWr3yE4KXsWSJX19U5NbKzTZzV9RVq9Lg0bWr55uMglpS4uUl71H37i5XTc3qR6yTgXaSCnRSoe7Z0+Xv08evT1pGk+1eXJyePyl5O/Xo4fVPKmaNKS3165PW28pKb88uXdIDAX36eFnZQYCykvc9hPRIfQjeBkOHepvNm+f9IQkfSeBL3oOsnj29fWatMVxY05KQmrSg1td7uyYHMtoqe5mQbt28DVatav5rs6Et+b+62uuYjDxbX+9tn4TapiSf6aSFv29fB4Y5c7xv9uiRniOcDU7JLSl78p51754Gwvp678O1tf58de3q/Tvpkp4NTcXFfq642Pt/r16ef11dGoCT/0tK0ve8Sxfvd++/n17TMunBEKPLvHy5P2ODB6f7cL9+Ls+HH6YhaPly7z/JAawePbwtsq04SSCX/NyKFennp1+/9GBCcj7y4sVe30GD/HhdncuVfK6TlvzKSgeampq0PNl179PH+39RkUNk0i2+f3/PZ4stXLbkM57sT5ttln6HFhd7Ob16eX5FRd4uy5d7mh490i72Q4dK55/f9nPN21tTAYuxuQAA600I/tFd1zRJaGpKMromNoykwpbfvac9JJXM5PzEJUscFrOVxhhd8SorS0OS5ErZihWukCWPrVqVthok3VX79HElMjtdCK4sNhX0s2WrqvKtXz9X+pYtS/9v6nXJMhqbX1YSNpMBgxYtSlvnFi1KWzyTSn55uSusSUtQly6eT329W5e6dHHZkmXX17uFb/58h5Ptt/c0yUGIbEtT165pYKmr8+PdunnaOXNc+d9yy7R8Xbqkr08GQ0oCUWOqqlZvGUrOAV21Kg3N8+en65jtXpwE0+7d0wC4fHna4r82SfjP7jvAhkQLFgAAAAC0UFMtWK08TRcAAAAAkI+ABQAAAADthIAFAAAAAO2EgAUAAAAA7YSABQAAAADthIAFAAAAAO2EgAUAAAAA7YSABQAAAADtpFkBK4RwdAhhUghhcgjh0kae3y6E8EIIoTqEcGH7FxMAAAAAOr6SdU0QQiiWdK2kIyTNkDQuhHBvjPHtzGSLJH1D0sfXRyEBAAAAoDNoTgvWXpImxxinxBhrJI2RdGJ2ghjjvBjjOEm166GMAAAAANApNCdgDZU0PXN/Ru4xAAAAAEBGcwJWaOSx2JqFhRDODiGMDyGMnz9/fmtmAQAAAAAdVnMC1gxJm2fuD5M0qzULizFeH2McHWMcPWDAgNbMAgAAAAA6rOYErHGSRoYQtgwhlEn6jKR712+xAAAAAKDzWecogjHGuhDCeZLGSiqWdGOMcWII4Zzc89eFEAZLGi+pp6SGEMK3JO0QY1y2/ooOAAAAAB3LOgOWJMUYH5T0YN5j12X+nyN3HQQAAACATVazLjQMAAAAAFg3AhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALSTZgWsEMLRIYRJIYTJIYRLG3k+hBB+l3v+zRDCHu1fVAAAAADo2NYZsEIIxZKulXSMpB0knRpC2CFvsmMkjczdzpb0x3YuJwAAAAB0eM1pwdpL0uQY45QYY42kMZJOzJvmREm3RntRUu8QwpB2LisAAAAAdGglzZhmqKTpmfszJO3djGmGSpqdnSiEcLbcwiVJK0IIk1pU2g2nf979BR3osY5Wno293BvTunS08myK69LRyrMprktHK8+muC7rczkLGlkWAKwvIxp7sDkBKzTyWGzFNIoxXi/p+mYss6BCCOOz92OMozvKYx2tPBt7uTemdelo5dkU16WjlWdTXJeOVp5NcV3W53JijKPzlwUAG1pzugjOkLR55v4wSbNaMQ0AAAAAbNSaE7DGSRoZQtgyhFAm6TOS7s2b5l5Jn8+NJriPpKUxxtn5MwIAAACAjdk6uwjGGOtCCOdJGiupWNKNMcaJIYRzcs9fJ+lBSR+TNFlSlaQz1l+RN4jGujF2pMc6Wnk29nJvTOvS0cqzKa5LRyvPprguHa08m+K6bMjlAMAGFWJc41QpAAAAAEArNOtCwwAAAACAdSNgAQAAAEA7ac4w7ZuMEMLtkj4hqSF3WyxpgNJh6BvbXqsklWv1oeqTfpeNDV+/NrEVr2mOOvn8ufUx7w2pudtnfW1HAEDHk/3Oj/Lvt+TfvVpJCyWdGmN8csMXDcCmiBas1f1D0hflwTq2klQpaaWkekkfSPqkHLrqco9VSSqV9Fzu8XpJyyUty91vkL/sT5X0eu5+pRzKGiS9mZtXVe7xhtz/UR76fkXusSm5+dXm7i+VdETuNVHpD0qtpBpJ1UpDYszN8/Vc+ZLw1yDpqdzyV+b+Nki6KbNu03Pzq8v9nZtb9qrcbUZmG9VIeiu3Lepzt+ckPS5pSaaMs3PTx1w5V0p6O/MeZLdbfWY65f5Pnk9+QBtyy465siU/tCszjyWvTdY9ef+S+dRnlr8yb97ZbabMa97NPJa8Pua2UVZtbv3zl5PMN9l2yesblO4f9bmyJstN/p+eVyYp3W+ykvWIec9FpdugNvN8dpsvy5QrKe8qef9OZLdjnVav2MxQ+tlpyEyfvLfJPpVVm1lW/jok5c5fv4ZGpss+Pl2ry5Y1qzKzjPq855L1qs67n31tXeZ+sl1WNlLu5PNem3ks+Txl55u/byaf7fx1qdaa8vfZZLlJubLrX5u5n78PJZ+t7PbMvp/ztObn6tW8aaT0s5jsb/nlypd97apGnk/2n8Yez98myXdR/mcgu5zsZyuZzxKt/rlMpqvPzb8289wypd8byf6d/J/Mt1arLz95P/O3SzLNs1p9P4xac19O5pOdJqsyU9b6zGPJer+t1bd1nfyeZr/3km2d/M1+vy2Uf6Oy31P1uceSsqzSmp/n7H6eX+Zqrfle5O9P2fIm+211powvSfq8/Du+QlLv3Da4JoRAnQfABsGXTUaM8R5Jz+f+nyNpqqSu8lGwufIXt+QfxqTiESS9Jmm+/CXeRa7Ud89NWy/pMfmHq0jSe7n5LZO/+Jfn7s/IPZ9Uaubm7hflypD8WAZJ3XLTlGXKUJ95rExpGIu5spRq9fc7+dEqzk1flHv9/vKPVHluuuJMOYpy05bn1vPW3LJLc7d+ub8hd/t1bh1XZMo4RWlAKJL0oaQtM+VKKhEht+ykYq9M+YNW/wFPKqddc39rcq+tyj2W/+Ncm7dOysyvJDP/pAyJZFsrt57ZimVSaViQt6zKzGPJNEkZk+eVeT7mypdsw2TdsiFupdZsMS3Rmq122e2UP31++ErCT1KxqlfaYptUWkvk7ZW8Zm5uvknFPauX/L4XZ14TcuudbNfivNfUZabLPpYtZ77sPpF9LLlfkTd9Q249sqFB8v6cLCNbrux2b8jckoMfUT5okP1sLZbXs1R+/2ryXvuBVt9eyRH2pHxJhTWpnCb7RLZcyXYqydzPBoH87VWrNEAl71fMlC+pGCfbLTlYlOxDSRiYnJn3ssw6JeV5Wen2T5Y/Lfc32aezsqEueT+yQbKxinX2c9mQ93iRVu9pkN33GutlkEyT3bbJPl2s1T+z2Yp+dl5ztPq2yh5AyB4AC3n/J7fkuz0/3Gb3qZC3rtnvv8bWKZlHsq2SgJeE3WTaosz/2e+W7HdEsoxaST0z818of79mt3mlVu/RUarGt3v+MpLn8ntaJO9pY3WVZD/rqvT3ql4+OBolDZb0n9zzqyQtksRFiAFsEIwimCeEsIWk+yWdIFcmpLQSMUeuhGyvtDWqh6RbJO0rX2y5S+41tUp/XBbKlZEtlf5wLs/9LZVDi/Jetzb5lVDl5tdNaUUhyqFukNIjsn3yXtvYfNb1uPJeryamlVzJSH4gkx/UOyXtLWm40opqT635I9zcLn5JhTS7zZLX51dSmqO5y06mS46Ql8nru0RS/7xpksCXvDd1Sis2yWtbs+ys/HVN7q/rPVpfkkpm9n2ZI2lgpizrs0z1WjPAtZclcnBL1q1aaQWvqTIk/y/NvXZd3bPrmjGNtPr7nuwXTZWnvTW2H86WNCRzPzlAUtHE9K1ZhtS6z3ZLrO/5o+3y943se/ae0qBVK+knki6RdFaM8Z8bspAANk38gDSuSNIj8rW/TpYrRu/KIWmg0spjt9z0+UfvGyTdrDSY/UPSiNzrku4rK+Uwlu0ycb/SIPKQVu9+tUrpUc4GufVghdKji8lRw2yXsj65/2OurNVyS5nkQPZe5vXZ7kBJF8NFSrs5SWseBa7TmpWfbIvMBK0erqK8PZNKdnKEeGnmNbdrzSO52S4/dfIP5pxMmZqqiGbLlt89ryUqG3ksOSJcnFt+8mPfV2kLQfaoc7YSXKL0SHFSSW+q22LytyazzPzWl+z8s/fzw1XSapHfTSd5rjYzTXbZamR5jUn2G+XmlX1forxt8o9Y/zdzv6qReca8v6vUePnyNRWu8rvZNaWprmk1cqts8p5LaajJ73KWLUNxbp7dtXroSt7zmPf6EqXd+pp6z6U1WzmiVj9gk513fqtWg9KW7uxj2fVdm+TgQTJdrdxqkNWQK0+2Mjwj83xT2zn5m2zbfK05cJJ/P/tYdd5yYiPTVStt7Uu+y5PvzfxW4aRFuC4zj+WZ+5WZ+S7T6u9z8vr8brSNdYtMPjMxM03ynZ3tzps8lm1xzH7ntET2M57dhtl1zu5vizNlzG+dzN8fsy2269LUQcBqpb8x98k9Ub4r9zRpbBsCQLsjYK2pRG6J+kDSzpJ+K39pbye3ViUh5AO5W2BU2gUsW6E6Xmn3qC/n/tZLmpl7XT+t3u2nStLhSiulu+aeq5YDyO9zzyU/iAPkynnSYpZ080ten3T9U+7x8txt89xjPSSNUnqEebH8g7Qit8x6pX3Xm/Je7m/2RzJbqd5Jq1dOknM2PtDq3Yq6Z6Y7Qul+WSd3OUq64yWBpiFXtmQaydtvZe5vg9z1cIlWr0wksvPP/zHPVogSjbUGZNchqegXa83WquR9z3aJSd7DbFe2pGtMyLwuqSxku/O0pGUuPxAny8h2m0rKlD0vJ3k8u4z8rpTZ9U6UZKbL7xok+aBF0pUxuW2TV961rUt2HZL/lSl7tsK4JK+82TImj+e/z+t6z5Mukfn7UxIistsrOXiQbKcVuWXnd4HKHoDIBpaYeSy5teY9T+af3xUsW9HNBtb8wKa86fIrxdn1yX/Pa+TW++zjUdKwRpbd1Loky8gvR/KeJ+e6JQGpsSAaG7kl+3yiVKt/dyUHq5Lu4Em34uQ7PXlN9iCJcq9Zkbdc5V5foXS/SPavhtz/Lyn9nkhu2e9wqfEDSclBvpCZpmvu/6TVMPm+mKv0uy5ZRmMthNnzr7L7sPKmL83MI8pBMXl9Mv9VSg/0Ja/Jyr7/2a6a2XVNfo+yoXOx0s9K8h7VZ17bVf6OfjHGuJPcc2IzrX5ABwDWGwJWRgghSPqF/GX9KUnbStpD/gGfJAed/kqPdCbnd5Qr7TK0Qm7t+pvSynFylDZIekAOAUW5vyXyl/6/cq9dKB95fD73mjL5xPHP5+4nP0KXyi1EczLLSLotVslhJntS+8clvSIHj2zrVNIC837u/5VKKwLflM+ZyracSOkP8GCtXolYKGliZr2TH9ykfMkJ9UNz2+JNSQ/nlp3M+19K1crbP1vRXCK/P/Py5pucB5Zso5fkH/ZVSo/q5rdeJF38shWMVVo9ENXJATq/JUVas0IUJb2h1cPKCqWVqWxoybZ+1sjnniUVxGwluUppBTmpfHyoNEhmZU/oT+4nf7OtIdlyKzef5By9ZBk1Wv18svyKcH6FPyo9L0lac6CBKGmfzHwacuuwUGtqKvQkrQBJJTHZz5IDD0mwXSUH8Aatfh5T/vZKzmmU0tbYZBCK7HZM/iYHM7LvueTPYPZo/hytvk9Iq1fg6+Xvkmcy5cqGifxglRwESAYoyIac/FYwZR7PtnBn3/PkNfnhK2lhSdY5f7CB/Ap58pr8wSCk9Duuf+bxWqXfS4lFWlN++FuqNQdASd7z5DPVkHksO1BCsm3zg2PSPTuZJtuqlv2cBvk7ODkwkBz0Sir92W2SlKOb0oMNpZn5JF2ikzImr1kkaS+tHlbfzZUpuy2yrVDZfS0pc9ICnXz2Vil9zxfKrTrZgDhRfv+yLW9S+h2Q3ceL86aR0vci2Qb5B0+UW7fse5H/eW4s3OUPmlGWKXeynB5KD7y9IekKpd9xj+Ze01PS+yGECkmHSVoRY8wOqAQA6w3nYGWEEB6VW5Gk1SsYK+VWlhqllayOpkouW1KByj/ama3Era2lYG3acl7CIrmLWFZjP7AAALRU0uU1CdozlLaWTpN0eIzxwwKVDcAmhoAFAAAAAO2ELoIAAAAA0E4IWAAAAADQTghYAAAAANBOCFgAAAAA0E4IWAAAAADQTghYAAAAANBOCFgAAAAA0E4IWAAAAADQTghYAAAAANBOCFgAAAAA0E4IWAAAAADQTkoKteD+/fvHLbbYolCLBwAAAIBWe+WVVxbEGAfkP16wgLXFFlto/PjxhVo8AAAAALRaCOHDxh6niyAAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAAAAtBMCFgAAAAC0EwIWAAAAALQTAhYAAEAH88EH0quvrn2a6mopxg1SHKzFqlVSZaX/r62V3n5bqqpqevp33pF+8ANp5kyprk5avlxatEiaMEF66y0/VlcnzZ4t1dRIc+as+T6//760YoUfX9c+sHixNG2atGCBtHLl2qdfskSaP19atkz6xS+kl1+WZs3y+sTosj/9tOcl+bEHHpDOP1965ZW1l+GRR7w++ZJ5f/ih9O9/Sy++KL33nnTvvdJ//7v2deuoSgpdAAAANkYTJ0oDBkgDBxZm+bW1rtS0Zvnz57vCsyHKPmOG9PDD0mc+I3Xvnj6+cKE0dqx05JFSnz7S+PHS5MnSscdKvXuve76rVvnWq5cUgiusJblaz6xZrmhuvbWXs2qVNHiwVFzs55cvl+65x4999KNSaam35+9+Jx14oLTXXulyFi+Wpk6Vbr1Veu016SMfcZnnzJFGjpTKy/26b3xD2mMPV2CnTPEya2qkbbf1vN97z4+/+aY0aJD0q1+5jI89Js2b5/VftkzaZhvp7LO9LY44wvP86U+luXO93GQdf/c76a67pLvvlvr3l15/3eVraPB6d+0q7b67lz1+vNStm7TddlKPHl6nu+6S/vMf6Ytf9HKKiqRx46QbbpBGjPA8R4/26+691/dXrPD67Lyzt/Fuu0nPPSe99JLDYK9eDo19+0onnCBNn+7t/JvfeHtNnuz5zZ4tXXedtOee3k4TJ3oblJVJxx3nMk6dKi1dKvXs6Yr54MHebvPn+3byyf773HPpdvvwQ+nb35Y+/Wnpvvuk66+XLr5YGjbMZZs1yyFgp52kvff2+7N8uVRfL/3jH/5MzJvn/WnYMOn55/0Zv/9+b/PTT/c8KytdnoMOcvmPOcbr06eP94dHH/X7cO216T6UtcMOfl+y4eL446Wvfc3Lf/FF6Q9/8Oela1eX79BDvb6DB/t9rK72+7V8ud/fhoZ0XiUlnmbECGnIEG/Xl17yOt9xh9d7yy2lN95IX9O3r7fL00/7flGR9KlP+b34y1/82E03SVdcIfXr533svPP8vnbv7m2/dKnnceihfv/mzfNn7oUXpK228v6QH8BKSqT99/d7M26c36fOIMQCHfoYPXp0HD9+fEGWDQDYNMXoiuigQa4k5auq8q1//+bPr7ZWuvlmVx4OOcSVzjfecGVl0CDplltc8dxhB1cSHnrIR66HD3cFbL/9XIGvr3eZ3n/flaGXXnIrRm2tK2Vf+YqPcN97ryttH/+47++4oytwJSWusCxfLnXpIp1yio8+n3mmtM8+rohttZUrKVdc4TJtt53LOHSoA87LL7sC/e67Lsthh0kXXOD1Ki+XnnrKFchhwxxy7r/flaKdd/Z6TJ7sytKSJV6/ESO8HnPnupJ+8cXSJZe4ArrLLl6Pe+/1Om6zjbdpfb2D3SuvOBTtuKOX9dxzfr6iwhX38nKvQ12dtMUWrqRWVvq5T31KOukkP3/AAS7LmDGuNG63nUNLdbX/f/ddz3eLLVzZfOUVb/+6Oj/ep4+Dy7x50hNP+L06+WQva8YMB4YYvf13280tENXV6T5SVuZKYwie16JFa9+nunXzPrjjji7/hx/68dJSh4mFC/1expjer6/3NEOH+rW9e7sCK/m9j9HvQ77dd3eIS7aB5HmvXJlu68pKL3vYML/XpaXp8+vSpYvf46yBA72PZueRbKOsXXf1Z6FnT5dzyBBvuwce8PszfLi359Kl0uab+7O1dKnXvaTE70NxsUNajx7eN0tLHWL331965hlPl7zPzdWzp7d3ZaX32QULHHLnznUQ/MQnpI99TLrtNn9+V63yc6NGeT3r6vzZPf546Wc/cxjZaSeXddgwb5tf/tJl/eIXvQ9UV0tXXrl6Wc891+WorfUynn/e7/+cOX7vi4u9P3bv7oMCI0a4zJWV/nxOnOggO326A+juu/u7Yaed/L698op0441+X5LP6ZtvuqVql10cvq++2mW7+GLprLP8fTFjRlrGQYOkww/3/Hv08PfIr37l77/NNkvX9+CD/X4NHy594Qv+LC9Y4M/k7bc7IG6xhQ8aDB7csvdrfQshvBJjHL3G4wQsAOgcJkzw0eHS0ta9fvp0/8jlH/2fO9c/1JtttvrjH37oo+qHH954GJH8ultv9bQ//KHvT5vmilB5uX9A5871j/ygQa7QvPOO9K9/+fmnn3YF8YADXHH62tdccais9FHet95y5WD4cOnBB6V//tNl2n9/6ZxzpMcfl377W89r//2l7bd3Jaa+3iHplFNc4fzb3zzt1KmugJxwggPFLbe47Mk2eeMNVyhOOsmPz57tykgI3j7Tp3u+I0e64jNunNdt6VK/PgQHmiee8HJXrfLrs4qLXVmcPdvlTMJVQ4OPCmePNBcVeZslIWvVKi8vBFdMEsOHuwL32GPpY6Wlrsjdc49fn/XRj3pbvfWWKz/vvZdWhPfdV/rkJz3/v/zFFabiYoeoiRPTSndtrbfDRz7iytikSd42++3nSvTUqa4gf+QjrkRed53nv/nmrvg9/7zLeMopfu8uv9zbpXt3h5mDDvI6nXuul//LX7oMf/ubu2DV1np/llyR7dvXZUu2wahRblH41a9c3jPP9H755psOvyNGSM8+6+DXq5dbepYv93KTlpKFC73P/ec/fu3llzvovfyyK/cDBnj6nXbyeg4f7v3i6ae9Lnfc4f39F79wi9CsWX58p51c1hD8uS4rcwAfPtwhcPZsz3vSJOmaaxzoknI9/7znW1vr8DtnjrdHz57eNoMH+7HttnMrwle+4m3x1a96nULwe/Phh359SYmX0bWry7Jkid/HAw7wwYIxY7wO06f7ffzxj/2axYvdnWvxYleua2ocDp99Nv2cPPWUP7/HH+/9d/Fif46qq6U//9mvOfJI6f/+z38POcTTrFzpfTSR/f5Ztcr7TdLa2JgY/T4PHbr6wZLKSlfgp071tvjGN7zNunZ1hb6oyN8L//2vW4m6dvV2XbZMOvVUvydJKFu4cPXK/sqVft0uu6xelpUrHW732cfBpbXeftv7xfDhLsOWWzY97cqV/k7JtgivTfLds2KF38OGBm+PdYWZd9/1dj75ZL9HlZUOT1OmuFX6oov8HmzMCFgA0ApJZbeoGWesjhvnyujBB7urxogR/kHs08cV+IYGVz4228yVmBdf9A/Se++5Unraaf5Bl1xBePhhtwYsWuRpHn3UR+ZvucU/au+/78rDBx84yMyZ40rsokWu8Awe7DItWuTyPPGEK2hJi8m4ca6Evfqqy3bQQf5x/OlPvdyrr3ZF4gtfcIX09793ubfZxhXtww/3a5NuLF/8oo9yru0Iff4R40GDXDF+5x1XGKZOdaVw7lz/2OfbbTcHg8ce8zpJDgP9+nn9pk93xbOoaPVQUVTk9d5qK1emr7nGj48c6QpREpC23dYVk9tvd2V+q6383tXUuHK8+eauWP33v65Q7L+/1/fkk72NLr7YrVlbbeW/yXswbJgrI0OGOMD06+f1e/ZZV0JLSlwBTVpViovdgrHTTl7Oe++55WfffaVvfcvTPfOMjzq/+KJ01VWu1Jxzjrfj3LmuIO+3n8s+c6YrXa+95nmfcsrq+/TcuQ4Fe+7psidqavyevv66g8XgwdIf/+hKZ2VlGvYkV4x79246jF9/vYPBLbe40hVj09NmTZzoSt/aKpRZt9zi93fMGO+rScvG9ts37/VNaW55O5pp07zfNlb2+fO9H/Trt+HLBWwMCFgAOryqKlekmmP2bIeFpioGy5b5qHNpqStXW2/tyvuvfuUK5vHH+7np0135XbDAlcyRI93dY/58B5YrrnBAOukkH70cOtSV2R13dDeQRx7x0clttnEgauwrtW9f6etf9xHsiRPXfL5XL5extNQV2AULXHFNKj+9e7vyffDBrjSG0PRJynvs4fI+/rjv9+nj1oTycrdmLF/uCvmKFa5Mv/22A0ZJiSv6DQ0+ai5JX/qSy37llb6/3XaupH74oY+IP/SQj7pfcIHPT/jnPx0Izj/fwa+qyhX7QYNcGZ8zx0efR4xwN5rSUq9ncjS8d29XjJ9/3tvk9NPdTejRRz2vXXZxoJA8n1tv9Xt55pmNVx4//NCV7QED/H4PG5Y+d9NNDhxf+craj4S3Rm1t61sZAQCdBwELQLtJujwcfHBasV21ypXgvn1Xn3bKFIeLvfd214tRo9wN5YIL3Grxla/4aPoFF7iL2LXXurL92muuGM+Y4ZPa77nHFeHzznNXnhtucBgoKfGtosKBYdEiH92fPn3NrlmSA0CvXqufz1FZ6QCSLC/r0ENdYX755fS8ii22cMCrrnbA23tvdy07/HCfPP3GG26pmDrVQePPf3aL0+67S9/8psNUly7uotK9u7s5PfmkA9qsWS7HggXuuvTpTztIJv7yl7Tb1ahRnm7zzb0t6+sdJEJwSCkp8XQtOeq+bJm7ZH30o9KXv+zHkhGlRoxIT6Bv7HV/+5v02c+m3bYAANiYEbCATUhjXVkWLHAXri23dCW/d293g9pzT/ezX7jQIaC62i05hx7qaevqpDvvlL7/fVfg99/f3ZXGj3dgOvxwV6yfesrLueQSt0I98UR6EviiRekJzYMGpSM/jRrlLlIVFT7iv9VW6bDEQ4e60t67t8NSr15e/ooVruSfe64r/IsWuYyLFjkEDRjg+XXv7haYbt38/wsvuLvTl7/sZSUnPCfnTCRdnWbM8PIGD/b9ESPSbZkMo7v33mkL1+67r7sFpKbGgWzEiHZ6gwEAQMERsIBOrrraJxTX1Lgb2447eqCAiy6SPv95d4eaOdNB5NFHXZk/91y32Dz6qIc7Trp+Se46Nneu/+/a1S1Q2a+DkhIHoGnT0u5ko0alIziddprPqZDc9erzn3dr1ZgxfiwZvWjJEo+m1KePh8V99VUHlp/8xK0/H/+4W23uvtvh6AtfcMvY17/u6Roa3KVtm23ckvTKKw55nDMAAAAKiYAFFMjSpWkXtro6t3Y88UQ6wEH//n5+s83cve6pp3yuztKlfj4Z8vWSS9w1LN9WWznYdO/u82HmzfOQze++6+VI6blKN97oc1ouucRd8K65xi0r48c7mB10kLuu9ejhLnjTprkl6cADfQ5ScbHLVFXlMJRcsyLpOhajW3iGDGnZMNdS5zx5HAAAbLoIWEA7qa31LRkdLjnnKLnCeY8ebi26/HKfSH/GGe4et/PODjybbeaWJmnNIZkThx/u82pqa936Izk8/fKXHqzhrbcctnr0cDe4KVMcoLKhJka3eC1b5vN4ysvX73YBAADYlBCwgLWI0UMe/+c/vlBeSYlHH6urc3e8hx/2OTlHHulriSTXiykuTq+YvmiRb8kIbyGkrTJ77eXWnk9+0q1CRx/tEdK6dXNLVV2dQ9eSJW4xGjkyLdujj7r73xe/2PQAAwAAANiwCFjY5NXWOii9/bZHb5s716O8heAR3P76V08XgluWunXzuUnz5jn0JK1O++/v1w8a5IESJkxw97zu3T1iWxKUjj/eQerCC321dgAAAGw8mgpYHA/HRqW62gMvPP20A9LIkT6XaPPNPcBDcmHSSy9d/XUhSD/6kYcM//GPPZ/f/MbnJc2b526At9/u6/788Y/NH4Z6zhx3IwQAAMCmgRYsdFjZwQ9WrPAgEQsXenCIadOkceM8uMLw4e46N3Omrzc0darPU1qwwN3vDjrI50CNGOER6nbayS1ZW24pbbutz4EKwfcBAACA5qAFCx3W8uXukldR4fs1NdI3vuGR9Pr2lc4/X/rWtxykZs3yKHaSB3RYtGj1QSL231/60598gdbKSp+7tP32a45Qd845G2TVAAAAsIkhYKEgPvzQXfcmTHC3O0naYw8PEb54sfT6677O0qOP+lpOO+/sYcH32svhaPPNHbgqK9MLzXbp4hH6EhUVHnkPAAAA2FAIWFjvFi708OQ//alDU1mZdPHFUn29tMUWHma8tNShqqbGj990k0fNe+cdt0h9//uNX1cpGVwCAAAA6Ag4Bwvtpq7OrU99+kh33unWqYcfll591c/36ePnJemEE6Rrr5WGDStceQEAAIDW4hwsrBdLlkhPPeXrR915py++27evu+0VFUm77ipdcYUHljjiCOmHP/S1oy67zH8BAACAjQkBC80Wo7v7NTRI110n/eEPvpaU5OtFHX64rwP15pvuCnjCCWuGqCuu2PDlBgAAADYUAhaatHChNGWKdPPNvghvdbXPkUocf7y0774euW/vvaXy8oIVFQAAAOgQCFhYTU2NrzFVXy/ts4+7ABYVSaefLg0Z4lH6ioqkUaOko44qdGkBAACAjoWABS1bJv3zn9J77/k8qvffd2tUjx6+v/POviAvAAAAgLUjYG1CYvQFd2fN8pDoU6dKL7/sC/pWVUklJQ5TP/uZrz91+eXu/gcAAACgeQhYm4Dly6VLLvG5VKNGSW+95YEqJKlnT3f/O+ssX8Q3BD/+ne8UrLgAAABAp0XA2ohNnSpdfbUv2rt8uXTKKR5G/eKLpeOOk7baSho0yOdUAQAAAGg7AtZGZvly6f77fU7Vv/7l8PTpT0vf+pY0eo3LoGGTMmuWRypJmilb4623pH79PNpJY5J+qMnyli6Vtt++9ctrjkWLPNwlOzgAAOgAaLvYiNx7rwejOO006YknpIsukj74QLrtNuqeG1SMUl1dy15TXb3665ct89+1LePvf5fOO0+qrU0fHzPGFyTLX/4jj0hDh3ps/Xnzmp7vu+9KZ5zhwPLii9Lkyelzt94q7bGHrxidXea8edLKlV52//7SffdJM2a4z+nee7vZVJLmzPF6Pv20dMghbmJtyrx50oIF6f3HH3dga8yXviTtt5+nnzzZ67jzztIXvyiNG+dbtryt8dJLPlmxo8leN6E5Zs6UVqxYP2UBAAAWYyzIbc8994xoPw8+GGNxcYy77Rbjk0/GWFdX6BJtpMaNi3GPPWJ8+eUYb789xkceiXHVqhivvz7Gf/0rxurqGC+5JMattkrfhJqaGGtr/X9DQ4yvvpref/fdGHfdNUYpxsMPj/Gzn41xs818v1+/GJ95ZvXl19fHeM45MY4Y4WmkGG+5JcZHH43xtttirKjwY2++GePEiS7vypUxfvzjMfbsGWOXLjGefLLntWBBjF/8YoxbbhnjwQfH+KMfxbjFFn599+7+u+WWMVZVxfjCCzGGEOMOO/jxgw+OceedvYxBg/z/Zpt5mhBi7NrV8ygri/GUU7yDdukS45lnuiySl/XIIy7PscfGuHixt893vxtjebnn2dAQ49/+5un794/xP//xtt966xhPOCHG665Lt8OFF8bYo4fX87jj0nWQYrzggnQbrlgR4+c+F+Pdd8f4y1/G+PWvr/6B+fGP022UvGfbb+/5XH55jBMmxPjEEzFOnuznYoxx5kx/8BYubHy/mTrV+0uynH//O8aHHlpzuv/+19uqMVOmxPh//xfj2LHeDkce6e08fnzj0z/9dIzvv5/enznT22bIkBjvuy/GDz+M8TOfifH11xt/fVNefTXGb387xj/8wft2Y267zftlsn3Wpq7O+9jaVFU1b16tUVXlz27ymfzgA2/jzqCystAlAIBNmqTxsZGcQ8DqxOrrY3zllRi/9z3XR3ffPcZlywpdqnYyebIrhO3pgQdivOGG9H5jFbYFC1xpWblyzcryqlVpwOjd23+HD4/x2mvTivxxxzlISK6ET5niMPSJT/j/j3zEz11xhed55pkORd/+dowDB8Y4YECMn/50jD/7WYzDhsU4erTL+cwzDhQXX5wu57rrHM569kyX37Wr//7mN2k5ttoqxpKSGC+6KMYf/MCPvfqqw1VJSYwnnRTjnns6GHXr5kCz994xfv7znvYb33Co3Gwz72DHH+80X1YWY58+nqa42H/HjnUI+PrXY3zxxRh/+MO0bEVFLl+XLjEecYSDmRRjaalvO+3k10pebynGn//c0++7r7d9t24OV/37xzh0aBoGt9suXf/Jk71t582L8eabY/zkJ72eEyf68SuuSMuU3A49NMbNN4/x+9/3tFKMb7zh/eHll9NAmP+6I46I8Z570vXv0cMB+7rrYjzsMAfIMWPS/WXvvR2uSkv9vs+eHePSpTGeeKLf9yQUXnRRjCNH+rVPPhnjgQem5Upu/fv7tuuuadCpr49xzhwHtdLSGAcPjvGmm2L81rdiPProNLiGkG6/zTaLcdq0NT8L773nsBGjPxN/+Yu3Z79+6fr+9Kfp9EuXxvjHP8Z4112ev+RlVlf7+Ysvdrj+v//zl9aXv+yQ+dGPxti3bxo48z+XS5b4c3bggat/Jhct8ue0JT74wO/1177mbd/Q4IMaUoy//72XNXKkt/WSJS2bd6KhwfvN2iTvUdaqVQ7/zZXsdxdemIZDAMAGRcDayNTV+SB7Utc69dQY584tdKnaSXW1K3277uoKY+Ktt2J87bXGXzNnjo+oJ5W5xIoVMX71qz5av802ruRPmODwtuOOMV52madbvtwVviQ4lJe7kpW0KO27r0NIUqns2tWtO5KDwvbbu9KYBInycrcObLml7ycV9F69HAaGD/cye/Rw0InRFbNs5fIvf/HrbrjBZc9W6pPp7rrLj518coyPP+5t1Lu3w5nkQNW3r/9/5x23EvXpk1auL7kkXd7ChTHOmLH69ksqn1KM//iHH6uqcuX0Jz/x4yec4BaAX/1qzfelocGh6ze/cctMMq8nnvD6X3ONW9kefTQNa4cf7orzwIG+P2KEw9Ls2WnL3f33uxyXXeZA+JvfrFnhT8yf73lvt52X26ePW3++9z23PF54YbqcJLCVlTkMFxU59JaXe/s880yMf/+71+myyzx9CA4t990X46c+lb7fSWui5H3n2mvTdezb1/vXKac4dBQXe30POcSBI3nd4MF+fPjwGL/zHbdI3XST17my0ts9We9nn/VnJgSHhIoK72/JPik5QFZVOdCVlsb4u995HxwyxAGnocGfubPP9ny23tpBK2lVTYLdf//rYN61qwPjO+94v0ym2Xprtw5KDtuTJvn/bHmSMFlU5P07BH9Wt97aBxBeeMGtjElZyspi3HZbB+UJEzyvPn0cvIcP9779zjv+3H31q27B69PH63rrrQ49557r7V5aGuNpp8V4441puQYP9vZP1uGuu7z/vP56jKef7rD45z/HeMYZDomTJvmL+PnnY7zjDn92qqs9bQh+vxtTV+f9pbzc71+M/gyMGBHjLrv4+ez33hNPOBC+8orLf+KJfh+HD0+D+2mn+b17880YDzpozc/xypUuz8yZ/n/GDB8s+fWvvc2Sz/Wjj6bLrqxMg+KKFd7m2SN49fX+4bnttqbX84EHYvzFL/xZj9EHK370o/T7q77ez60tII4f7zLX1Piz3NDg1uAjjnBrd2taNuvq1nxdst51df69AIBmIGBtBJYti/HKK90YktT1f/hDN4xsVG67La3kXH65K5bnnZceFT/oIFe4E9XVMe6zj5876SQfZf+///N8rrnGjyfPJ60IO++cVu7+/W9XaouLvZyLLnKXss99ztMcdpin33lnV7BidGVu8WJX+pIKbm2tK8sXXJB2gysvd0Uvaf0YM8aVsaSsSdhoTG2tmyWTct94o+c9fXo6TUODK2fZCkpS0e3Z05WSyZN9tDvxxBNe3912Sys+TUkqkI89tmaFZOVKb+eklWNdGhq8zAEDGu/DOnVqjOefH+OsWb5/5ZWu+Ga7sE2dGuM//7nma6uq/N7kB+zEk0+mLX1lZa6sZss1Z47X56yz3LXt05/2tNts4/3itNMan++FFzoovPlm+tjMmd5my5fHeOmlnl/y/kyd6n3j/vu9nyXv7VVXpa9fssTB79FH/VxJydq78Z18stepWzfvZyee6Ndddpkrp//4h8vy+OOrd1VNWoPefNOBTHJY+c530v0+2Qbdunm/ef75tNvhBx+kFfzk9vOfuzX2jTc8zbe/nc63rMzbOQkQlZUu4913+/8vfCH+r8U1+Vwlt698xe/hwIF+P3r0cCA67TS3SEleVhKOJZd5yJC0pXTwYLeGnnWWW2XLyvzc/vt73slrbrjB+92ZZ6ZBv1evNGT26pUGvuyBj+TAipR+v5x3nr9HjjjC+9ycOel30ogRfs3XvuZyJdvys591MHzgAW/zpCU6+T7Zaaf0u/Dpp9MDHd/8pg8EJdsiMWtW+oNx8MFpiEzCblmZ97/kiN1xx3kfPPpovxfvv5+2jHfr5v2joSEN98OHe7966il/zyYHwc46Ky33D37gH7Dhw33/oYf83g8e7PsDB6YBP+lBEKP3N8nvxcknuxynnZYG/WS9s5/7P/3J+0vShffBB33wLbn98IduhT36aAe2GB2ottjC++App3i+xx7rgwN/+IO/c266yaE/Ru8j2d4Q+RYtcovreeelRz4bGvxbM326DxIk82qNhoamu+e2h/r6ps8zmDUrxt/+1i2uzZXsL3/844Zpba2s9Ocne6BiXebMWffvIdAIAlYn9qc/ubdW8ls+apR/R5NeZh1WdXX6I7BihY/8Pvywf2AefTSd7vOfd4Vizz3dQrDHHl7JHXeM/2shkHxk+Le/dYVjm23SoNCjR/xfM162UhZC2gqSVFSTLnL9+rklIqk0FRW5VSDfun5ETjjBr89PuWPG+PG//MX3x43zGxmjt0nSgrTttmv/EaisdEvL97+/9nJkJS1pn/pU81+zoUyc6K6DzdXSLmBr89//uiWjOYFwwgRXjOfPdwVzbX1vW3seTEODl/PKK00fhf/pT9N9qClz5rhFbLvt/H9DgwNZSyoXVVUOgkml9dBDvZ8mLaHf+U7jr1u40JX8W25p/Jyy2lp30ZT8OV+b5GDBypUOfX/9a4zPPefgnGz/mTPdanHMMe7mmjjoIC+jSxe/z0m30Bdf9HZ47rl0Xd55x/th8r3w1FOex733pp/jk092OLvpJk/z6KP+LnjpJW+X2bMdhPbZx+V86SUfbLjoIm+H2lpX/CW3luUH0X339Xfiscf6/l57uSKeHFAJweGvosLh9PnnPe9Jk1y+t95ySE+22ze+kc57xAgHzcsv9/mE223n+1/6UjrNGWd4Gz3wgI/YJY8ff7y3W9LlNgnaIThQJAcefv5zf08nweuMM9JweeCB/m6VfMDkE5/w8o87zvPp0ydtyf3Yx3wgZaed0rCXLHe33dIu1clvQPK6M85wAEjWe4stHJSTsJ1Mn/3+z94OOsjl3Xdff3533DEtv+QyDx2a/rZkb9/9rt/T4mK3Wl9wgT8fe+3l1vexY90roajI04we7d/CM89M1zEEL2/OHL/vRxzhlr0PP/R7llT0//IXH5C5+mq3Oj7/vN+HAw/0vI880q/91rf8mamuTvf5e+91OMwGmhUr1n2+4+LF3vbJeajjxrmnw7vvOjgm79XVV/v5++5zKD3gAN/OOy/dT2P05ybZbyRvj6Qbd1ZVld/DUaNiPOoob+fk+7+6es1gVlnpz+ubb7pltKHBAfnww9MDqtdd5+fuvHPt3XYfesiftUMOaf25nnV1LQudifb8jUNBELA6qRde8Pd0r14+yPz004UuUfSX9J/+5B/87BfKzJlpN7IY/UV33HH+4kmCSI8eabiYMMEVQclfqMnRTMmtUK++6i4sS5asfm7Cc8+lP5zdurnbTNJN5d133aVp4UJ/USdH8ouKfMSyocGVteRLdOJEV5CS83NaauLExivADQ0uS1OmT/dR/nX92LXGv/+9erjDxm/27Jadv9OUSZNcOUxC6DXXOGg0NXhHc1RX+8BIe59TmfXPf3qf//GPfb+2ds3zymbPXv0L9LjjXHltzC23eH7du7vy3dpK13/+4++BuXPdKvmHP7jSl7TA19b6yH7y3o0b50FsHnvM31mjRrnczXHrrQ40r72WhozkvMqnn/Y6fPGLPsiU1dDgcl16qf+/+eb4v5bEpJvr4Yd72vp6h9vke/rGG9PW+UMP9QGB5Lm993YYffttr0tZmcPUL37h508+Od2ulZXeLhdd5Hn8+Mdpy+P//Z+D1ciRriTfc8/qrSv33usyHXKIu2qff76/X3/+cx9kuvVWb8M5c3xL9uWrrvL8v/99/73vPu/vP/tZWq6GBgf2V15xKEgCXHl52vU6OTdyt91W/w275BIvW3LXT8nr941vOBCF4PcjOXJaVJQOpnPIIe7yW17eeMgbMsStdNtt56BbWurHk/frC19Iw+9HPuLfmo99zGXt3t0B8qyzHJjuvNOtyHV1DsZ7750u59xz0/932CHG/fbz+7j99v4N/spX/NzQoT7YeeCBXu7IkQ6LP/952qPiJz/xgcc+fVyh+fWv/V7/9rde9iWXpCE/aXE96CCHzaOO8sHI6dP9+3/WWasPYiT59z2pE5SX+7PTq1d6vmhJiac59VTfHnnE7/HLL3v79evn6f7979U/H7Nm+X1LBmJqTHW1w+WoUWmQu/tuB8CVK1cfiGjmzLQL7+uvu4yXXZYepEnqVJMnu4zJ/FryHbRggetE55/vAys33th4+JswIV2n++7zvvjss75fX+/tnV1uXZ3rPI0F5NZaX4MXbUAErE7mv//152LQIPeqWLq0gIWpq/MXxBtv+EOXHC1OWpWSH7vkCGnSlSipoNx3n/+/9FIfIe/Txz8Ep57q8yUqKvxFP2uWj4plu1s1ZcYMV0ReeqnpaSZM8JHF6mr/iLQ2RHU2NTU+YZ8jY2gPneEHsKHBlZGWdj9qat3q6lzpGThw9YNGG9K4ceseLKMpTz/t7qgLF/q7taXuvtutZKef7u/uW29Nn6usdCU06Wb74os+J6qhwdv/5JP9XZ89ePTii2ngTbrzrqs71qxZPm+sutoHzZKuw+1lypQ02Iwc2bz9/P333dX40kt9jt7RR/vHOtnvkvMir7zS37/19Q5ASatfVtJy2LevuzEOGOD7Z565eovdnDn+7fr5z73M999fcz+fP99B5UtfcqiUXM4//CENXV26OMSceWZ68PGCC/x8WZl/i5PyXH992up6zDH+/UxC+113OeQkoeW881avvD/0ULq8pMXu979Pn586Ne1+nG11DcHlT/z9737swAPT6ZLtUlHh9bjpJu97yYBMO+3kA6gzZ6aDE+2zj1upL7jAIXHkSK9jnz4+kDRypAc4mjvXgXXIENcbBgzwfr/HHg5pIThQnn++Wyu//GW/L/vsk7a0lpR43caN8/0TT0xbss85xwewkkrdtGnpeb/duqUt7Ice6v1oq618v39/14m22cYHIa691u/Jyy/7c/WrX/mgxb33OiwtWpQexO7SJW31PeYYv0/33+/37De/8Xrtt5+DbxJE99nHn4Vkmw4f7u2cjPCbvBcPP7z6PrhggT8Pv/rV6p+ltfWkuOwyh+mkh8JVV/kA0Guvtc8Bww2EgNWJ3HabPxfdu3t/ffnlAhfo5z9PP1TJkaXf/z7t+z90qH+Qky/kffbxEafkNSec4CNEVVX+Qps2bfXzT84/v8ArCABYwyuvuJWvE1V2WiQJP5df3vzXZHtANMeUKelgJlkTJvi38e23ff/JJ92CFqPD7SWXrFmJbY5Vq1w5Ts5VHTfOFYnnnlt9uuxvdNIadO65aYX42mv9W54E9D//efXzX198cfVzobM+/WkHiXHjmq5gv/KKt81NN7mF9HvfW7Mr9re+Ff/X1fOJJ3z/b39bc7qaGnexzD84+8YbjXfhfvPNdFTboqL0POjXXku7xybnWkoOIOeck4a8/faL/2vJ7N3bpxp897vpoDnJ+b7J+aLJuYfJa5Lw3KWL16eoyPO94AI/l5zu8PWvp/NIwmoybX6rZjLvPff0a8aO9bZvaEgvZ5J0wU1ev/nm6Wv339/hSErP5fzCF9L/P/e5tFK62Wbunnr77T7ftHfvtPU1afEeM8bnKFdU+IBDvmnT0vJ88YvurpVdl7Iyr3/2AFFLur1vQASsTuLOO/35Ofjg9dujZq2ef97dZ04+2UdFBg50q1Vy9GLvvdMP7r/+5aNGyShl2f78ydHPEPwhzVq40B++W25pemACAADWlyuv9MG/5g7UszFJRnU94AAHubPPbt05RI1p7flI+VascItQtgW1vZx3nus22fPBY3S5x41zF8fevb38ZFCgU09NQ+/3v+8glT9YSTKwzxlnpHWhZ55xID3lFNepjjvOjyfnff/2t+moo0mg6dLFXZeSbpjnnusuqDvs4GD6pz+5/jVrlqd78sl0gJZLL11zfR96yJfK+PWvHYxvucWnX3z84+4GvWCBg+qBB7o7ZjJCZ319OtKu5PCfHFyX3P01OXdzzBgfJEi6WyYj0ZaUeLlXXeXtduSRXmZpaXpuYjJw0bvvej5nneWguOWWDspPPeUDIlOntude0C6aCljBz214o0ePjuPHjy/IsjuquXOlbbeVdthBevRRqaKinWb8/vvSG29In/iEFELT09XXSz/6kfTTn0qDBklFRdKsWX7u8celQw+Vnn5aGjVKGjx49fnvtpvUtas0fbp0772eZqedpJ49paoq6aKLpCuvbKcVAgCgjerqpGnTpK22KnRJNryGBulb35I+8xlpv/0KXZoNL0bXeUpKmp5m3jzXYbp0afz52lqptHT1x+rqpP/8RzrkEOmYY6RFi6RXXlm97rVkietkBx+85jz/9S/ppJOkk0+W7rjD0952m3TWWVJlpcvSvXvTZX7vPWmbbVx/a46GBm+L4uK1T/Ptb0tlZdJVV0nz50tbby3ts4/re126SNXVUnm5p1++XJo0SdpiC893t938OZO8HXbZRaqpkU49Vfrud6Xf/Ea6/HLp2mulz342Xe5LL0mf/KS3c3m5b6+9tvb1L4AQwisxxtFrPN6cgBVCOFrS1ZKKJd0QY7wi7/k+km6UtLWkVZLOjDFOWNs8CVira2iQPv95f57eestBq00zy364jjlGevhh6aCDpJUrpauvlvbdV5owQfrLX6Sf/ET66lf9wV6+XDrjDE8TgvS5z/k1Dz209nD21FP+EBx++OqPH3ig9Oyz0r//LZ1wQhtWCgAAoJNYvtz1sV69mv+ahgbp0kul00+Xdt11/ZWtrRYskPr0WXswSyxcKC1e7AP3paWNB9YYG69jvvOODwAsXy4995y0995tL3s7a3XACiEUS3pP0hGSZkgaJ+nUGOPbmWmukrQixvjjEMJ2kq6NMR62tvkSsFJvvimdfbbD+ve/7yDfapdfLt14ozR2rFuRFi50a9POO/uow/z5PmL1k5/46MPMmd55n39e+vSnfdTkk59st3XThRdKv/61jwT1799+8wUAAMDGbcIEac6cNQ/gdxBNBay1tI3+z16SJscYp+RmNEbSiZLezkyzg6SfS1KM8d0QwhYhhEExxrltL/rG65FH3GvuySelvn3dCnzaaW2Y4ZIlnuGKFW56/uIX3fxdVyfdcIO0xx5ufr3/fmn2bGnpUu+wjz3m7nx/+1vzjka0xMUXS0cdRbgCAABAy+y0k2+dTHM6aQ6VND1zf0busaw3JJ0kSSGEvSSNkDQsf0YhhLNDCONDCOPnz5/fuhJvJGpqpC98wd1lv/Utt4Kefvrae+GtZvJk91e94w7fr65Ow9Utt0gjR0q//KVbqrbeWtp9d0/38Y+7VeuRR6Qf/ED6618dsv74x/YPV5I0cKB0xBHtP18AAACgA2pOC1ZjVf78foVXSLo6hPC6pLckvSapbo0XxXi9pOsldxFsUUk3Mnff7RbPBx6QPvaxFr74gw+kvfZyn9YQHKZOOEGaMcMz+/znfZszR7rmGvdZTZLbUUf5RME+faTzzpO6dfOIGgAAAADarDkBa4akzTP3h0malZ0gxrhM0hmSFEIIkqbmbsjT0CCNGeOGpa22ko4+ugUvjtEjtnzve57Rgw9Kxx4rnXiiw9Vtt3n0mcTgwR4RMKtHD+n3v5eGD3e4AgAAANBumtNFcJykkSGELUMIZZI+I+ne7AQhhN655yTpS5KezoUu5Pn+990VcM4c6Re/aP5ImpKkm292F78lS6Tbb/fogEcc4aHRjzrKM+7add3z+dKXpCOPbN0KAAAAAGjSOqv3McY6SedJGivpHUl3xBgnhhDOCSGck5tse0kTQwjvSjpG0jfXV4E7szvvlH7+c48YuGCB9KlPteDFlZVuudpnH3cRPOooP37uuf576aXtXVwAAAAALcSFhjeQhQul7bf3ddeee27Na9Ot1cMPS9/5jvT6635x/kUBZ86UhuaPOwIAAABgfWnLMO1oB9/9rsekeOyxFoarefOkU07xBdpuuqnxK64TrgAAAIAOgYC1AUyZIv3lL9JXvyrtskszXvDMM74473HHSY8/LlVVSffdJ2233XovKwAAAIDWa8kQC2ilyy5zq1Wjp0k99ZSHWH/vvfSxa6+V7rnHg1H84x/S175GuAIAAAA6AQLWehSjdOGFvu7veedJm23WyESXXurWqT32kA491OdYPf649NnPSm+95fOufvvbDVxyAAAAAK1BF8H16IEHpF/9yl0Dr7iikQlefll68UXp4os9Csb993sY9gULPIz6Tjtt6CIDAAAAaANGEVyPDjpI+vBDafLkRga2WLjQYeqNN3yR4J49pb//3deykqRZs6QhQzZ0kQEAAAA0Q1OjCNJFcD15/nmPVfHtbzcSrqqqPBrgyy/7fKuePf34KadII0d6JAzCFQAAANDp0EVwPaislM480+dcfelLjUzws595UItHHpGOOCJ9vKTEj9XXb7CyAgAAAGg/tGCtB9/6lvPTbbdJ3btL+v73fbFgyRcFvuoqdwXMhqvEFltIW2+9AUsLAAAAoL0QsNrZnXdKN9zgwQEPOUTS7NnST38q/eY3nuD++6WaGul73ytoOQEAAAC0PwJWO1q2TDr3XGmvvaQf/zj34KOP+u9zz0l1ddLYsdLw4VzXCgAAANgIcQ5WO/rNbzw44NixmYEtxo7138pKD2rx+OPSpz8thVCwcgIAAABYP2jBaifLlvmaVyedJO25Z+7BhgYPWnH44b5/xRWe8KijClZOAAAAAOsPLVjt5NlnpeXLfVHh/3nySV80+IwzfEGs++6TeveWDjusQKUEAAAAsD4RsNrJCy9IRUXS3ntnHrziCmnQIDdrLVggPfWURxDs3btQxQQAAACwHhGw2smLL/r6wN1XzJGKekrvvOMBLq64QurSRfrGN3wDAAAAsNEiYLWD+nrppZekz54epX32cdIqK5N69fKwggAAAAA2CQSsdvD22z7/6rBtZ0jXfejzrSTpu9+VevYsbOEAAAAAbDAErHZwzz3+u3/5eP/TrZtHEPzmNwtWJgAAAAAbHgGrjebP97gVJ54oDZ4+TiopkR57TFq6VBo4sNDFAwAAALABEbDa6KqrpKoqj2Whb4yXdt5Z2nffQhcLAAAAQAFwoeE2uuce6cgjpe22jdL48dLo0YUuEgAAAIACIWC1wdSp0n//Kx17eLWvMLx4sUcRBAAAALBJImC1wdix/ntS7e3SdddJX/+69NnPFrZQAAAAAAqGgNUGY8dKI0ZIg2un+4Err/T1rwAAAABskghYrVRbKz3+uHTUUVJYMF/q0UPq0qXQxQIAAABQQASsVnrhBV9c+KijJM2bx5DsAAAAAAhYrTV2rFRcLB12mHwxrAEDCl0kAAAAAAVGwGqlsWM9YGCvXnLAogULAAAA2OQRsFphwQLp1Vdz3QMldxGkBQsAAADY5BGwWuGFF6QYpY9+VP5nwQICFgAAAAACVms8/7xUUiKNHi1p6VIPKUgXQQAAAGCTR8BqhRdekHbfXeraVe4eKNGCBQAAAICA1VK1tdK4cdK+++YemD/ff2nBAgAAADZ5JYUuQGfz5ptSVVUuYH3lK9KMGX6CFiwAAABgk0fAaqHx4/33oLIXpeuvT5+gBQsAAADY5NFFsIUmTJC6d5eG/O2q1Z/o378wBQIAAADQYRCwWmjCBOmjo2Yp/Otf0gUXSL17+2rD5eWFLhoAAACAAqOLYAtNnCj9bMcnfP2r00+XunXzVYcBAAAAbPIIWC0wb54HDdy7+im3Wu2yi8drBwAAAADRRbBFJkzw362mPyUdeKBUXFzYAgEAAADoUAhYLTBxojRYs1Ux4z3p4IMLXRwAAAAAHQwBqwUmTpSOrXjKdz760YKWBQAAAEDHQ8BqgSlTpGMqnpJ69JB2263QxQEAAADQwRCwWmDKFGnvVU9JBxwglTA+CAAAAIDVEbCaqa5OqvpgnoYte4fzrwAAAAA0ioDVTDNmSPvX586/ImABAAAAaAQBq5mmTpVO0t2q61Ih7blnoYsDAAAAoAMiYDVT9X2P6FSN0YozvyGVlha6OAAAAAA6IAJWM+005vt6TyPV/Rc/LHRRAAAAAHRQBKxm6rpktt7ofoBKuncpdFEAAAAAdFAErGYqrVmh0t4VhS4GAAAAgA6MgNVMXeorVd6/e6GLAQAAAKADI2A1w/KFNSpTrSoG0IIFAAAAoGkErGaY9k6lJKnHEFqwAAAAADSNgNUMM95dIUnqM4wWLAAAAABNI2A1w+zJbsHqvwUtWAAAAACaRsBqhnlT3IJVMZAWLAAAAABNI2A1w8JpbsEKPWjBAgAAANA0AlYzLJ3pFixV0IIFAAAAoGkErHVoaJBWzHULlrrTggUAAACgaQSsdZg3TyqrpQULAAAAwLoRsNZh3jypQrRgAQAAAFi3ZgWsEMLRIYRJIYTJIYRLG3m+VwjhvhDCGyGEiSGEM9q/qIUxf77UXbRgAQAAAFi3dQasEEKxpGslHSNpB0mnhhB2yJvsa5LejjHuKumjkn4VQihr57IWxPz5bsGKRUVSly6FLg4AAACADqw5LVh7SZocY5wSY6yRNEbSiXnTREk9QghBUndJiyTVtWtJC2TePLdgxW4VUgiFLg4AAACADqw5AWuopOmZ+zNyj2X9XtL2kmZJekvSN2OMDfkzCiGcHUIYH0IYP3/+/FYWecNyF8FKroEFAAAAYJ2aE7Aaa7aJefePkvS6pM0k7Sbp9yGEnmu8KMbrY4yjY4yjBwwY0MKiFsb8+VLf8hUKnH8FAAAAYB2aE7BmSNo8c3+Y3FKVdYaku6NNljRV0nbtU8TCmj9f6lNayQiCAAAAANapOQFrnKSRIYQtcwNXfEbSvXnTTJN0mCSFEAZJ2lbSlPYsaKHMmyf1KlnBCIIAAAAA1qlkXRPEGOtCCOdJGiupWNKNMcaJIYRzcs9fJ+lySTeHEN6SuxReEmNcsB7LvcHMny/1KKqUuvcpdFEAAAAAdHDrDFiSFGN8UNKDeY9dl/l/lqQj27doHcP8+VL3uEKqGFboogAAAADo4Jp1oeFNVV2dtGiR1LWBc7AAAAAArBsBay0WLJCkqPI6zsECAAAAsG4ErLVY8fhLiipS18qFtGABAAAAWCcC1to8+WT6Py1YAAAAANaBgLUWlZWZO/PmFawcAAAAADoHAtZaNMxfKEmKIUjHH1/g0gAAAADo6Jo1TPsma/EizdRmGrBqpsrKCl0YAAAAAB0dLVhrUbJkoZYU9SVcAQAAAGgWAtZalK5YpGWl/QpdDAAAAACdBAFrLbpWLVRVl76FLgYAAACAToKAtRYVqxaquoIWLAAAAADNQ8BqSozqWbdINT0IWAAAAACah4DVlMpKlcUaNfSmiyAAAACA5iFgNaFhwSL/048WLAAAAADNQ8BqQuU0X2S4ZCAtWAAAAACah4DVhOUfugWrdDAtWAAAAACah4DVhJUz3ILVZSgBCwAAAEDzELCaUD3LAatic7oIAgAAAGgeAlYTaue5i2DPLQhYAAAAAJqHgNWEOH+hVqhCfYeUF7ooAAAAADoJAlZTFi/WIvVVnz6FLggAAACAzoKA1YTiZYu1rKi3SksLXRIAAAAAnQUBqwmlVUu0vITmKwAAAADNR8BqQteVi1VZ2rvQxQAAAADQiRCwmtC1ZomqymjBAgAAANB8BKwmVNQs1souBCwAAAAAzUfAakxdnSrql6u6W+9ClwQAAABAJ0LAaszSpZKkmgpasAAAAAA0HwGrMYsXS5LquvcubDkAAAAAdCoErMYsWSJJqu9BCxYAAACA5iNgNSbXghV7E7AAAAAANB8BqxENCx2w1Lt3QcsBAAAAoHMhYDWidv4SSVLoSwsWAAAAgOYjYDWidp5bsIr79S5sQQAAAAB0KgSsRtTNX6walaq8T7dCFwUAAABAJ0LAakTDoiVaot6q6B4KXRQAAAAAnQgBqxFx0WItVh9VVBS6JAAAAAA6EwJWY5YuIWABAAAAaDECViOKli52F0ECFgAAAIAWIGA1oqhyuZarBwELAAAAQIsQsBpRVL1SVepGwAIAAADQIgSsRhRXr9RKdSVgAQAAAGgRAlYjimuqCFgAAAAAWoyA1YiS2pVaqW7q0qXQJQEAAADQmRCw8tXWqjjWq66sqwLXGQYAAADQAgSsfFVVkqSGsq4FLggAAACAzoaAlW/lSklSfZduBS4IAAAAgM6GgJUvF7BiF1qwAAAAALQMAStfrougCFgAAAAAWoiAlS/XgqVudBEEAAAA0DIErHy5gBW60YIFAAAAoGUIWPmSLoJdCVgAAOD/27v74Kqqg9/jv5UTEggIKiCicAUFRX3AAKn6YFt1qIqtDxarAmWsSG1FpYiO12ur7dhaZ3zUub5Ui4NXRFOnWEblUa/4gopWnWt5p8CjiDQV1FAKBRLydk7Oun/svXJWdk5IcnbekO9nJpOcffbL2i/nnPXba50VAGgbAlaUG+SiF10EAQAAALQNASvKfQeLFiwAAAAAbUTAigq7CPIdLAAAAABtRcCKYhRBAAAAADkiYEWFASuvNy1YAAAAANqGgBWRPhB0ESRgAQAAAGir/K4uQHeTrqxWUgUq6JXo6qIAAAAAOMTQghVRX1mtavVSYWFXlwQAAADAoYaAFZE+QMACAAAAkBsCVkT6QJWqVETAAgAAANBmBKwISwsWAAAAgBy1KmAZYyYZYz4xxmw1xtye5fn/aYxZF/5sNMbUG2OObv/idjxbTcACAAAAkJsWA5YxJiHpMUkXSzpN0nRjzGn+PNba+621xdbaYkk/l/SutXZPB5S341XRRRAAAABAblrTgnWmpK3W2m3W2jpJiyVdepD5p0v6Y3sUrkvQggUAAAAgR60JWMdL2u493hFOa8IYUyRpkqTnm3n+p8aYVcaYVbt27WprWTuFqSFgAQAAAMhNawKWyTLNNjPvf0j6oLnugdbaBdbaEmttycCBA1tbxk6VV00XQQAAAAC5aU3A2iFpqPd4iKQvm5l3mg7l7oGSTC0tWAAAAABy05qAtVLSSGPMcGNMgYIQ9VJ0JmNMP0nnSvqv9i1i50oQsAAAAADkKL+lGay1KWPMHEmvS0pIWmit3WSMmR0+/3g46xRJb1hrD3RYaTtBoi7oIlhQ0NUlAQAAAHCoaTFgSZK19lVJr0amPR55vEjSovYqWJdIp5VI1tKCBQAAACAnrfpHw4eNmhpJImABAAAAyAkByxcGrBr1JGABAAAAaDMCli+VkiQl1YOABQAAAKDNCFi+ZFKSlFI+AQsAAABAmxGwfGELVtrkK5Ho4rIAAAAAOOQQsHxhwFKPHl1bDgAAAACHJAKWL+wiqB6tGr0eAAAAABohYPnCFixDwAIAAACQAwKWryFg0UUQAAAAQNsRsHxhF0FasAAAAADkgoDlC1uw8goIWAAAAADajoDlc10EC+giCAAAAKDtCFg+WrAAAAAAxEDA8oXfwSJgAQAAAMgFAcvnWrAK6SIIAAAAoO0IWL4wYCUKacECAAAA0HYELF/YRZCABQAAACAXBCwfXQQBAAAAxEDA8tFFEAAAAEAMBCxf2EUwvycBCwAAAEDbEbB8rgWrJ10EAQAAALQdAcsXBixasAAAAADkgoDlSdfRRRAAAABA7ghYnlRN0ILVo4guggAAAADajoDlqa9lFEEAAAAAuSNgeWwt/2gYAAAAQO4IWB6bDFqwlE/AAgAAANB2BCyPTaaUllFej0RXFwUAAADAIYiA5UsmlVK+8jgqAAAAAHJAlPDYZIqABQAAACBnRAlfKqWkehCwAAAAAOSEKOGxdXQRBAAAAJA7ooQvRRdBAAAAALkjSnhs2EUwwSCCAAAAAHJAwPIxiiAAAACAGIgSProIAgAAAIiBKOFjFEEAAAAAMRAlfPwfLAAAAAAxECV8Kb6DBQAAACB3RAkfowgCAAAAiIGA5TEMcgEAAAAgBqKEjy6CAAAAAGIgSvgYRRAAAABADEQJD10EAQAAAMRBlPDRRRAAAABADEQJj6lnFEEAAAAAuSNgeegiCAAAACAOooSPLoIAAAAAYiBKeFwXQQIWAAAAgFwQJTymni6CAAAAAHJHlPAYuggCAAAAiIEo4WEUQQAAAABxELA8dBEEAAAAEAdRwpNHF0EAAAAAMRAlPCZNCxYAAACA3BElPAzTDgAAACAOooRjrfL4DhYAAACAGIgSTn29JCmlfEYRBAAAAJATApaTSkkSXQQBAAAA5Iwo4SSTkkQXQQAAAAA5I0o4YQsWAQsAAABArogSDl0EAQAAAMTUqihhjJlkjPnEGLPVGHN7M/OcZ4xZZ4zZZIx5t32L2QlowQIAAAAQU35LMxhjEpIek3SBpB2SVhpjXrLWbvbmOVLS7yVNstZ+bow5poPK23G872AxiiAAAACAXLSmreZMSVuttdustXWSFku6NDLPDyW9YK39XJKstf9o32J2AroIAgAAAIipNVHieEnbvcc7wmm+kyUdZYxZYYxZbYz5UbYVGWN+aoxZZYxZtWvXrtxK3FHoIggAAAAgptZECZNlmo08zpc0XtL3JF0k6ZfGmJObLGTtAmttibW2ZODAgW0ubIdimHYAAAAAMbX4HSwFLVZDvcdDJH2ZZZ5/WmsPSDpgjHlP0hmStrRLKTsDXQQBAAAAxNSaKLFS0khjzHBjTIGkaZJeiszzX5K+ZYzJN8YUSTpL0n+3b1E7GF0EAQAAAMTUYguWtTZljJkj6XVJCUkLrbWbjDGzw+cft9b+tzHmNUkbJKUl/R9r7caOLHi7YxRBAAAAADG1pougrLWvSno1Mu3xyOP7Jd3ffkXrZHQRBAAAABATUcKhiyAAAACAmIgSDqMIAgAAAIiJKOHQRRAAAABATEQJhy6CAAAAAGIiSjgjRui9b92hrzSYUQQBAAAA5ISA5Zx6qt46/7f6SsfJmK4uDAAAAIBDEQHLk06L7oEAAAAAckac8BCwAAAAAMRBnPAQsAAAAADEQZzw1NcTsAAAAADkjjjhSafFCIIAAAAAckbA8tBFEAAAAEAcxAkPAQsAAABAHMQJDwELAAAAQBzECQ8BCwAAAEAcxAkPowgCAAAAiIM44WEUQQAAAABxELA8dBEEAAAAEAdxwkPAAgAAABAHccJDwAIAAAAQB3HCQ8ACAAAAEAdxwsMoggAAAADiIE54GEUQAAAAQBwELA9dBAEAAADEQZzwELAAAAAAxEGc8BCwAAAAAMRBnPAQsAAAAADEQZzwMIogAAAAgDiIEx5GEQQAAAAQBwHLQxdBAAAAAHEQJzwELAAAAABxECc8BCwAAAAAcRAnPAQsAAAAAHEQJzyMIggAAAAgDuKEh1EEAQAAAMRBwPLQRRAAAABAHMQJDwELAAAAQBzECQ8BCwAAAEAcxAkPAQsAAABAHMQJD6MIAgAAAIiDOOFhFEEAAAAAcRCwPHQRBAAAABAHccJDwAIAAAAQB3HCQ8ACAAAAEAdxwkPAAgAAABAHccLDKIIAAAAA4iBOeGjBAgAAABAHccLDMO0AAAAA4iBgeWjBAgAAABAHccJDwAIAAAAQB3HCQ8ACAAAAEAdxwsMoggAAAADiIE54aMECAAAAEAdxwsMoggAAAADiIGB5aMECAAAAEAdxwkPAAgAAABAHccJDwAIAAAAQB3HCwyiCAAAAAOIgTnhowQIAAAAQB3HCwyiCAAAAAOIgYHlowQIAAAAQB3HCQ8ACAAAAEAdxwkPAAgAAABBHq+KEMWaSMeYTY8xWY8ztWZ4/zxizzxizLvz5VfsXteMRsAAAAADEkd/SDMaYhKTHJF0gaYeklcaYl6y1myOz/tlae0kHlLFTWBv8ELAAAAAA5Ko1ceJMSVuttdustXWSFku6tGOL1fnS6eA3owgCAAAAyFVrAtbxkrZ7j3eE06L+3Riz3hizzBhzerYVGWN+aoxZZYxZtWvXrhyK23FcwKIFCwAAAECuWhMnTJZpNvJ4jaQTrLVnSPqdpKXZVmStXWCtLbHWlgwcOLBNBe1oBCwAAAAAcbUmTuyQNNR7PETSl/4M1tr91trK8O9XJfUwxgxot1J2AgIWAAAAgLhaEydWShppjBlujCmQNE3SS/4MxphjjTEm/PvMcL2727uwHYmABQAAACCuFkcRtNamjDFzJL0uKSFpobV2kzFmdvj845Iul3S9MSYlqVrSNGtttBtht1ZfH/wmYAEAAADIVYsBS2ro9vdqZNrj3t+PSnq0fYvWuRhFEAAAAEBctNeE6CIIAAAAIC7iRIiABQAAACAu4kSIgAUAAAAgLuJEiIAFAAAAIC7iRIhRBAEAAADERZwIMYogAAAAgLgIWCG6CAIAAACIizgRImABAAAAiIs4ESJgAQAAAIgrv6sL0F0QsAAAAFBXV6fPPvtMVVVVXV0UdBNFRUU66aSTVFBQ0Kr5CVghRhEEAADAZ599piOPPFKnnHKK8qgYHvbS6bTKy8u1adMmjR49Wvn5LccnrpoQowgCAACgqqpKgwYNIlxBkpSXl6djjz1W9fX1evPNN1u3TAeX6ZBBF0EAAABIIlyhkby8PBlj9Mknn6iurq7l+TuhTIcEAhYAAACA5uTl5SmVSrU8XyeU5ZBAwAIAAEBX2717t4qLi1VcXKxjjz1Wxx9/fMPjllpPVq1apblz57a4jQkTJrRXcZEFg1yECFgAAADoav3799e6deskSXfddZf69OmjW2+9teH5VCrV7EALJSUlKikpaXEbH374YbuUtTPV19crcYgMlkDACjGKIAAAAHzz5klh1mk3xcXSQw+1bZmZM2fq6KOP1tq1azVu3DhNnTpV8+bNU3V1tXr16qWnnnpKp5xyilasWKEHHnhAr7zyiu666y59/vnn2rZtmz7//HPNmzevoXWrT58+qqys1IoVK3TXXXdpwIAB2rhxo8aPH68//OEPMsbo1Vdf1S233KIBAwZo3Lhx2rZtm1555ZVG5SorK9NVV12lAwcOSJIeffTRhtax++67T6WlpcrLy9PFF1+se++9V1u3btXs2bO1a9cuJRIJLVmyRNu3b28osyTNmTNHJSUlmjlzpoYNG6ZZs2bpjTfe0Jw5c1RRUaEFCxaorq5OI0aMUGlpqYqKirRz507Nnj1b27ZtkyTNnz9fy5Yt04ABA3TTTTdJku644w4NGjSoVS18cRGwQowiCAAAgO5qy5YtWr58uRKJhPbv36/33ntP+fn5Wr58uX7xi1/o+eefb7LMxx9/rHfeeUcVFRU65ZRTdP3116tHjx6N5lm7dq02bdqk4447Tuecc44++OADlZSU6LrrrtN7772n4cOHa/r06VnLdMwxx+jNN99Uz5499emnn2r69OlatWqVli1bpqVLl+qjjz5SUVGR9uzZI0maMWOGbr/9dk2ZMkU1NTVKp9Pavn37Qfe7Z8+eev/99yUF3Sd/8pOfSJLuvPNOPfnkk/rZz36muXPn6txzz9WLL76o+vp6VVZW6rjjjtNll12mm266Sel0WosXL9Zf/vKXNh/3XBCwQnQRBAAAgK+tLU0d6YorrmjoIrdv3z5dffXV+vTTT2WMUTKZzLrM9773PRUWFqqwsFDHHHOMdu7cqSFDhjSa58wzz2yYVlxcrLKyMvXp00cnnniihg8fLkmaPn26FixY0GT9yWRSc+bM0bp165RIJLRlyxZJ0vLly3XNNdeoqKhIknT00UeroqJCX3zxhaZMmSIpCE6tMXXq1Ia/N27cqDvvvFN79+5VZWWlLrroIknS22+/rWeeeUaSlEgk1K9fP/Xr10/9+/fX2rVrtXPnTo0dO1b9+/dv1TbjImCFCFgAAADornr37t3w9y9/+Uudf/75evHFF1VWVqbzzjsv6zKFhYUNfycSiawj4GWbx1rbqjI9+OCDGjRokNavX690Ot0Qmqy1MsY0mre5debn5yvtKuKSampqGj3v7/fMmTO1dOlSnXHGGVq0aJFWrFhx0PJde+21WrRokcrLyzVr1qxW7VN7IE6ECFgAAAA4FOzbt0/HH3+8JGnRokXtvv5Ro0Zp27ZtKisrkyQ999xzzZZj8ODBysvLU2lpqerDQQ0uvPBCLVy4UFVVVZKkPXv2qG/fvhoyZIiWLl0qSaqtrVVVVZVOOOEEbd68WbW1tdq3b5/eeuutZstVUVGhwYMHK5lM6tlnn22YPnHiRM2fP19SMBjG/v37JUlTpkzRa6+9ppUrVza0dnUG4kSIgAUAAIBDwW233aaf//znOueccxpCTXvq1auXfv/732vSpEn65je/qUGDBqlfv35N5rvhhhv09NNP6+yzz9aWLVsaWpsmTZqkyZMnq6SkRMXFxXrggQckSaWlpXrkkUc0ZswYTZgwQeXl5Ro6dKiuvPJKjRkzRjNmzNDYsWObLdfdd9+ts846SxdccIFGjRrVMP3hhx/WO++8o9GjR2v8+PHatGmTJKmgoEDnn3++rrzyyk4dgdC0tgmwvZWUlNhVq1Z1ybazefttaeJEacUK6dxzu7o0AAAA6AqrV6/W+PHju7oYXa6yslJ9+vSRtVY33nijRo4cqZtvvrmri9Um6XRa48aN05IlSzRy5MhY61q9erU++OADXXvttQ3fLTPGrLbWNhkXn/aaEKMIAgAAAIEnnnhCxcXFOv3007Vv3z5dd911XV2kNtm8ebNGjBihiRMnxg5XbcUgFyG6CAIAAACBm2+++ZBrsfKddtppDf8Xq7MRJ0IELAAAAABxESdCBCwAAAAAcREnQgQsAAAAAHERJ0JuhEsCFgAAAIBcESdCo0dLv/udNHRoV5cEAAAAh6vzzjtPr7/+eqNpDz30kG644YaDLuP+/dF3v/td7d27t8k8d911V8P/o2rO0qVLtXnz5obHv/rVr7R8+fI2lB4SAavBiSdKc+ZIAwd2dUkAAABwuJo+fboWL17caNrixYs1ffr0Vi3/6quv6sgjj8xp29GA9Zvf/Ebf+c53clpXV+mIf7zcVgzTDgAAAGQzb560bl37rrO4WHrooWafvvzyy3XnnXeqtrZWhYWFKisr05dffqlvfvObuv7667Vy5UpVV1fr8ssv169//esmyw8bNkyrVq3SgAEDdM899+iZZ57R0KFDNXDgwIZ/oPzEE09owYIFqqur04gRI1RaWqp169bppZde0rvvvqvf/va3ev7553X33Xfrkksu0eWXX6633npLt956q1KplL7xjW9o/vz5Kiws1LBhw3T11Vfr5ZdfVjKZ1JIlSzRq1KhGZSorK9NVV12lAwcOSJIeffRRTZgwQZJ03333qbS0VHl5ebr44ot17733auvWrZo9e7Z27dqlRCKhJUuWaPv27XrggQf0yiuvSJLmzJmjkpISzZw5U8OGDdOsWbP0xhtvaM6cOaqoqGiyf0VFRdq5c6dmz57dMHz7/PnztWzZMg0YMEA33XSTJOmOO+7QoEGDNHfu3JxPMS1YAAAAQDfRv39/nXnmmXrttdckBa1XU6dOlTFG99xzj1atWqUNGzbo3Xff1YYNG5pdz+rVq7V48WKtXbtWL7zwglauXNnw3GWXXaaVK1dq/fr1OvXUU/Xkk09qwoQJmjx5su6//36tW7dOJ510UsP8NTU1mjlzpp577jn99a9/VSqV0vz58xueHzBggNasWaPrr78+azfEY445Rm+++abWrFmj5557riG8LFu2TEuXLtVHH32k9evX67bbbpMkzZgxQzfeeKPWr1+vDz/8UIMHD27xuPXs2VPvv/++pk2blnX/JGnu3Lk699xztX79eq1Zs0ann366fvzjH+vpp5+WJKXTaS1evFgzZsxocXsHQwsWAAAAkM1BWpo6kusmeOmll2rx4sVauHChJOlPf/qTFixYoFQqpa+++kqbN2/WmDFjsq7jz3/+s6ZMmaKioiJJ0uTJkxue27hxo+68807t3btXlZWVuuiiiw5ank8++UTDhw/XySefLEm6+uqr9dhjj2nevHmSgsAmSePHj9cLL7zQZPlkMqk5c+Zo3bp1SiQS2rJliyRp+fLluuaaaxrKePTRR6uiokJffPGFpkyZIikITq0xderUFvfv7bff1jPPPCNJSiQS6tevn/r166f+/ftr7dq12rlzp8aOHav+/fu3apvNIWABAAAA3cj3v/993XLLLVqzZo2qq6s1btw4/e1vf9MDDzyglStX6qijjtLMmTNVU1Nz0PUYY7JOnzlzppYuXaozzjhDixYt0ooVKw66HmvtQZ8vLCyUFISWVCrV5PkHH3xQgwYN0vr165VOpxtCk7W2SRmb21Z+fr7S7v8qSU32vXfv3g1/t3X/rr32Wi1atEjl5eWaNWvWQedtDboIAgAAAN1Inz59dN5552nWrFkNg1vs379fvXv3Vr9+/bRz504tW7bsoOv49re/rRdffFHV1dWqqKjQyy+/3PBcRUWFBg8erGQyqWeffbZh+hFHHKGKioom6xo1apTKysq0detWSVJpaanOPffcVu/Pvn37NHjwYOXl5am0tLRhIIoLL7xQCxcuVFVVlSRpz5496tu3r4YMGaKlS5dKkmpra1VVVaUTTjhBmzdvVm1trfbt26e33nqr2e01t38TJ05s6NpYX1+v/fv3S5KmTJmi1157TStXrmyxNa81CFgAAABANzN9+nStX79e06ZNkySdccYZGjt2rE4//XTNmjVL55xzzkGXHzdunKZOnari4mL94Ac/0Le+9a2G5+6++26dddZZuuCCCxoNSDFt2jTdf//9Gjt2rD777LOG6T179tRTTz2lK664QqNHj1ZeXp5mz57d6n254YYb9PTTT+vss8/Wli1bGlqbJk2apMmTJ6ukpETFxcUN398qLS3VI488ojFjxmjChAkqLy/X0KFDdeWVV2rMmDGaMWOGxo4d2+z2mtu/hx9+WO+8845Gjx6t8ePHa9OmTZKkgoICnX/++bryyiuVSCRavV/NMS01+XWUkpIS68brBwAAALqD1atXN4y2h8NDOp3WuHHjtGTJEo0cOTLrPKtXr9YHH3yga6+9tuE7Y8aY1dbakui8tGABAAAAOCxt3rxZI0aM0MSJE5sNV23FIBcAAAAADkunnXZaw//Fai+0YAEAAAAef7Q6oK3XAwELAAAACBUVFam8vJyQBUlBuCovL1cymWxxuHqHLoIAAABA6KSTTtKGDRv05ZdfNvt/pHB4SSaT2rp1q/Lz8xv+59fBELAAAACAUEFBgU4++WQ9//zzWf8nFA5fl1xySauGcSdgAQAAAJ6+ffvqhz/8ofbs2dPwT3Fx+DLG6IgjjlDfvn1bNT8BCwAAAIgoLCzU4MGDu7oYOAQxyAUAAAAAtBPT2tEw2n3DxuyS9Pcu2XjLBkQe/7MbTetu5fm6l/vrtC/drTyH4750t/IcjvvS3cpzOO5LR27nn1m2BQAd5QRr7cDoxC4LWN2ZMWaV/9haW9JdpnW38nzdy/112pfuVp7DcV+6W3kOx33pbuU5HPelI7djrS2JbgsAOhtdBAEAAACgnRCwAAAAAKCdMIpgdgu6+bTuVp6ve7m/TvvS3cpzOO5LdyvP4bgv3a08h+O+dOZ2AKBT8R0sAAAAAGgndBEEAAAAgHZCwAIAAACAdsJ3sDzGmOckTZGUDn/+JWmgJBPOku141Ugq9OaRJNfv0jSd/aBsDsu0RkpSooPW3Zlae3w66jgCALof/z3fKvj8loLPvaSk3ZKmW2tXdH7RAByOaMFq7I+SZkraKulESQckVUuql1Qm6QcKQlcqnFYlqYekD8Lp9ZIqJO0PH6cVvNlPl7QufHxAQShLS9oQrqsqnJ4O/7aSdkiqDKdtC9eXDB/vk3RBuIxV5gMlKalOUq0yIdGG61wXls+Fv7Skd8PtV4e/05Ke8vZte7i+VPh7Z7jtmvBnh3eM6iT9NTwW9eHPB5LekrTXK+NX4fw2LGe1pM3eOfCPW703n8K/3fPuAzQdbtuGZXMftNXeNLes23d3/tx66r3tV0fW7R8zect87E1zy9vwGPmS4f5Ht+PW646dWz6tzPVRH5bVbdf9vT1SJilz3fjcftjIc1aZY5D0nveP+X6vXK68NQqub8c/jik1rtjsUOa1k/bmd+fWXVO+pLet6D64ckf3L51lPn/69izLuLL6DnjbqI885/arNvLYXzblPXbHpTpLud3rPelNc68nf73Ra9O9tqP7Uqumotes264rl7//Se9x9Bpyry3/ePrn8x9q+rpaE5lHyrwW3fUWLVeUv2xNlufd9ZNtevSYuPei6GvA347/2nLr2avGr0s3X324/qT33H5l3jfc9e3+dutNqvH23fmMHhc3z/tqfB1aNb2W3Xr8eXwHvLLWe9Pcfm9W42OdUnBO/fc9d6zdb//9bbeCzyj/fao+nObKUqOmr2f/Oo+WuVZNz0X0evLL667bWq+MH0n6kYLP8UpJR4bH4HfGGOo8ADoFbzYea+1SSR+Gf5dL+pukXgrugu1U8MYtBR+MruJhJK2VtEvBm3hPBZX6PuG89ZKWK/jgypO0JVzffgVv/BXh4x3h865SszN8nBeWwX1YGklF4TwFXhnqvWkFyoQxG5alhxqfb/ehlQjnzwuXP0fBh1RhOF/CK0deOG9huJ/PhNvuEf70D3+b8Od/h/tY6ZVxmzIBIU/S3yUN98rlKhEm3Lar2Msrv1HjD3BXOe0V/q4Ll60Kp0U/nJORfZK3vnxv/a4MjjvWCvfTr1i6SsM/I9s64E1z87gyuuflPW/D8rlj6PbND3HVatpimq+mrXb+cYrOHw1fLvy4ilW9Mi22rtKar+B4uWV2hut1FXdfPwXnPeEtY8L9dsc1EVkm5c3nT/PLGeVfE/4097h3ZP50uB9+aJCC69ltwy+Xf9zT3o+7+WEV3DTwX1v/UrCfPRScv7rIsmVqfLzcHXZXPldhdZVTd0345XLHKd977AeB6PFKKhOg3PmyXvlcxdgdN3ezyF1DLgxs9da939snV56/KHP83fY/D3+7a9rnhzp3Pvwgma1i7b8u05HpeWrc08C/9rL1MnDz+MfWXdMJNX7N+hV9f13lanys/BsI/g0wE/nb/bj39mi49a8pE9lX//0v2z65dbhj5QKeC7tu3jzvb/+9xX+PcNtISurrrX+3gvdX/5gfUOMeHT2U/bhHt+Gei/a0cOc0W13FXWe9lPm8qldwc9RKOlbS2+HzNZL2SOKfEAPoFIwiGGGMGSbpFUmTFVQmpEwlolxBJeRUZVqjjpD0tKR/lzRUQUVNCj6M3IfLbgWVkeHKfHBWhL97KAgtiix3MNFKqML1FSlTUbAKQt0gZe7IHhVZNtt6WpquyPJqZl4pqGS4D0j3gbpE0lmS/ocyFdW+avoh3Noufq5C6h8zt3y0ktIard22m8/dIS9QsL97JQ2IzOMCnzs3KWUqNm7ZXLbti+6re9zSOeoorpLpn5dyScd4ZenIMtWraYBrL3sVBDe3b7XKVPCaK4P7e1+4bEvds1OtmEdqfN7dddFcedpbtuvwK0mDvcfuBknvZubPZRtSbq/ttujo9SO+6LXhn7MtygStpKTfSvpfkn5srX2+MwsJ4PDEB0h2eZLekPS6pCsUVIw+VhCSjlGm8lgUzh+9e5+WtEiZYPZHSSeEy7nuK9UKwpjfZeIVZYLIMjXuflWjzF3OtILWg0pl7i66u4Z+l7Kjwr9tWNZaBS1lUhDItnjL+92BXBfDPcp0c5Ka3gVOqWnlx2+R2ajG4coqOJ6uku3uEO/zlnlOTe/k+l1+Ugo+MMu9MjVXEfXLFu2e1xYHskxzd4QT4fbdh/3RyrQQ+Hed/UpwvjJ3il0lvblui+53nbfNaOuLv37/cTRcuVaLaDcd91zSm8fftrJsLxt33Shcl39erIJjE71j/an3uCrLOm3kd42yly+quXAV7WbXnOa6ptUpaJV151zKhJpolzO/DIlwnX3UOHS5c24jy+cr062vuXMuNW3lsGp8w8Zfd7RVK61MS7c/zd/fg3E3D9x8SQWtBr50WB6/MrzDe7654+x+u2MblcuNk+hjf1ptZDs2y3y1yrT2ufdy974ZbRV2LcIpbx0V3uMD3nr3q/F5dstHu9Fm6xbpXjPWm8e9Z/vded00v8XRf89pC/817h9Df5/96+1fXhmjrZPR69FvsW1JczcBa5X5jHlZQU+UXyjoaZLtGAJAuyNgNZWvoCWqTNJoSQ8peNMepaC1yoWQMgXdAq0yXcD8CtV/KNM96ifh73pJX4TL9Vfjbj9Vkr6jTKX0jPC5WgUB5NHwOfeBOFBB5dy1mLlufm551/VP4fTC8GdoOO0ISScrc4f5Xwo+kCrDbdYr03e9OVvC3/6HpF+p/jc1rpy472yUqXG3oj7efBcoc12mFHQ5ct3xXKBJh2Vz80jB8asOf6cVdD3cq8aVCcdff/TD3K8QOdlaA/x9cBX9hJq2Vrnz7neJcefQ78rmusYYbzlXWfC787SlZS4aiN02/G5Trkz+93LcdH8b0a6U/n47+d580a5BUnDTwnVldD8jIuU92L74++D+lld2v8K4N1Jev4xuevQ8t3TOXZfI6PXkQoR/vNzNA3ecKsNtR7tA+Tcg/MBivWnuJ5dz7tYf7QrmV3T9wBoNbIrMF60U+/sTPed1Clrv/elW0pAs225uX9w2ouVw59x9180FpGxB1Gb5cde800ON37vczSrXHdx1K3bv6W4Z/yaJwmUqI9tVuHxvZa4Ld32lw78/UuZ9wv347+FS9htJ7iaf8ebpFf7tWg3d+8VOZd7r3DaytRD637/yr2FF5u/hrcMqCIpuebf+GmVu9LllfP7597tq+vvqPo/80PkvZV4r7hzVe8v2UvAe/f+stf+moOfEcWp8QwcAOgwBy2OMMZL+U8Gb9eWSTpE0TsEH+CcKgs4AZe50uu93FCrTZahSQWvXs8pUjt1dWiPp/yoIAXnh73wFb/ovhsvuVnDn8cNwmQIFXxz/UfjYfQjdrqCFqNzbhuu2WKUgzPhfav++pNUKgoffOuVaYD4L/65WpiJwk4LvTPktJ1LmA/hYNa5E7Ja0ydtv94Hryue+UH98eCw2SHot3LZb94vKSCo4/n5Fc6+C8/OPyHrd98DcMfpIwQd7jTJ3daOtF66Ln1/BqFHjQJRSEKCjLSlS0wqRlbRejcNKpTKVKT+0+K2fdQq+e+YqiH4luUqZCrKrfPxdmSDp87/Q7x67335riF9uhetx39Fz26hT4++TRSvC0Qq/VeZ7SVLTgQaspLO99aTDfditppoLPa4VwFUS3XXmbjy4YFujIICn1fh7TNHj5b7TKGVaY90gFP5xdL/dzQz/nEvBa9C/m1+uxteE1LgCX6/gveTPXrn8MBENVu4mgBugwA850VYwedP9Fm7/nLtlouHLtbC4fY4ONhCtkLtlooNBSJn3uAHe9KQy70vOHjUVDX/71HQAFHfO3Wsq7U3zB0pwxzYaHF33bDeP36rmv06Ngvdgd2PA3fRylX7/mLhyFClzs6GHtx7XJdqV0S2zR9KZahxWPw7L5B8LvxXKv9ZcmV0LtHvt1ShzzncraNXxA+ImBefPb3mTMu8B/jWeiMwjZc6FOwbRmycK980/F9HXc7ZwFx00o8Art9vOEcrceFsv6V5l3uPeDJfpK+kzY0xvSRMlVVpr/QGVAKDD8B0sjzHmTQWtSFLjCka1glaWOmUqWd1NlYKyuQpU9G6nX4k7WEvBwcT5XsIeBV3EfNk+YAEAaCvX5dUF7R3KtJZ+Luk71tq/d1HZABxmCFgAAAAA0E7oIggAAAAA7YSABQAAAADthIAFAAAAAO2EgAUAAAAA7YSABQAAAADthIAFAAAAAO2EgAUAAAAA7eT/A+nHdChDkxvtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 400, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 400, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis\n",
    "Finding the Confusion matrix,Precision,Recall and F1 score to analyse the model thus created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig(os.path.join(MODEL_PATH,\"confusion_matrix.png\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heatmap(n_labels, n_predictions, class_names):\n",
    "    labels = n_labels #sess.run(tf.argmax(n_labels, 1))\n",
    "    predictions = n_predictions #sess.run(tf.argmax(n_predictions, 1))\n",
    "\n",
    "    matrix = confusion_matrix(labels.argmax(axis=1),predictions.argmax(axis=1))\n",
    "    row_sum = np.sum(matrix, axis = 1)\n",
    "    w, h = matrix.shape\n",
    "\n",
    "    c_m = np.zeros((w, h))\n",
    "\n",
    "    for i in range(h):\n",
    "        c_m[i] = matrix[i] * 100 / row_sum[i]\n",
    "\n",
    "    c = c_m.astype(dtype = np.uint8)\n",
    "\n",
    "    \n",
    "    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "class_names = list()\n",
    "for name,idx in labels_id.items():\n",
    "    class_names.append(name)\n",
    "# print(class_names)\n",
    "ypred = VGG16_model.predict(valid_vgg16,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_heatmap(ytest,ypred,class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision Recall F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_class = np.argmax(ypred,axis=1)\n",
    "# print(ypred_class[:10])\n",
    "ytest = np.argmax(ytest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.906132\n",
      "Precision: 0.906774\n",
      "Recall: 0.906132\n",
      "F1 score: 0.906273\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest,ypred_class)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(ytest, ypred_class,average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(ytest,ypred_class,average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(ytest,ypred_class,average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
